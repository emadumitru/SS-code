{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### original w/ count vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification results saved successfully.\n",
      "Accuracy  and TN/TP/FN/FP for each refactoring type:\n",
      "Extract Interface: 0.881 -- TN/TP/FN/FP : 37/0/5/0\n",
      "Extract Method: 0.405 -- TN/TP/FN/FP : 7/10/10/15\n",
      "Extract Superclass: 0.857 -- TN/TP/FN/FP : 36/0/6/0\n",
      "Inline Method: 0.881 -- TN/TP/FN/FP : 37/0/5/0\n",
      "Move Attribute: 0.738 -- TN/TP/FN/FP : 31/0/11/0\n",
      "Move Class: 0.548 -- TN/TP/FN/FP : 23/0/19/0\n",
      "Move Method: 0.738 -- TN/TP/FN/FP : 31/0/11/0\n",
      "Pull Up Method: 0.857 -- TN/TP/FN/FP : 36/0/6/0\n",
      "Rename Package: 0.833 -- TN/TP/FN/FP : 35/0/7/0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import pickle\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "\n",
    "def load_data(data_folder, refactoring_details_path):\n",
    "    ref_details = pd.read_csv(refactoring_details_path)\n",
    "    train_documents = []\n",
    "    test_documents = []\n",
    "    train_ids = []\n",
    "    test_ids = []\n",
    "    training_labels = {}\n",
    "    testing_labels = {}\n",
    "\n",
    "    # Initialize training labels for all refactoring types\n",
    "    ref_types = [d.replace('_single', '') for d in os.listdir(data_folder) if '_single' in d]\n",
    "    for ref_type in ref_types:\n",
    "        training_labels[ref_type] = []\n",
    "        testing_labels[ref_type] = []\n",
    "\n",
    "    # Load training data from _single directories and assign labels\n",
    "    for ref_type in os.listdir(data_folder):\n",
    "        if '_single' in ref_type:\n",
    "            ref_type_clean = ref_type.replace('_single', '')\n",
    "            subfolder_path = os.path.join(data_folder, ref_type)\n",
    "            for filename in os.listdir(subfolder_path):\n",
    "                if filename.endswith('.md'):\n",
    "                    file_path = os.path.join(subfolder_path, filename)\n",
    "                    with open(file_path, 'r') as file:\n",
    "                        content = file.read()\n",
    "                        train_documents.append(content)\n",
    "                        train_ids.append(filename.split('_')[0])\n",
    "                        # Initialize labels for all refactoring types as 0\n",
    "                        for key in training_labels:\n",
    "                            training_labels[key].append(0)\n",
    "                        # Set the current refactoring type label to 1\n",
    "                        training_labels[ref_type_clean][-1] = 1\n",
    "\n",
    "    # Load testing data from _mixed directories and assign labels based on CSV\n",
    "    for ref_type in os.listdir(data_folder):\n",
    "        if '_mixed' in ref_type:\n",
    "            ref_type_clean = ref_type.replace('_mixed', '')\n",
    "            subfolder_path = os.path.join(data_folder, ref_type)\n",
    "            for filename in os.listdir(subfolder_path):\n",
    "                if filename.endswith('.md'):\n",
    "                    file_path = os.path.join(subfolder_path, filename)\n",
    "                    with open(file_path, 'r') as file:\n",
    "                        content = file.read()\n",
    "                        test_documents.append(content)\n",
    "                        file_id = filename.split('_')[0]\n",
    "                        test_ids.append(file_id) \n",
    "                        # Initialize labels for all refactoring types as 0\n",
    "                        for key in testing_labels:\n",
    "                            testing_labels[key].append(0)\n",
    "                        # Set labels based on occurrence counts from the CSV\n",
    "                        for key in ref_types:\n",
    "                            count = ref_details.loc[ref_details['id'] == int(file_id), key].values[0]\n",
    "                            if count > 0:\n",
    "                                testing_labels[key][-1] = 1\n",
    "\n",
    "    return train_documents, train_ids, test_documents, test_ids, training_labels, testing_labels\n",
    "\n",
    "def train_and_evaluate(train_docs, train_labels, test_docs, test_labels, path_save='analysis_results\\\\'):\n",
    "    vectorizer=CountVectorizer()\n",
    "    X_train = vectorizer.fit_transform(train_docs)\n",
    "    X_test = vectorizer.transform(test_docs)\n",
    "    classifiers = {}\n",
    "    results = {}\n",
    "    summary = {}\n",
    "    \n",
    "    for refactoring_type, labels in train_labels.items():\n",
    "        clf = RandomForestClassifier()\n",
    "        clf.fit(X_train, labels)\n",
    "        classifiers[refactoring_type] = clf\n",
    "\n",
    "        # Evaluate classifier\n",
    "        predictions = clf.predict(X_test)\n",
    "        true = np.array(test_labels[refactoring_type])\n",
    "        cm = confusion_matrix(true, predictions)\n",
    "        acc = accuracy_score(true, predictions)\n",
    "        \n",
    "        # Store results\n",
    "        results[refactoring_type] = {\n",
    "            'confusion_matrix': cm,\n",
    "            'accuracy': acc\n",
    "        }\n",
    "        summary[refactoring_type] = [acc, *cm.ravel()]  # Flatten confusion matrix and prepend accuracy\n",
    "\n",
    "    # Serialize results and summary\n",
    "    with open(path_save + 'classification_summary.pkl', 'wb') as f:\n",
    "        pickle.dump(summary, f)\n",
    "    with open(path_save + 'classification_results.txt', 'w') as f:\n",
    "        f.write(str(results))\n",
    "    \n",
    "    return classifiers, results\n",
    "\n",
    "data_folder = \"dataset_clean\\\\\"\n",
    "refactoring_details_path = 'analysis_results\\\\refactoring_details_post.csv'\n",
    "train_docs, train_ids, test_docs, test_ids, train_labels, test_labels = load_data(data_folder, refactoring_details_path)\n",
    "classifiers, results = train_and_evaluate(train_docs, train_labels, test_docs, test_labels)\n",
    "\n",
    "print(\"Classification results saved successfully.\")\n",
    "\n",
    "print(\"Accuracy  and TN/TP/FN/FP for each refactoring type:\")\n",
    "for refactoring_type, result in results.items():\n",
    "    print(f\"{refactoring_type}: {round(result['accuracy'],3)} -- TN/TP/FN/FP : {result['confusion_matrix'][0][0]}/{result['confusion_matrix'][1][1]}/{result['confusion_matrix'][1][0]}/{result['confusion_matrix'][0][1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### w/ action count (0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy  and TN/TP/FN/FP for each refactoring type:\n",
      "Inline Method: 0.865 -- TN/TP/FN/FP : 32/0/5/0\n",
      "Extract Method: 0.811 -- TN/TP/FN/FP : 11/19/3/4\n",
      "Move Class: 0.865 -- TN/TP/FN/FP : 32/0/3/2\n",
      "Extract Interface: 0.946 -- TN/TP/FN/FP : 35/0/2/0\n",
      "Rename Package: 0.973 -- TN/TP/FN/FP : 36/0/1/0\n",
      "Pull Up Method: 0.973 -- TN/TP/FN/FP : 36/0/1/0\n",
      "Pull Up Attribute: 0.973 -- TN/TP/FN/FP : 36/0/1/0\n",
      "Move Attribute: 0.973 -- TN/TP/FN/FP : 36/0/1/0\n",
      "Move Method: 0.973 -- TN/TP/FN/FP : 36/0/1/0\n",
      "Extract Superclass: 0.946 -- TN/TP/FN/FP : 35/0/2/0\n",
      "Push Down Attribute: 0.973 -- TN/TP/FN/FP : 36/0/1/0\n",
      "Push Down Method: 1.0 -- TN/TP/FN/FP : 37/0/0/0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Ema\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "\n",
    "folder_path = 'data_diffs_clean\\\\'\n",
    "refactoring_df = pd.read_csv('analysis_results\\\\refactoring_details_post.csv')\n",
    "all_present_actions = ['delete-tree', 'insert-node', 'move-tree', 'delete-node', 'update-node', 'insert-tree']\n",
    "refactorings = refactoring_df.columns[1:]\n",
    "\n",
    "# Function to count the occurrences of each action in a file\n",
    "def count_file_content(lines, actions):\n",
    "    blocks = []\n",
    "    current_block = []\n",
    "    for line in lines:\n",
    "        if line.strip() == '===':\n",
    "            if current_block != []:\n",
    "                blocks.append(current_block)\n",
    "                current_block = []\n",
    "        current_block.append(line)\n",
    "\n",
    "    for block in blocks:\n",
    "        action = block[1].strip()\n",
    "        if action in actions:\n",
    "            actions[action] += 1\n",
    "    \n",
    "    return actions\n",
    "\n",
    "# Function to parse edit script files and count edit actions\n",
    "def parse_edit_script(file_path):\n",
    "    with open(file_path, 'r') as file:\n",
    "        content = file.read()\n",
    "    actions = {action: 0 for action in all_present_actions}\n",
    "    action_counts = count_file_content(content.split('\\n'), actions)\n",
    "    return action_counts\n",
    "\n",
    "# Creating a dataframe with action counts\n",
    "edit_script_data = []\n",
    "for filename in os.listdir(folder_path):\n",
    "    if filename.endswith(\".md\"):\n",
    "        file_path = os.path.join(folder_path, filename)\n",
    "        action_counts = parse_edit_script(file_path)\n",
    "        edit_script_data.append({'id': int(filename.split('_')[0]), **action_counts})\n",
    "\n",
    "edit_script_df = pd.DataFrame(edit_script_data).fillna(0)\n",
    "\n",
    "# Merge the two dataframes on 'id'\n",
    "merged_df = pd.merge(edit_script_df, refactoring_df, on='id')\n",
    "\n",
    "# Create a binary label for refactoring presence\n",
    "for refactoring in refactorings:\n",
    "    merged_df[f'{refactoring}_Label'] = merged_df[refactoring] > 0\n",
    "\n",
    "# Train and evaluate a RandomForestClassifier for each refactoring\n",
    "clfs = {}\n",
    "cms = {}\n",
    "accs = {}\n",
    "summary = {}\n",
    "\n",
    "for refactoring in refactorings:\n",
    "    features = all_present_actions\n",
    "    target = f'{refactoring}_Label'\n",
    "\n",
    "    X = merged_df[features]\n",
    "    y = merged_df[target]\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=17)\n",
    "\n",
    "    clf = RandomForestClassifier(n_estimators=100, random_state=17)\n",
    "    clf.fit(X_train, y_train)\n",
    "\n",
    "    y_pred = clf.predict(X_test)\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "\n",
    "    if cm.shape == (1, 1):\n",
    "        cm = np.array([[cm[0][0], 0], [0, 0]])\n",
    "\n",
    "    clfs[refactoring] = clf\n",
    "    cms[refactoring] = cm\n",
    "    accs[refactoring] = acc\n",
    "    summary[refactoring] = [acc, *cm.ravel()]\n",
    "\n",
    "# Save the results\n",
    "with open('cluster_results\\\\classification_accuracy.txt', 'w') as f:\n",
    "    f.write(str(accs))\n",
    "with open('cluster_results\\\\classification_summary.pkl', 'wb') as f:\n",
    "    pickle.dump(summary, f)\n",
    "\n",
    "print(\"Accuracy  and TN/TP/FN/FP for each refactoring type:\")\n",
    "for ref in accs:\n",
    "    print(f\"{ref}: {round(accs[ref],3)} -- TN/TP/FN/FP : {cms[ref][0][0]}/{cms[ref][1][1]}/{cms[ref][1][0]}/{cms[ref][0][1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### w/ action count balance y (0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy  and TN/TP/FN/FP for each refactoring type:\n",
      "Inline Method: 0.919 -- TN/TP/FN/FP : 34/0/3/0\n",
      "Extract Method: 0.757 -- TN/TP/FN/FP : 7/21/1/8\n",
      "Move Class: 0.784 -- TN/TP/FN/FP : 29/0/5/3\n",
      "Extract Interface: 0.973 -- TN/TP/FN/FP : 36/0/1/0\n",
      "Rename Package: 1.0 -- TN/TP/FN/FP : 36/1/0/0\n",
      "Pull Up Method: 0.946 -- TN/TP/FN/FP : 35/0/2/0\n",
      "Pull Up Attribute: 0.973 -- TN/TP/FN/FP : 36/0/1/0\n",
      "Move Attribute: 0.919 -- TN/TP/FN/FP : 34/0/2/1\n",
      "Move Method: 0.946 -- TN/TP/FN/FP : 35/0/2/0\n",
      "Extract Superclass: 0.946 -- TN/TP/FN/FP : 35/0/2/0\n",
      "Push Down Attribute: 0.973 -- TN/TP/FN/FP : 36/0/1/0\n",
      "Push Down Method: 1.0 -- TN/TP/FN/FP : 37/0/0/0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Ema\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "\n",
    "folder_path = 'data_diffs_clean\\\\'\n",
    "refactoring_df = pd.read_csv('analysis_results\\\\refactoring_details_post.csv')\n",
    "all_present_actions = ['delete-tree', 'insert-node', 'move-tree', 'delete-node', 'update-node', 'insert-tree']\n",
    "refactorings = refactoring_df.columns[1:]\n",
    "\n",
    "# Function to count the occurrences of each action in a file\n",
    "def count_file_content(lines, actions):\n",
    "    blocks = []\n",
    "    current_block = []\n",
    "    for line in lines:\n",
    "        if line.strip() == '===':\n",
    "            if current_block != []:\n",
    "                blocks.append(current_block)\n",
    "                current_block = []\n",
    "        current_block.append(line)\n",
    "\n",
    "    for block in blocks:\n",
    "        action = block[1].strip()\n",
    "        if action in actions:\n",
    "            actions[action] += 1\n",
    "    \n",
    "    return actions\n",
    "\n",
    "# Function to parse edit script files and count edit actions\n",
    "def parse_edit_script(file_path):\n",
    "    with open(file_path, 'r') as file:\n",
    "        content = file.read()\n",
    "    actions = {action: 0 for action in all_present_actions}\n",
    "    action_counts = count_file_content(content.split('\\n'), actions)\n",
    "    return action_counts\n",
    "\n",
    "# Creating a dataframe with action counts\n",
    "edit_script_data = []\n",
    "for filename in os.listdir(folder_path):\n",
    "    if filename.endswith(\".md\"):\n",
    "        file_path = os.path.join(folder_path, filename)\n",
    "        action_counts = parse_edit_script(file_path)\n",
    "        edit_script_data.append({'id': int(filename.split('_')[0]), **action_counts})\n",
    "\n",
    "edit_script_df = pd.DataFrame(edit_script_data).fillna(0)\n",
    "\n",
    "# Merge the two dataframes on 'id'\n",
    "merged_df = pd.merge(edit_script_df, refactoring_df, on='id')\n",
    "\n",
    "# Create a binary label for refactoring presence\n",
    "for refactoring in refactorings:\n",
    "    merged_df[f'{refactoring}_Label'] = merged_df[refactoring] > 0\n",
    "\n",
    "# Train and evaluate a RandomForestClassifier for each refactoring\n",
    "clfs = {}\n",
    "cms = {}\n",
    "accs = {}\n",
    "summary = {}\n",
    "\n",
    "for refactoring in refactorings:\n",
    "    features = all_present_actions\n",
    "    target = f'{refactoring}_Label'\n",
    "\n",
    "    X = merged_df[features]\n",
    "    y = merged_df[target]\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=17, stratify=y)\n",
    "\n",
    "    clf = RandomForestClassifier(n_estimators=100, random_state=17)\n",
    "    clf.fit(X_train, y_train)\n",
    "\n",
    "    y_pred = clf.predict(X_test)\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "\n",
    "    if cm.shape == (1, 1):\n",
    "        cm = np.array([[cm[0][0], 0], [0, 0]])\n",
    "\n",
    "    clfs[refactoring] = clf\n",
    "    cms[refactoring] = cm\n",
    "    accs[refactoring] = acc\n",
    "    summary[refactoring] = [acc, *cm.ravel()]\n",
    "\n",
    "# Save the results\n",
    "with open('cluster_results\\\\classification_accuracy.txt', 'w') as f:\n",
    "    f.write(str(accs))\n",
    "with open('cluster_results\\\\classification_summary.pkl', 'wb') as f:\n",
    "    pickle.dump(summary, f)\n",
    "\n",
    "print(\"Accuracy  and TN/TP/FN/FP for each refactoring type:\")\n",
    "for ref in accs:\n",
    "    print(f\"{ref}: {round(accs[ref],3)} -- TN/TP/FN/FP : {cms[ref][0][0]}/{cms[ref][1][1]}/{cms[ref][1][0]}/{cms[ref][0][1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### w/ AC and start y (0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inline Method\n",
      "Extract Method\n",
      "Move Class\n",
      "Extract Interface\n",
      "Rename Package\n",
      "Pull Up Method\n",
      "Pull Up Attribute\n",
      "Move Attribute\n",
      "Move Method\n",
      "Extract Superclass\n",
      "Push Down Attribute\n",
      "Push Down Method\n",
      "Accuracy  and TN/TP/FN/FP for each refactoring type:\n",
      "Inline Method: 0.909 -- TN/TP/FN/FP : 50/0/5/0\n",
      "Extract Method: 0.709 -- TN/TP/FN/FP : 11/28/4/12\n",
      "Move Class: 0.8 -- TN/TP/FN/FP : 44/0/8/3\n",
      "Extract Interface: 0.982 -- TN/TP/FN/FP : 54/0/1/0\n",
      "Rename Package: 0.982 -- TN/TP/FN/FP : 53/1/1/0\n",
      "Pull Up Method: 0.945 -- TN/TP/FN/FP : 52/0/2/1\n",
      "Pull Up Attribute: 0.945 -- TN/TP/FN/FP : 52/0/2/1\n",
      "Move Attribute: 0.927 -- TN/TP/FN/FP : 51/0/4/0\n",
      "Move Method: 0.909 -- TN/TP/FN/FP : 49/1/2/3\n",
      "Extract Superclass: 0.964 -- TN/TP/FN/FP : 53/0/2/0\n",
      "Push Down Attribute: 0.982 -- TN/TP/FN/FP : 54/0/1/0\n",
      "Push Down Method: 0.982 -- TN/TP/FN/FP : 54/0/1/0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "\n",
    "folder_path = 'data_diffs_clean\\\\'\n",
    "refactoring_df = pd.read_csv('analysis_results\\\\refactoring_details_post.csv')\n",
    "all_present_actions = ['delete-tree', 'insert-node', 'move-tree', 'delete-node', 'update-node', 'insert-tree']\n",
    "refactorings = refactoring_df.columns[1:]\n",
    "\n",
    "# Function to count the occurrences of each action in a file\n",
    "def count_file_content(lines, actions):\n",
    "    blocks = []\n",
    "    current_block = []\n",
    "    for line in lines:\n",
    "        if line.strip() == '===':\n",
    "            if current_block != []:\n",
    "                blocks.append(current_block)\n",
    "                current_block = []\n",
    "        current_block.append(line)\n",
    "\n",
    "    for block in blocks:\n",
    "        action = block[1].strip()\n",
    "        if action in actions:\n",
    "            actions[action] += 1\n",
    "    \n",
    "    return actions\n",
    "\n",
    "# Function to parse edit script files and count edit actions\n",
    "def parse_edit_script(file_path):\n",
    "    with open(file_path, 'r') as file:\n",
    "        content = file.read()\n",
    "    actions = {action: 0 for action in all_present_actions}\n",
    "    action_counts = count_file_content(content.split('\\n'), actions)\n",
    "    return action_counts\n",
    "\n",
    "# Creating a dataframe with action counts\n",
    "edit_script_data = []\n",
    "for filename in os.listdir(folder_path):\n",
    "    if filename.endswith(\".md\"):\n",
    "        file_path = os.path.join(folder_path, filename)\n",
    "        action_counts = parse_edit_script(file_path)\n",
    "        edit_script_data.append({'id': int(filename.split('_')[0]), **action_counts})\n",
    "\n",
    "edit_script_df = pd.DataFrame(edit_script_data).fillna(0)\n",
    "\n",
    "# Merge the two dataframes on 'id'\n",
    "merged_df = pd.merge(edit_script_df, refactoring_df, on='id')\n",
    "\n",
    "# Create a binary label for refactoring presence\n",
    "for refactoring in refactorings:\n",
    "    merged_df[f'{refactoring}_Label'] = merged_df[refactoring] > 0\n",
    "\n",
    "# Train and evaluate a RandomForestClassifier for each refactoring\n",
    "clfs = {}\n",
    "cms = {}\n",
    "accs = {}\n",
    "summary = {}\n",
    "\n",
    "for refactoring in refactorings:\n",
    "    print(refactoring)\n",
    "    features = all_present_actions\n",
    "    target = f'{refactoring}_Label'\n",
    "\n",
    "    X = merged_df[features]\n",
    "    y = merged_df[target]\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=17, stratify=y)\n",
    "\n",
    "    clf = RandomForestClassifier(n_estimators=100, random_state=17)\n",
    "    clf.fit(X_train, y_train)\n",
    "\n",
    "    y_pred = clf.predict(X_test)\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "\n",
    "    if cm.shape == (1, 1):\n",
    "        cm = np.array([[cm[0][0], 0], [0, 0]])\n",
    "\n",
    "    clfs[refactoring] = clf\n",
    "    cms[refactoring] = cm\n",
    "    accs[refactoring] = acc\n",
    "    summary[refactoring] = [acc, *cm.ravel()]\n",
    "\n",
    "# Save the results\n",
    "with open('cluster_results\\\\classification_accuracy.txt', 'w') as f:\n",
    "    f.write(str(accs))\n",
    "with open('cluster_results\\\\classification_summary.pkl', 'wb') as f:\n",
    "    pickle.dump(summary, f)\n",
    "\n",
    "print(\"Accuracy  and TN/TP/FN/FP for each refactoring type:\")\n",
    "for ref in accs:\n",
    "    print(f\"{ref}: {round(accs[ref],3)} -- TN/TP/FN/FP : {cms[ref][0][0]}/{cms[ref][1][1]}/{cms[ref][1][0]}/{cms[ref][0][1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### w/ SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping Extract Interface due to low sample count\n",
      "Skipping Rename Package due to low sample count\n",
      "Skipping Pull Up Method due to low sample count\n",
      "Skipping Pull Up Attribute due to low sample count\n",
      "Skipping Extract Superclass due to low sample count\n",
      "Skipping Push Down Attribute due to low sample count\n",
      "Skipping Push Down Method due to low sample count\n",
      "\n",
      "Accuracy  and TN/TP/FN/FP for each refactoring type:\n",
      "Inline Method: 0.913 -- TN/TP/FN/FP : 42/0/4/0\n",
      "Extract Method: 0.717 -- TN/TP/FN/FP : 8/25/2/11\n",
      "Move Class: 0.783 -- TN/TP/FN/FP : 36/0/7/3\n",
      "Move Attribute: 0.935 -- TN/TP/FN/FP : 43/0/3/0\n",
      "Move Method: 0.913 -- TN/TP/FN/FP : 41/1/2/2\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "\n",
    "folder_path = 'data_diffs_clean\\\\'\n",
    "refactoring_df = pd.read_csv('analysis_results\\\\refactoring_details_post.csv')\n",
    "all_present_actions = ['delete-tree', 'insert-node', 'move-tree', 'delete-node', 'update-node', 'insert-tree']\n",
    "refactorings = refactoring_df.columns[1:]\n",
    "\n",
    "# Function to count the occurrences of each action in a file\n",
    "def count_file_content(lines, actions):\n",
    "    blocks = []\n",
    "    current_block = []\n",
    "    for line in lines:\n",
    "        if line.strip() == '===':\n",
    "            if current_block != []:\n",
    "                blocks.append(current_block)\n",
    "                current_block = []\n",
    "        current_block.append(line)\n",
    "\n",
    "    for block in blocks:\n",
    "        action = block[1].strip()\n",
    "        if action in actions:\n",
    "            actions[action] += 1\n",
    "    \n",
    "    return actions\n",
    "\n",
    "# Function to parse edit script files and count edit actions\n",
    "def parse_edit_script(file_path):\n",
    "    with open(file_path, 'r') as file:\n",
    "        content = file.read()\n",
    "    actions = {action: 0 for action in all_present_actions}\n",
    "    action_counts = count_file_content(content.split('\\n'), actions)\n",
    "    return action_counts\n",
    "\n",
    "# Creating a dataframe with action counts\n",
    "edit_script_data = []\n",
    "for filename in os.listdir(folder_path):\n",
    "    if filename.endswith(\".md\"):\n",
    "        file_path = os.path.join(folder_path, filename)\n",
    "        action_counts = parse_edit_script(file_path)\n",
    "        edit_script_data.append({'id': int(filename.split('_')[0]), **action_counts})\n",
    "\n",
    "edit_script_df = pd.DataFrame(edit_script_data).fillna(0)\n",
    "\n",
    "# Merge the two dataframes on 'id'\n",
    "merged_df = pd.merge(edit_script_df, refactoring_df, on='id')\n",
    "\n",
    "# Create a binary label for refactoring presence\n",
    "for refactoring in refactorings:\n",
    "    merged_df[f'{refactoring}_Label'] = merged_df[refactoring] > 0\n",
    "\n",
    "# Train and evaluate a RandomForestClassifier for each refactoring\n",
    "clfs = {}\n",
    "cms = {}\n",
    "accs = {}\n",
    "summary = {}\n",
    "\n",
    "for refactoring in refactorings:\n",
    "    features = all_present_actions\n",
    "    target = f'{refactoring}_Label'\n",
    "\n",
    "    X = merged_df[features]\n",
    "    y = merged_df[target]\n",
    "\n",
    "    # skip refactoring types with less than 10 samples\n",
    "    if y.sum() < 10:\n",
    "        print(f\"Skipping {refactoring} due to low sample count\")\n",
    "        continue\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=17, stratify=y)\n",
    "\n",
    "    # Apply SMOTE to the training data\n",
    "    smote = SMOTE(random_state=17)\n",
    "    X_train_balanced, y_train_balanced = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "    clf = RandomForestClassifier(n_estimators=100, random_state=17)\n",
    "    clf.fit(X_train, y_train)\n",
    "\n",
    "    y_pred = clf.predict(X_test)\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "\n",
    "    if cm.shape == (1, 1):\n",
    "        cm = np.array([[cm[0][0], 0], [0, 0]])\n",
    "\n",
    "    clfs[refactoring] = clf\n",
    "    cms[refactoring] = cm\n",
    "    accs[refactoring] = acc\n",
    "    summary[refactoring] = [acc, *cm.ravel()]\n",
    "\n",
    "# Save the results\n",
    "with open('cluster_results\\\\classification_accuracy.txt', 'w') as f:\n",
    "    f.write(str(accs))\n",
    "with open('cluster_results\\\\classification_summary.pkl', 'wb') as f:\n",
    "    pickle.dump(summary, f)\n",
    "\n",
    "print(\"\\nAccuracy  and TN/TP/FN/FP for each refactoring type:\")\n",
    "for ref in accs:\n",
    "    print(f\"{ref}: {round(accs[ref],3)} -- TN/TP/FN/FP : {cms[ref][0][0]}/{cms[ref][1][1]}/{cms[ref][1][0]}/{cms[ref][0][1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### w/ new features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping Extract Interface due to low sample count\n",
      "Skipping Rename Package due to low sample count\n",
      "Skipping Pull Up Method due to low sample count\n",
      "Skipping Pull Up Attribute due to low sample count\n",
      "Skipping Extract Superclass due to low sample count\n",
      "Skipping Push Down Attribute due to low sample count\n",
      "Skipping Push Down Method due to low sample count\n",
      "\n",
      "Accuracy  and TN/TP/FN/FP for each refactoring type:\n",
      "Inline Method: 0.918 -- TN/TP/FN/FP : 67/0/6/0\n",
      "Extract Method: 0.658 -- TN/TP/FN/FP : 12/36/7/18\n",
      "Move Class: 0.753 -- TN/TP/FN/FP : 55/0/11/7\n",
      "Move Attribute: 0.932 -- TN/TP/FN/FP : 68/0/5/0\n",
      "Move Method: 0.904 -- TN/TP/FN/FP : 65/1/3/4\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "\n",
    "folder_path = 'data_diffs_clean\\\\'\n",
    "refactoring_df = pd.read_csv('analysis_results\\\\refactoring_details_post.csv')\n",
    "all_present_actions = ['delete-tree', 'insert-node', 'move-tree', 'delete-node', 'update-node', 'insert-tree']\n",
    "refactorings = refactoring_df.columns[1:]\n",
    "\n",
    "# Function to count the occurrences of each action in a file\n",
    "def count_file_content(lines, actions):\n",
    "    blocks = []\n",
    "    current_block = []\n",
    "    for line in lines:\n",
    "        if line.strip() == '===':\n",
    "            if current_block != []:\n",
    "                blocks.append(current_block)\n",
    "                current_block = []\n",
    "        current_block.append(line)\n",
    "\n",
    "    for block in blocks:\n",
    "        action = block[1].strip()\n",
    "        if action in actions:\n",
    "            actions[action] += 1\n",
    "    \n",
    "    return actions\n",
    "\n",
    "# Function to parse edit script files and count edit actions\n",
    "def parse_edit_script(file_path):\n",
    "    with open(file_path, 'r') as file:\n",
    "        content = file.read()\n",
    "    actions = {action: 0 for action in all_present_actions}\n",
    "    action_counts = count_file_content(content.split('\\n'), actions)\n",
    "    return action_counts\n",
    "\n",
    "# Creating a dataframe with action counts\n",
    "edit_script_data = []\n",
    "for filename in os.listdir(folder_path):\n",
    "    if filename.endswith(\".md\"):\n",
    "        file_path = os.path.join(folder_path, filename)\n",
    "        action_counts = parse_edit_script(file_path)\n",
    "        edit_script_data.append({'id': int(filename.split('_')[0]), **action_counts})\n",
    "\n",
    "edit_script_df = pd.DataFrame(edit_script_data).fillna(0)\n",
    "\n",
    "edit_script_df['ratio-node'] = 1/(edit_script_df['insert-node'] / edit_script_df['delete-node'])\n",
    "edit_script_df['ratio-tree'] = 1/(edit_script_df['insert-tree'] / edit_script_df['delete-tree'])\n",
    "edit_script_df = edit_script_df.replace([np.inf, -np.inf], np.nan).fillna(0)\n",
    "\n",
    "# Merge the two dataframes on 'id'\n",
    "merged_df = pd.merge(edit_script_df, refactoring_df, on='id')\n",
    "\n",
    "# Create a binary label for refactoring presence\n",
    "for refactoring in refactorings:\n",
    "    merged_df[f'{refactoring}_Label'] = merged_df[refactoring] > 0\n",
    "\n",
    "# Train and evaluate a RandomForestClassifier for each refactoring\n",
    "clfs = {}\n",
    "cms = {}\n",
    "accs = {}\n",
    "summary = {}\n",
    "\n",
    "for refactoring in refactorings:\n",
    "    features = all_present_actions + ['ratio-node', 'ratio-tree']\n",
    "    target = f'{refactoring}_Label'\n",
    "\n",
    "    X = merged_df[features]\n",
    "    y = merged_df[target]\n",
    "\n",
    "    # skip refactoring types with less than 10 samples\n",
    "    if y.sum() < 10:\n",
    "        print(f\"Skipping {refactoring} due to low sample count\")\n",
    "        continue\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=17, stratify=y, test_size=0.4)\n",
    "\n",
    "    # Apply SMOTE to the training data\n",
    "    smote = SMOTE(random_state=17)\n",
    "    X_train_balanced, y_train_balanced = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "    clf = RandomForestClassifier(n_estimators=100, random_state=17)\n",
    "    clf.fit(X_train, y_train)\n",
    "\n",
    "    y_pred = clf.predict(X_test)\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "\n",
    "    if cm.shape == (1, 1):\n",
    "        cm = np.array([[cm[0][0], 0], [0, 0]])\n",
    "\n",
    "    clfs[refactoring] = clf\n",
    "    cms[refactoring] = cm\n",
    "    accs[refactoring] = acc\n",
    "    summary[refactoring] = [acc, *cm.ravel()]\n",
    "\n",
    "# Save the results\n",
    "with open('cluster_results\\\\classification_accuracy.txt', 'w') as f:\n",
    "    f.write(str(accs))\n",
    "with open('cluster_results\\\\classification_summary.pkl', 'wb') as f:\n",
    "    pickle.dump(summary, f)\n",
    "\n",
    "print(\"\\nAccuracy  and TN/TP/FN/FP for each refactoring type:\")\n",
    "for ref in accs:\n",
    "    print(f\"{ref}: {round(accs[ref],3)} -- TN/TP/FN/FP : {cms[ref][0][0]}/{cms[ref][1][1]}/{cms[ref][1][0]}/{cms[ref][0][1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grids = {\n",
    "    'RandomForest': {'n_estimators': [100, 200], 'max_depth': [None, 10, 20]},\n",
    "    'SVM': {'C': [0.1, 1, 10], 'kernel': ['linear', 'rbf']},\n",
    "    'LogisticRegression': {'C': [0.1, 1, 10]}\n",
    "}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
