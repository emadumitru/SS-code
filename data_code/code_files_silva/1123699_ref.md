

File: blueflood-core/src/integration-test/java/com/rackspacecloud/blueflood/cache/MetadataCacheIntegrationTest.java
/*
 * Copyright 2015 Rackspace
 *
 *    Licensed under the Apache License, Version 2.0 (the "License");
 *    you may not use this file except in compliance with the License.
 *    You may obtain a copy of the License at
 *
 *        http://www.apache.org/licenses/LICENSE-2.0
 *
 *    Unless required by applicable law or agreed to in writing, software
 *    distributed under the License is distributed on an "AS IS" BASIS,
 *    WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 *    See the License for the specific language governing permissions and
 *    limitations under the License.
 */

package com.rackspacecloud.blueflood.cache;

import com.google.common.base.Supplier;
import com.google.common.collect.HashBasedTable;
import com.google.common.collect.Maps;
import com.google.common.collect.Table;
import com.google.common.collect.Tables;
import com.rackspacecloud.blueflood.io.AstyanaxMetadataIO;
import com.rackspacecloud.blueflood.io.MetadataIO;
import com.rackspacecloud.blueflood.service.Configuration;
import com.rackspacecloud.blueflood.service.CoreConfig;
import com.rackspacecloud.blueflood.types.Locator;
import com.rackspacecloud.blueflood.io.IntegrationTestBase;
import com.rackspacecloud.blueflood.types.MetricMetadata;
import com.rackspacecloud.blueflood.utils.TimeValue;
import org.junit.Assert;
import org.junit.Test;
import org.junit.runner.RunWith;
import org.junit.runners.Parameterized;
import com.rackspacecloud.blueflood.utils.InMemoryMetadataIO;

import java.io.DataInputStream;
import java.io.DataOutputStream;
import java.io.File;
import java.io.FileInputStream;
import java.io.FileOutputStream;
import java.io.IOException;
import java.util.*;
import java.util.concurrent.TimeUnit;

@RunWith(Parameterized.class)
public class MetadataCacheIntegrationTest extends IntegrationTestBase {

    private final MetadataIO io;
    
    public MetadataCacheIntegrationTest(MetadataIO io) {
        this.io = io;
    }

    @Override
    public void setUp() throws Exception {
        super.setUp();
        
        // equivalent of database truncate.
        if (io instanceof InMemoryMetadataIO) {
            ((InMemoryMetadataIO)io).backingTable.clear();
        }
    }
    
    @Test
    public void testPut() throws Exception {
        assertNumberOfRows("metrics_metadata", 0);
        
        MetadataCache cache = MetadataCache.createLoadingCacheInstance(new TimeValue(5, TimeUnit.MINUTES), 1);
        cache.setIO(io);
        Locator loc1 = Locator.createLocatorFromPathComponents("acOne", "ent", "chk", "mz", "met");
        Locator loc2 = Locator.createLocatorFromPathComponents("acTwo", "ent", "chk", "mz", "met");
        cache.put(loc1, "metaA", "some string");
        cache.put(loc1, "metaB", "fooz");
        cache.put(loc1, "metaC", "some other string");

        if (io instanceof AstyanaxMetadataIO)
            assertNumberOfRows("metrics_metadata", 1);
        else
            Assert.assertEquals(1, io.getNumberOfRowsTest());
        
        cache.put(loc2, "metaA", "hello");
        
        if (io instanceof AstyanaxMetadataIO)
            assertNumberOfRows("metrics_metadata", 2);
        else
            Assert.assertEquals(2, io.getNumberOfRowsTest());
    }


    @Test
    public void testGetNull() throws Exception {
        Locator loc1 = Locator.createLocatorFromPathComponents("acOne", "ent", "chk", "mz", "met");
        MetadataCache cache1 = MetadataCache.createLoadingCacheInstance(new TimeValue(5, TimeUnit.MINUTES), 1);
        cache1.setIO(io);
        Assert.assertNull(cache1.get(loc1, "foo"));
        Assert.assertNull(cache1.get(loc1, "foo"));
    }

    @Test
    public void testCollisions() throws Exception {
        Locator loc1 = Locator.createLocatorFromPathComponents("ac76PeGPSR", "entZ4MYd1W", "chJ0fvB5Ao", "mzord", "truncated"); // put unit of bytes
        Locator loc2 = Locator.createLocatorFromPathComponents("acTmPLSgfv", "enLctkAMeN", "chQwBe5YiE", "mzdfw", "cert_end_in"); // put type of I

        MetadataCache cache = MetadataCache.getInstance();
        cache.setIO(io);

        cache.put(loc1, MetricMetadata.UNIT.name().toLowerCase(), "foo");
        String str = cache.get(loc2, MetricMetadata.TYPE.name().toLowerCase(), String.class);
        Assert.assertEquals(str, null); // This catches a bug where the hashCode of these two cache keys is identical. (loc2 type == loc1 unit)
    }

    @Test
    public void testGet() throws Exception {
        Locator loc1 = Locator.createLocatorFromPathComponents("acOne", "ent", "chk", "mz", "met");
        MetadataCache cache1 = MetadataCache.createLoadingCacheInstance(new TimeValue(5, TimeUnit.MINUTES), 1);
        MetadataCache cache2 = MetadataCache.createLoadingCacheInstance(new TimeValue(5, TimeUnit.MINUTES), 1);
        
        cache1.setIO(io);
        cache2.setIO(io);
        
        // put in one, read in both.
        Class<String> expectedClass = String.class;
        String expected = "expected";

        String key = "metaA";
        cache1.put(loc1, key, expected);
        Assert.assertEquals(expected, cache1.get(loc1, key, expectedClass));
        Assert.assertEquals(expected, cache2.get(loc1, key, expectedClass));
        
        // update in one verify can only new value there.
        expected = "different expected";
        Assert.assertFalse(expected.equals(cache1.get(loc1, key, expectedClass)));
        cache1.put(loc1, key, expected);
        Assert.assertEquals(expected, cache1.get(loc1, key, expectedClass));
        
        // cache2 has old value that is unexpired. invalidate and read new value.
        Assert.assertFalse(expected.equals(cache2.get(loc1, key, expectedClass)));
        cache2.invalidate(loc1, key);
        Assert.assertEquals(expected, cache2.get(loc1, key, expectedClass));
        
        // re-read on invalidate.
        cache1.invalidate(loc1, key);
        Assert.assertFalse(cache1.containsKey(loc1, key));
        Assert.assertEquals(expected, cache1.get(loc1, key));
    }

    @Test
    public void testPutsAreNotDuplicative() throws Exception {
        Locator loc1 = Locator.createLocatorFromPathComponents("acOne", "ent", "chk", "mz", "met");
        MetadataCache cache1 = MetadataCache.createLoadingCacheInstance(new TimeValue(5, TimeUnit.MINUTES), 1);
        cache1.setIO(io);
        String key = "metaA";
        String v1 = new String("Hello");
        String v2 = new String("Hello");
        
        Assert.assertTrue(v1 != v2);
        Assert.assertEquals(v1, v2);
        Assert.assertTrue(cache1.put(loc1, key, v1));
        Assert.assertFalse(cache1.put(loc1, key, v2));
    }

    @Test
    public void testExpiration() throws Exception {
        Locator loc1 = Locator.createLocatorFromPathComponents("acOne", "ent.chk.mz.met");

        MetadataCache cache1 = MetadataCache.createLoadingCacheInstance(new TimeValue(5, TimeUnit.MINUTES), 1);
        MetadataCache cache2 = MetadataCache.createLoadingCacheInstance(new TimeValue(3, TimeUnit.SECONDS), 1);
        
        cache1.setIO(io);
        cache2.setIO(io);
        
        // update in 1, should read out of both.
        Class<String> expectedClass = String.class;
        String expected = "Hello";
        String key = "metaA";
        cache1.put(loc1, key, expected);
        Assert.assertEquals(expected, cache1.get(loc1, key, expectedClass));
        Assert.assertEquals(expected, cache2.get(loc1, key, expectedClass));
        
        // update cache1, but not cache2.
        expected = "Hello2";
        Assert.assertFalse(expected.equals(cache1.get(loc1, key, expectedClass)));
        cache1.put(loc1, key, expected);
        Assert.assertEquals(expected, cache1.get(loc1, key, expectedClass));
        // verify that 2 has old value.
        Assert.assertFalse(expected.equals(cache2.get(loc1, key, expectedClass)));
        
        // wait for expiration, then verify that new value is picked up.
        Thread.sleep(4000);
        Assert.assertEquals(expected, cache2.get(loc1, key, expectedClass));
    }

    @Test
    public void testTypedGet() throws Exception {
        MetadataCache cache = MetadataCache.createLoadingCacheInstance(new TimeValue(5, TimeUnit.MINUTES), 1);
        cache.setIO(io);
        Locator loc1 = Locator.createLocatorFromPathComponents("acOne", "ent", "chk", "mz", "met");
        String expectedString = "expected";
        
        cache.put(loc1, "str", expectedString);

        Assert.assertEquals(expectedString, cache.get(loc1, "str", String.class));
    }
    
    @Test
    public void testIOReplacement() throws Exception {
        
        // create the replacement IO.
        final MetadataIO mapIO = new InMemoryMetadataIO();
        final MetadataIO astIO = new AstyanaxMetadataIO();
        
        final MetadataCache cache = MetadataCache.createLoadingCacheInstance();
        cache.setIO(astIO);
        
        // DO NOT SET USING LOCAL IO INSTANCE!!!!
        
        // put an get a value with the old IO
        Locator loc = Locator.createLocatorFromPathComponents("io_replacment", "a", "b", "c");
        Assert.assertNull(cache.get(loc, "foo"));
        cache.put(loc, "foo", "bar");
        Assert.assertNotNull(cache.get(loc, "foo"));
        Assert.assertEquals("bar", cache.get(loc, "foo"));
        
        // replace the IO, ensure there is nothing there, do a put and get, verify they are different than from before.
        cache.setIO(mapIO);
        Assert.assertNull(cache.get(loc, "foo"));
        cache.put(loc, "foo", "baz");
        Assert.assertNotNull(cache.get(loc, "foo"));
        Assert.assertEquals("baz", cache.get(loc, "foo"));
        
        // put the old IO back. this should result in the old value being read from the cache.
        cache.setIO(astIO);
        Assert.assertEquals("bar", cache.get(loc, "foo"));
    }
    
    @Test
    public void testPersistence() throws Exception {
        MetadataCache cache0 = MetadataCache.createLoadingCacheInstance();
        cache0.setIO(new InMemoryMetadataIO());
        
        Locator l0 = Locator.createLocatorFromPathComponents("1", "a", "b");
        Locator l1 = Locator.createLocatorFromPathComponents("1", "c", "d");
        cache0.put(l0, "foo" , "l0_foo");
        cache0.put(l0, "bar", "l0_bar");
        cache0.put(l1, "zee", "zzzzz");
        
        File f = File.createTempFile("metadatacache_persistence", "txt");
        f.deleteOnExit();
        DataOutputStream out = new DataOutputStream(new FileOutputStream(f, false));
        
        cache0.save(out);
        out.close();
        
        MetadataCache cache1 = MetadataCache.createLoadingCacheInstance();
        cache1.setIO(new InMemoryMetadataIO());
        
        // verify nothing is in the cache.
        Assert.assertNull(cache1.get(l0, "foo"));
        Assert.assertNull(cache1.get(l0, "bar"));
        Assert.assertNull(cache1.get(l1, "zee"));
        
        // now load it.
        DataInputStream in = new DataInputStream(new FileInputStream(f));
        cache1.load(in);
        
        Assert.assertEquals("l0_foo", cache1.get(l0, "foo"));
        Assert.assertEquals("l0_bar", cache1.get(l0, "bar"));
        Assert.assertEquals("zzzzz", cache1.get(l1, "zee"));
    }
    

    @Parameterized.Parameters
    public static Collection<Object[]> getIOs() {
        List<Object[]> ios = new ArrayList<Object[]>();
        ios.add(new Object[] { new AstyanaxMetadataIO() });
        ios.add(new Object[] { new InMemoryMetadataIO() });
        return ios;
    }
}


File: blueflood-core/src/integration-test/java/com/rackspacecloud/blueflood/io/AstyanaxReaderIntegrationTest.java
/*
 * Copyright 2015 Rackspace
 *
 *    Licensed under the Apache License, Version 2.0 (the "License");
 *    you may not use this file except in compliance with the License.
 *    You may obtain a copy of the License at
 *
 *        http://www.apache.org/licenses/LICENSE-2.0
 *
 *    Unless required by applicable law or agreed to in writing, software
 *    distributed under the License is distributed on an "AS IS" BASIS,
 *    WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 *    See the License for the specific language governing permissions and
 *    limitations under the License.
 */

package com.rackspacecloud.blueflood.io;

import com.netflix.astyanax.serializers.AbstractSerializer;
import com.netflix.astyanax.serializers.BooleanSerializer;
import com.netflix.astyanax.serializers.StringSerializer;
import com.rackspacecloud.blueflood.cache.MetadataCache;
import com.rackspacecloud.blueflood.outputs.formats.MetricData;
import com.rackspacecloud.blueflood.rollup.Granularity;
import com.rackspacecloud.blueflood.types.*;
import org.junit.Assert;
import org.junit.Test;

import java.util.ArrayList;
import java.util.List;
import java.util.Map;

public class AstyanaxReaderIntegrationTest extends IntegrationTestBase {
    
    @Test
    public void testCanReadNumeric() throws Exception {
        Metric metric = writeMetric("long_metric", 74L);
        AstyanaxReader reader = AstyanaxReader.getInstance();

        final Locator locator = metric.getLocator();
        MetricData res = reader.getDatapointsForRange(locator, new Range(metric.getCollectionTime() - 100000,
                metric.getCollectionTime() + 100000), Granularity.FULL);
        int numPoints = res.getData().getPoints().size();
        Assert.assertTrue(numPoints > 0);

        // Test that the RangeBuilder is end-inclusive on the timestamp.
        res = reader.getDatapointsForRange(locator, new Range(metric.getCollectionTime() - 100000,
                metric.getCollectionTime()), Granularity.FULL);
        Assert.assertEquals(numPoints, res.getData().getPoints().size());
    }

    @Test
    public void testCanReadString() throws Exception {
        Metric metric = writeMetric("string_metric", "version 1.0.43342346");
        final Locator locator = metric.getLocator();

        AstyanaxReader reader = AstyanaxReader.getInstance();
        MetricData res = reader.getDatapointsForRange(locator, new Range(metric.getCollectionTime() - 100000,
                metric.getCollectionTime() + 100000), Granularity.FULL);
        Assert.assertTrue(res.getData().getPoints().size() > 0);
    }

    @Test
    public void testCanReadMetadata() throws Exception {
        Locator loc1 = Locator.createLocatorFromPathComponents("acOne", "ent", "ch", "mz", "met");
        AstyanaxWriter writer = AstyanaxWriter.getInstance();
        AstyanaxReader reader = AstyanaxReader.getInstance();
        writer.writeMetadataValue(loc1, "foo", "bar");
        Assert.assertEquals("bar", reader.getMetadataValues(loc1).get("foo").toString());
    }

    @Test
    public void testBatchedReads() throws Exception {
        // Write metrics and also persist their types.
        List<Locator> locatorList = new ArrayList<Locator>();
        Metric metric = writeMetric("string_metric", "version 1.0.43342346");
        MetadataCache.getInstance().put(metric.getLocator(), MetricMetadata.TYPE.name().toLowerCase(), DataType.STRING.toString());
        locatorList.add(metric.getLocator());

        metric = writeMetric("int_metric", 45);
        MetadataCache.getInstance().put(metric.getLocator(), MetricMetadata.TYPE.name().toLowerCase(), DataType.NUMERIC.toString());
        locatorList.add(metric.getLocator());

        metric = writeMetric("long_metric", 67L);
        MetadataCache.getInstance().put(metric.getLocator(), MetricMetadata.TYPE.name().toLowerCase(), DataType.NUMERIC.toString());
        locatorList.add(metric.getLocator());

        // Test batch reads
        AstyanaxReader reader = AstyanaxReader.getInstance();
        Map<Locator, MetricData> results = reader.getDatapointsForRange(locatorList, new Range(metric.getCollectionTime() - 100000,
                metric.getCollectionTime() + 100000), Granularity.FULL);

        Assert.assertEquals(locatorList.size(), results.size());

        for (Locator locator : locatorList) {
            MetricData metrics = results.get(locator);
            Assert.assertEquals(1, metrics.getData().getPoints().size());
        }
    }

    @Test
    public void testCanRetrieveNumericMetricsEvenIfNoMetaDataStored() throws Exception {
        // Write metrics and also persist their types.
        List<Locator> locatorList = new ArrayList<Locator>();
        Metric metric = writeMetric("string_metric", "version 1.0.43342346");
        MetadataCache.getInstance().put(metric.getLocator(), MetricMetadata.TYPE.name().toLowerCase(), DataType.STRING.toString());
        locatorList.add(metric.getLocator());

        metric = writeMetric("int_metric", 45);
        locatorList.add(metric.getLocator());

        metric = writeMetric("long_metric", 67L);
        locatorList.add(metric.getLocator());

        // Test batch reads
        AstyanaxReader reader = AstyanaxReader.getInstance();
        Map<Locator, MetricData> results = reader.getDatapointsForRange(locatorList, new Range(metric.getCollectionTime() - 100000,
                metric.getCollectionTime() + 100000), Granularity.FULL);

        Assert.assertEquals(locatorList.size(), results.size());

        for (Locator locator : locatorList) {
            MetricData metrics = results.get(locator);
            Assert.assertEquals(1, metrics.getData().getPoints().size());
        }
    }

    @Test
    public void test_StringMetrics_WithoutMetadata_NotRetrieved() throws Exception {
        List<Locator> locatorList = new ArrayList<Locator>();
        Metric metric = writeMetric("string_metric_1", "version 1.0.43342346");
        locatorList.add(metric.getLocator());

        // Test batch reads
        AstyanaxReader reader = AstyanaxReader.getInstance();
        Map<Locator, MetricData> results = reader.getDatapointsForRange(locatorList, new Range(metric.getCollectionTime() - 100000,
                metric.getCollectionTime() + 100000), Granularity.FULL);

        Assert.assertEquals(1, results.size());
        Assert.assertTrue(results.get(metric.getLocator()).getData().isEmpty());
    }

    @Test
    public void testNullRollupType_DoesNotReturn_StringOrBooleanSerializers() {
        AstyanaxReader reader = AstyanaxReader.getInstance();

        AbstractSerializer serializer = reader.serializerFor(null, DataType.INT, Granularity.MIN_5);

        Assert.assertTrue(serializer != null);
        Assert.assertFalse(serializer instanceof StringSerializer);
        Assert.assertFalse(serializer instanceof BooleanSerializer);
    }

    @Test
    public void testNullDataType_DoesNotReturn_StringOrBooleanSerializers() {
        AstyanaxReader reader = AstyanaxReader.getInstance();

        AbstractSerializer serializer = reader.serializerFor(null, null, Granularity.MIN_5);

        Assert.assertTrue(serializer != null);
        Assert.assertFalse(serializer instanceof StringSerializer);
        Assert.assertFalse(serializer instanceof BooleanSerializer);
    }
}


File: blueflood-core/src/integration-test/java/com/rackspacecloud/blueflood/io/AstyanaxWriterIntegrationTest.java
/*
 * Copyright 2015 Rackspace
 *
 *    Licensed under the Apache License, Version 2.0 (the "License");
 *    you may not use this file except in compliance with the License.
 *    You may obtain a copy of the License at
 *
 *        http://www.apache.org/licenses/LICENSE-2.0
 *
 *    Unless required by applicable law or agreed to in writing, software
 *    distributed under the License is distributed on an "AS IS" BASIS,
 *    WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 *    See the License for the specific language governing permissions and
 *    limitations under the License.
 */

package com.rackspacecloud.blueflood.io;

import com.rackspacecloud.blueflood.types.Locator;
import org.junit.Test;

public class AstyanaxWriterIntegrationTest extends IntegrationTestBase {

    @Test
    public void testEnsureStringMetricsDoNotEndUpInNumericSpace() throws Exception {
        assertNumberOfRows("metrics_string", 0);
        assertNumberOfRows("metrics_full", 0);
        assertNumberOfRows("metrics_locator", 0);

        writeMetric("string_metric", "This is a string test");
        
        assertNumberOfRows("metrics_string", 1);
        assertNumberOfRows("metrics_full", 0);
        assertNumberOfRows("metrics_locator", 0);
    }

    @Test
    public void testEnsureNumericMetricsDoNotEndUpInStringSpaces() throws Exception {
        assertNumberOfRows("metrics_string", 0);
        assertNumberOfRows("metrics_full", 0);
        assertNumberOfRows("metrics_locator", 0);

        writeMetric("long_metric", 64L);
        
        assertNumberOfRows("metrics_string", 0);
        assertNumberOfRows("metrics_full", 1);
        assertNumberOfRows("metrics_locator", 1);
    }

    @Test
    public void testMetadataGetsWritten() throws Exception {
        assertNumberOfRows("metrics_metadata", 0);

        Locator loc1 = Locator.createLocatorFromPathComponents("acONE", "entityId", "checkId", "mz", "metric");
        Locator loc2 = Locator.createLocatorFromPathComponents("acTWO", "entityId", "checkId", "mz", "metric");
        AstyanaxWriter writer = AstyanaxWriter.getInstance();

        // multiple cols on a single locator should produce a single row.
//        writer.writeMetadataValue(loc1, "a", new byte[]{1,2,3,4,5});
//        writer.writeMetadataValue(loc1, "b", new byte[]{6,7,8,9,0});
//        writer.writeMetadataValue(loc1, "c", new byte[]{11,22,33,44,55,66});
//        writer.writeMetadataValue(loc1, "d", new byte[]{-1,-2,-3,-4});
//        writer.writeMetadataValue(loc1, "e", new byte[]{1,2,3,4,5});
//        writer.writeMetadataValue(loc1, "f", new byte[]{1,2,3,4,5,6,7,8,9,0});
        writer.writeMetadataValue(loc1, "a", "Some1String");
        writer.writeMetadataValue(loc1, "b", "Some2String");
        writer.writeMetadataValue(loc1, "c", "Some3String");
        writer.writeMetadataValue(loc1, "d", "Some4String");
        writer.writeMetadataValue(loc1, "e", "Some5String");
        writer.writeMetadataValue(loc1, "f", "Some6String");

        assertNumberOfRows("metrics_metadata", 1);

        // new locator means new row.
        writer.writeMetadataValue(loc2, "a", "strrrrring");
        assertNumberOfRows("metrics_metadata", 2);
    }
}


File: blueflood-core/src/integration-test/java/com/rackspacecloud/blueflood/service/MetricsIntegrationTest.java
/*
 * Copyright 2015 Rackspace
 *
 *    Licensed under the Apache License, Version 2.0 (the "License");
 *    you may not use this file except in compliance with the License.
 *    You may obtain a copy of the License at
 *
 *        http://www.apache.org/licenses/LICENSE-2.0
 *
 *    Unless required by applicable law or agreed to in writing, software
 *    distributed under the License is distributed on an "AS IS" BASIS,
 *    WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 *    See the License for the specific language governing permissions and
 *    limitations under the License.
 */

package com.rackspacecloud.blueflood.service;

import com.google.common.collect.Lists;
import com.netflix.astyanax.MutationBatch;
import com.netflix.astyanax.connectionpool.exceptions.ConnectionException;
import com.netflix.astyanax.model.ColumnFamily;
import com.rackspacecloud.blueflood.io.AstyanaxReader;
import com.rackspacecloud.blueflood.io.AstyanaxWriter;
import com.rackspacecloud.blueflood.io.CassandraModel;
import com.rackspacecloud.blueflood.io.IntegrationTestBase;
import com.rackspacecloud.blueflood.outputs.formats.MetricData;
import com.rackspacecloud.blueflood.rollup.Granularity;
import com.rackspacecloud.blueflood.types.*;
import com.rackspacecloud.blueflood.utils.TimeValue;
import com.rackspacecloud.blueflood.utils.Util;
import org.junit.Assert;
import org.junit.Test;
import org.mockito.internal.util.reflection.Whitebox;

import java.io.IOException;
import java.util.*;
import java.util.concurrent.TimeUnit;

/**
 * Some of these tests here were horribly contrived to mimic behavior in Writer. The problem with this approach is that
 * when logic in Writer changes, these tests can break unless the logic is changed here too. */
public class MetricsIntegrationTest extends IntegrationTestBase {

    private static boolean areStringMetricsDropped = Configuration.getInstance().getBooleanProperty(CoreConfig.STRING_METRICS_DROPPED);
    // returns a collection all checks that were written at some point.
    // this was a lot cooler back when the slot changed with time.
    private Collection<Locator> writeLocatorsOnly(int hours) throws Exception {
        // duplicate the logic from Writer.writeFull() that inserts locator rows.
        final String tenantId = "ac" + randString(8);
        final List<Locator> locators = new ArrayList<Locator>();
        for (int i = 0; i < hours; i++) {
            locators.add(Locator.createLocatorFromPathComponents(tenantId, "test:locator:inserts:" + i));
        }

        AstyanaxTester at = new AstyanaxTester();
        MutationBatch mb = at.createMutationBatch();

        for (Locator locator : locators) {
            int shard = Util.computeShard(locator.toString());
            mb.withRow(at.getLocatorCF(), (long)shard)
                    .putColumn(locator, "", 100000);
        }
        mb.execute();

        return locators;
    }

    private void writeFullData(
            Locator locator,
            long baseMillis, 
            int hours,
            AstyanaxWriter writer) throws Exception {
        // insert something every minute for 48h
        for (int i = 0; i < 60 * hours; i++) {
            final long curMillis = baseMillis + i * 60000;
            List<Metric> metrics = new ArrayList<Metric>();
            metrics.add(getRandomIntMetric(locator, curMillis));
            writer.insertFull(metrics);
        }
    }

    @Test
    public void testLocatorsWritten() throws Exception {
        Collection<Locator> locators = writeLocatorsOnly(48);
        AstyanaxReader r = AstyanaxReader.getInstance();

        Set<String> actualLocators = new HashSet<String>();
        for (Locator locator : locators) {
            for (Locator databaseLocator : r.getLocatorsToRollup(Util.computeShard(locator.toString()))) {
                actualLocators.add(databaseLocator.toString());
            }
        }
        Assert.assertEquals(48, actualLocators.size());
    }

    @Test
    public void testRollupGenerationSimple() throws Exception {
        AstyanaxWriter writer = AstyanaxWriter.getInstance();
        AstyanaxReader reader = AstyanaxReader.getInstance();
        final long baseMillis = 1333635148000L; // some point during 5 April 2012.
        int hours = 48;
        final String acctId = "ac" + IntegrationTestBase.randString(8);
        final String metricName = "fooService,barServer," + randString(8);
        final long endMillis = baseMillis + (1000 * 60 * 60 * hours);
        final Locator locator = Locator.createLocatorFromPathComponents(acctId, metricName);

        writeFullData(locator, baseMillis, hours, writer);

        // FULL -> 5m
        ArrayList<SingleRollupWriteContext> writes = new ArrayList<SingleRollupWriteContext>();
        for (Range range : Range.getRangesToRollup(Granularity.FULL, baseMillis, endMillis)) {
            // each range should produce one average
            Points<SimpleNumber> input = reader.getDataToRoll(SimpleNumber.class, locator, range, CassandraModel.CF_METRICS_FULL);
            BasicRollup basicRollup = BasicRollup.buildRollupFromRawSamples(input);
            HistogramRollup histogramRollup = HistogramRollup.buildRollupFromRawSamples(input);

            writes.add(new SingleRollupWriteContext(basicRollup,
                    locator,
                    Granularity.FULL.coarser(),
                    CassandraModel.getColumnFamily(BasicRollup.class, Granularity.FULL.coarser()),
                    range.start));
            writes.add(new SingleRollupWriteContext(histogramRollup,
                    locator,
                    Granularity.FULL.MIN_5,
                    CassandraModel.getColumnFamily(HistogramRollup.class, Granularity.MIN_5),
                    range.start));
        }
        writer.insertRollups(writes);

        // 5m -> 20m
        writes.clear();

        for (Range range : Range.getRangesToRollup(Granularity.MIN_5, baseMillis, endMillis)) {
            Points<BasicRollup> input = reader.getDataToRoll(BasicRollup.class, locator, range,
                    CassandraModel.getColumnFamily(BasicRollup.class, Granularity.MIN_5));
            BasicRollup basicRollup = BasicRollup.buildRollupFromRollups(input);
            writes.add(new SingleRollupWriteContext(basicRollup,
                    locator,
                    Granularity.MIN_5.coarser(),
                    CassandraModel.getColumnFamily(BasicRollup.class, Granularity.MIN_5.coarser()),
                    range.start));

            Points<HistogramRollup> histInput = reader.getDataToRoll(HistogramRollup.class, locator, range,
                    CassandraModel.getColumnFamily(HistogramRollup.class, Granularity.MIN_5));
            HistogramRollup histogramRollup = HistogramRollup.buildRollupFromRollups(histInput);
            writes.add(new SingleRollupWriteContext(histogramRollup,
                    locator,
                    Granularity.MIN_20,
                    CassandraModel.getColumnFamily(HistogramRollup.class, Granularity.MIN_20),
                    range.start));
        }
        writer.insertRollups(writes);

        // 20m -> 60m
        writes.clear();
        for (Range range : Range.getRangesToRollup(Granularity.MIN_20, baseMillis, endMillis)) {
            Points<BasicRollup> input = reader.getDataToRoll(BasicRollup.class, locator, range,
                    CassandraModel.getColumnFamily(BasicRollup.class, Granularity.MIN_20));
            BasicRollup basicRollup = BasicRollup.buildRollupFromRollups(input);
            writes.add(new SingleRollupWriteContext(basicRollup,
                    locator,
                    Granularity.MIN_20.coarser(),
                    CassandraModel.getColumnFamily(BasicRollup.class, Granularity.MIN_20.coarser()),
                    range.start));

            Points<HistogramRollup> histInput = reader.getDataToRoll(HistogramRollup.class, locator, range,
                    CassandraModel.getColumnFamily(HistogramRollup.class, Granularity.MIN_5));
            HistogramRollup histogramRollup = HistogramRollup.buildRollupFromRollups(histInput);
            writes.add(new SingleRollupWriteContext(histogramRollup,
                    locator,
                    Granularity.MIN_60,
                    CassandraModel.getColumnFamily(HistogramRollup.class, Granularity.MIN_60),
                    range.start));
        }
        writer.insertRollups(writes);

        // 60m -> 240m
        writes.clear();
        for (Range range : Range.getRangesToRollup(Granularity.MIN_60, baseMillis, endMillis)) {
            Points<BasicRollup> input = reader.getDataToRoll(BasicRollup.class, locator, range,
                    CassandraModel.getColumnFamily(BasicRollup.class, Granularity.MIN_60));

            BasicRollup basicRollup = BasicRollup.buildRollupFromRollups(input);
            writes.add(new SingleRollupWriteContext(basicRollup,
                    locator,
                    Granularity.MIN_60.coarser(),
                    CassandraModel.getColumnFamily(BasicRollup.class, Granularity.MIN_60.coarser()),
                    range.start));

            Points<HistogramRollup> histInput = reader.getDataToRoll(HistogramRollup.class, locator, range,
                    CassandraModel.getColumnFamily(HistogramRollup.class, Granularity.MIN_5));
            HistogramRollup histogramRollup = HistogramRollup.buildRollupFromRollups(histInput);
            writes.add(new SingleRollupWriteContext(histogramRollup,
                    locator,
                    Granularity.MIN_240,
                    CassandraModel.getColumnFamily(HistogramRollup.class, Granularity.MIN_240),
                    range.start));
        }
        writer.insertRollups(writes);

        // 240m -> 1440m
        writes.clear();
        for (Range range : Range.getRangesToRollup(Granularity.MIN_240, baseMillis, endMillis)) {
            Points<BasicRollup> input = reader.getDataToRoll(BasicRollup.class, locator, range,
                    CassandraModel.getColumnFamily(BasicRollup.class, Granularity.MIN_240));
            BasicRollup basicRollup = BasicRollup.buildRollupFromRollups(input);
            writes.add(new SingleRollupWriteContext(basicRollup,
                    locator,
                    Granularity.MIN_240.coarser(),
                    CassandraModel.getColumnFamily(BasicRollup.class, Granularity.MIN_240.coarser()),
                    range.start));

            Points<HistogramRollup> histInput = reader.getDataToRoll(HistogramRollup.class, locator, range,
                    CassandraModel.getColumnFamily(HistogramRollup.class, Granularity.MIN_5));
            HistogramRollup histogramRollup = HistogramRollup.buildRollupFromRollups(histInput);
            writes.add(new SingleRollupWriteContext(histogramRollup,
                    locator,
                    Granularity.MIN_1440,
                    CassandraModel.getColumnFamily(HistogramRollup.class, Granularity.MIN_1440),
                    range.start));
        }
        writer.insertRollups(writes);

        // verify the number of points in 48h worth of rollups. 
        Range range = new Range(Granularity.MIN_1440.snapMillis(baseMillis), Granularity.MIN_1440.snapMillis(endMillis + Granularity.MIN_1440.milliseconds()));
        Points<BasicRollup> input = reader.getDataToRoll(BasicRollup.class, locator, range,
                CassandraModel.getColumnFamily(BasicRollup.class, Granularity.MIN_1440));
        BasicRollup basicRollup = BasicRollup.buildRollupFromRollups(input);
        Assert.assertEquals(60 * hours, basicRollup.getCount());

        Points<HistogramRollup> histInput = reader.getDataToRoll(HistogramRollup.class, locator, range,
                CassandraModel.getColumnFamily(HistogramRollup.class, Granularity.MIN_1440));
        HistogramRollup histogramRollup = HistogramRollup.buildRollupFromRollups(histInput);
        Assert.assertTrue(histogramRollup.getBins().size() > 0);
        Assert.assertTrue("Number of bins is " + histogramRollup.getBins().size(),
                histogramRollup.getBins().size() <= HistogramRollup.MAX_BIN_SIZE);
    }

    @Test
    public void testSimpleInsertAndGet() throws Exception {
        AstyanaxWriter writer = AstyanaxWriter.getInstance();
        AstyanaxReader reader = AstyanaxReader.getInstance();
        final long baseMillis = 1333635148000L; // some point during 5 April 2012.
        long lastMillis = baseMillis + (300 * 1000); // 300 seconds.
        final String acctId = "ac" + IntegrationTestBase.randString(8);
        final String metricName = "fooService,barServer," + randString(8);

        final Locator locator  = Locator.createLocatorFromPathComponents(acctId, metricName);

        Set<Long> expectedTimestamps = new HashSet<Long>();
        // insert something every 30s for 5 mins.
        for (int i = 0; i < 10; i++) {
            final long curMillis = baseMillis + (i * 30000); // 30 seconds later.
            expectedTimestamps.add(curMillis);
            List<Metric> metrics = new ArrayList<Metric>();
            metrics.add(getRandomIntMetric(locator, curMillis));
            writer.insertFull(metrics);
        }
        
        Set<Long> actualTimestamps = new HashSet<Long>();
        // get back the cols that were written from start to stop.

        Points<SimpleNumber> points = reader.getDataToRoll(SimpleNumber.class, locator, new Range(baseMillis, lastMillis),
                CassandraModel.getColumnFamily(BasicRollup.class, Granularity.FULL));
        actualTimestamps = points.getPoints().keySet();
        Assert.assertEquals(expectedTimestamps, actualTimestamps);
    }

    @Test
    //In this test, string metrics are configured to be always dropped. So they are not persisted at all.
    public void testStringMetricsIfSoConfiguredAreAlwaysDropped() throws Exception {
        Whitebox.setInternalState(AstyanaxWriter.getInstance(), "areStringMetricsDropped", true);

        AstyanaxWriter writer = AstyanaxWriter.getInstance();
        AstyanaxReader reader = AstyanaxReader.getInstance();
        final long baseMillis = 1333635148000L; // some point during 5 April 2012.
        long lastMillis = baseMillis + (300 * 1000); // 300 seconds.
        final String acctId = "ac" + IntegrationTestBase.randString(8);
        final String metricName = "fooService,barServer," + randString(8);

        final Locator locator  = Locator.createLocatorFromPathComponents(acctId, metricName);

        Set<Long> expectedTimestamps = new HashSet<Long>();
        // insert something every 30s for 5 mins.
        for (int i = 0; i < 10; i++) {
            final long curMillis = baseMillis + (i * 30000); // 30 seconds later.

            expectedTimestamps.add(curMillis);
            List<Metric> metrics = new ArrayList<Metric>();
            metrics.add(makeMetric(locator,curMillis,getRandomStringMetricValue()));
            writer.insertFull(metrics);
        }

        Set<Long> actualTimestamps = new HashSet<Long>();
        // get back the cols that were written from start to stop.

        MetricData data = reader.getDatapointsForRange(locator, new Range(baseMillis, lastMillis),Granularity.FULL);
        actualTimestamps = data.getData().getPoints().keySet();

        Assert.assertTrue(actualTimestamps.size() == 0);
    }

    @Test
    //In this test, string metrics are configured to be always dropped. So they are not persisted at all.
    public void testStringMetricsIfSoConfiguredAreNotDroppedForKeptTenantIds() throws Exception {
        Whitebox.setInternalState(AstyanaxWriter.getInstance(), "areStringMetricsDropped", true);

        AstyanaxWriter writer = AstyanaxWriter.getInstance();
        AstyanaxReader reader = AstyanaxReader.getInstance();
        final long baseMillis = 1333635148000L; // some point during 5 April 2012.
        long lastMillis = baseMillis + (300 * 1000); // 300 seconds.
        final String acctId = "ac" + IntegrationTestBase.randString(8);
        final String metricName = "fooService,barServer," + randString(8);

        final Locator locator  = Locator.createLocatorFromPathComponents(acctId, metricName);
        HashSet<String> keptTenants = new HashSet<String>();
        keptTenants.add(locator.getTenantId());

        Whitebox.setInternalState(AstyanaxWriter.getInstance(), "keptTenantIdsSet",keptTenants);

        Set<Long> expectedTimestamps = new HashSet<Long>();
        // insert something every 30s for 5 mins.
        for (int i = 0; i < 10; i++) {
            final long curMillis = baseMillis + (i * 30000); // 30 seconds later.

            expectedTimestamps.add(curMillis);
            List<Metric> metrics = new ArrayList<Metric>();
            metrics.add(makeMetric(locator,curMillis,getRandomStringMetricValue()));
            writer.insertFull(metrics);
        }

        Set<Long> actualTimestamps = new HashSet<Long>();
        // get back the cols that were written from start to stop.

        MetricData data = reader.getDatapointsForRange(locator, new Range(baseMillis, lastMillis),Granularity.FULL);
        actualTimestamps = data.getData().getPoints().keySet();

        Assert.assertEquals(expectedTimestamps, actualTimestamps);
    }

    @Test
    //In this test, string metrics are not configured to be dropped so they are persisted.
    public void testStringMetricsIfSoConfiguredArePersistedAsExpected() throws Exception {
        Whitebox.setInternalState(AstyanaxWriter.getInstance(), "areStringMetricsDropped", false);

        AstyanaxWriter writer = AstyanaxWriter.getInstance();
        AstyanaxReader reader = AstyanaxReader.getInstance();
        final long baseMillis = 1333635148000L; // some point during 5 April 2012.
        long lastMillis = baseMillis + (300 * 1000); // 300 seconds.
        final String acctId = "ac" + IntegrationTestBase.randString(8);
        final String metricName = "fooService,barServer," + randString(8);

        final Locator locator  = Locator.createLocatorFromPathComponents(acctId, metricName);

        Set<Long> expectedTimestamps = new HashSet<Long>();
        // insert something every 30s for 5 mins.
        for (int i = 0; i < 10; i++) {
            final long curMillis = baseMillis + (i * 30000); // 30 seconds later.

            expectedTimestamps.add(curMillis);
            List<Metric> metrics = new ArrayList<Metric>();
            metrics.add(makeMetric(locator,curMillis,getRandomStringMetricValue()));
            writer.insertFull(metrics);
        }

        Set<Long> actualTimestamps = new HashSet<Long>();
        // get back the cols that were written from start to stop.

        MetricData data = reader.getDatapointsForRange(locator, new Range(baseMillis, lastMillis),Granularity.FULL);
        actualTimestamps = data.getData().getPoints().keySet();

        Assert.assertEquals(expectedTimestamps, actualTimestamps);
    }

    @Test
    //In this test, we attempt to persist the same value of String Metric every single time. Only the first one is persisted.
    public void testStringMetricsWithSameValueAreNotPersisted() throws Exception {
        Whitebox.setInternalState(AstyanaxWriter.getInstance(), "areStringMetricsDropped", false);

        AstyanaxWriter writer = AstyanaxWriter.getInstance();
        AstyanaxReader reader = AstyanaxReader.getInstance();
        final long baseMillis = 1333635148000L; // some point during 5 April 2012.
        long lastMillis = baseMillis + (300 * 1000); // 300 seconds.
        final String acctId = "ac" + IntegrationTestBase.randString(8);
        final String metricName = "fooService,barServer," + randString(8);

        final Locator locator  = Locator.createLocatorFromPathComponents(acctId, metricName);
        String sameValue = getRandomStringMetricValue();
        Set<Long> expectedTimestamps = new HashSet<Long>();
        // insert something every 30s for 5 mins.
        //value remains the same
        for (int i = 0; i < 10; i++) {
            final long curMillis = baseMillis + (i * 30000); // 30 seconds later.

            expectedTimestamps.add(curMillis);
            List<Metric> metrics = new ArrayList<Metric>();
            metrics.add(makeMetric(locator,curMillis,sameValue));
            writer.insertFull(metrics);
        }

        Set<Long> actualTimestamps = new HashSet<Long>();
        // get back the cols that were written from start to stop.

        MetricData data = reader.getDatapointsForRange(locator, new Range(baseMillis, lastMillis),Granularity.FULL);
        actualTimestamps = data.getData().getPoints().keySet();

        Assert.assertTrue(actualTimestamps.size() == 1);
        for(long ts : actualTimestamps) {
            Assert.assertEquals(ts, baseMillis);
            break;
        }
    }

    @Test
    //In this case, we alternate between two values for a string metric. But since the string metric does not have the same value in two
    //consecutive writes, it's always persisted.
    public void testStringMetricsWithDifferentValuesArePersisted() throws Exception {
        AstyanaxWriter writer = AstyanaxWriter.getInstance();
        AstyanaxReader reader = AstyanaxReader.getInstance();
        final long baseMillis = 1333635148000L; // some point during 5 April 2012.
        long lastMillis = baseMillis + (300 * 1000); // 300 seconds.
        final String acctId = "ac" + IntegrationTestBase.randString(8);
        final String metricName = "fooService,barServer," + randString(8);

        final Locator locator  = Locator.createLocatorFromPathComponents(acctId, metricName);
        String firstValue = getRandomStringMetricValue();
        String secondValue = getRandomStringMetricValue();

        Set<Long> expectedTimestamps = new HashSet<Long>();
        // insert something every 30s for 5 mins.
        //string metric value is alternated.
        for (int i = 0; i < 10; i++) {
            final long curMillis = baseMillis + (i * 30000); // 30 seconds later.
            String value = null;
            if (i % 2 == 0) {
                value = firstValue;
            }
            else {
                value = secondValue;
            }
            expectedTimestamps.add(curMillis);
            List<Metric> metrics = new ArrayList<Metric>();
            metrics.add(makeMetric(locator, curMillis, value));
            writer.insertFull(metrics);
        }

        Set<Long> actualTimestamps = new HashSet<Long>();
        // get back the cols that were written from start to stop.

        MetricData data = reader.getDatapointsForRange(locator, new Range(baseMillis, lastMillis),Granularity.FULL);
        actualTimestamps = data.getData().getPoints().keySet();
        Assert.assertEquals(expectedTimestamps, actualTimestamps);
    }

    @Test
    //Numeric value is always persisted.
    public void testNumericMetricsAreAlwaysPersisted() throws Exception {
        AstyanaxWriter writer = AstyanaxWriter.getInstance();
        AstyanaxReader reader = AstyanaxReader.getInstance();
        final long baseMillis = 1333635148000L; // some point during 5 April 2012.
        long lastMillis = baseMillis + (300 * 1000); // 300 seconds.
        final String acctId = "ac" + IntegrationTestBase.randString(8);
        final String metricName = "fooService,barServer," + randString(8);

        final Locator locator  = Locator.createLocatorFromPathComponents(acctId, metricName);
        int sameValue = getRandomIntMetricValue();
        Set<Long> expectedTimestamps = new HashSet<Long>();
        // insert something every 30s for 5 mins.
        //value of numeric metric remains the same, still it is always persisted
        for (int i = 0; i < 10; i++) {
            final long curMillis = baseMillis + (i * 30000); // 30 seconds later.
            expectedTimestamps.add(curMillis);
            List<Metric> metrics = new ArrayList<Metric>();
            metrics.add(makeMetric(locator, curMillis,sameValue));
            writer.insertFull(metrics);
        }

        Set<Long> actualTimestamps = new HashSet<Long>();
        // get back the cols that were written from start to stop.

        Points<SimpleNumber> points = reader.getDataToRoll(SimpleNumber.class, locator, new Range(baseMillis, lastMillis),
                CassandraModel.getColumnFamily(BasicRollup.class, Granularity.FULL));
        actualTimestamps = points.getPoints().keySet();
        Assert.assertEquals(expectedTimestamps, actualTimestamps);
    }

    @Test
    //In this test, the same value is sent, and the metric is not persisted except for the first time.
    public void testBooleanMetricsWithSameValueAreNotPersisted() throws Exception {
        AstyanaxWriter writer = AstyanaxWriter.getInstance();
        AstyanaxReader reader = AstyanaxReader.getInstance();
        final long baseMillis = 1333635148000L; // some point during 5 April 2012.
        long lastMillis = baseMillis + (300 * 1000); // 300 seconds.
        final String acctId = "ac" + IntegrationTestBase.randString(8);
        final String metricName = "fooService,barServer," + randString(8);

        final Locator locator  = Locator.createLocatorFromPathComponents(acctId, metricName);
        boolean sameValue = true;
        Set<Long> expectedTimestamps = new HashSet<Long>();
        // insert something every 30s for 5 mins.
        for (int i = 0; i < 10; i++) {
            final long curMillis = baseMillis + (i * 30000); // 30 seconds later.
            expectedTimestamps.add(curMillis);
            List<Metric> metrics = new ArrayList<Metric>();
            metrics.add(makeMetric(locator,curMillis,sameValue));
            writer.insertFull(metrics);
        }

        Set<Long> actualTimestamps = new HashSet<Long>();
        // get back the cols that were written from start to stop.

        MetricData data = reader.getDatapointsForRange(locator, new Range(baseMillis, lastMillis),Granularity.FULL);
        actualTimestamps = data.getData().getPoints().keySet();

        Assert.assertTrue(actualTimestamps.size() == 1);
        for(long ts : actualTimestamps) {
            Assert.assertEquals(ts, baseMillis);
            break;
        }
    }

    @Test
    //In this test, we alternately persist true and false. All the boolean metrics are persisted.
    public void testBooleanMetricsWithDifferentValuesArePersisted() throws Exception {
        AstyanaxWriter writer = AstyanaxWriter.getInstance();
        AstyanaxReader reader = AstyanaxReader.getInstance();
        final long baseMillis = 1333635148000L; // some point during 5 April 2012.
        long lastMillis = baseMillis + (300 * 1000); // 300 seconds.
        final String acctId = "ac" + IntegrationTestBase.randString(8);
        final String metricName = "fooService,barServer," + randString(8);

        final Locator locator  = Locator.createLocatorFromPathComponents(acctId, metricName);

        Set<Long> expectedTimestamps = new HashSet<Long>();
        // insert something every 30s for 5 mins.
        for (int i = 0; i < 10; i++) {
            final long curMillis = baseMillis + (i * 30000); // 30 seconds later.
            boolean value;
            if (i % 2 == 0) {
                value = true;
            }
            else {
                value = false;
            }
            expectedTimestamps.add(curMillis);
            List<Metric> metrics = new ArrayList<Metric>();
            metrics.add(makeMetric(locator, curMillis, value));
            writer.insertFull(metrics);
        }

        Set<Long> actualTimestamps = new HashSet<Long>();
        // get back the cols that were written from start to stop.

        MetricData data = reader.getDatapointsForRange(locator, new Range(baseMillis, lastMillis),Granularity.FULL);
        actualTimestamps = data.getData().getPoints().keySet();
        Assert.assertEquals(expectedTimestamps, actualTimestamps);
    }

    @Test
    public void testConsecutiveWriteAndRead() throws ConnectionException, IOException {
        AstyanaxWriter writer = AstyanaxWriter.getInstance();
        AstyanaxReader reader = AstyanaxReader.getInstance();
        final long baseMillis = 1333635148000L;

        final Locator locator = Locator.createLocatorFromPathComponents("ac0001",
                "fooService,fooServer," + randString(8));

        final List<Metric> metrics = new ArrayList<Metric>();
        for (int i = 0; i < 100; i++) {
            final Metric metric = new Metric(locator, i, baseMillis + (i * 1000),
                    new TimeValue(1, TimeUnit.DAYS), "unknown");
            metrics.add(metric);
            writer.insertFull(metrics);
            metrics.clear();
        }

        int count = 0;
            ColumnFamily<Locator, Long> CF_metrics_full = CassandraModel.getColumnFamily(BasicRollup.class, Granularity.FULL);
        Points<SimpleNumber> points = reader.getDataToRoll(SimpleNumber.class, locator,
                new Range(baseMillis, baseMillis + 500000), CF_metrics_full);
        for (Map.Entry<Long, Points.Point<SimpleNumber>> data : points.getPoints().entrySet()) {
            Points.Point<SimpleNumber> point = data.getValue();
            Assert.assertEquals(count, point.getData().getValue());
            count++;
        }
    }

    @Test
    public void testShardStateWriteRead() throws Exception {
        final Collection<Integer> shards = Lists.newArrayList(0, 1, 2, 3, 4, 5, 6, 7, 8, 9);
        AstyanaxWriter writer = AstyanaxWriter.getInstance();

        // Simulate active or running state for all the slots for all granularities.
        for (int shard : shards) {
            Map<Granularity, Map<Integer, UpdateStamp>> allUpdates = new HashMap<Granularity, Map<Integer, UpdateStamp>>();
            for (Granularity granularity : Granularity.rollupGranularities()) {
                Map<Integer, UpdateStamp> updates = new HashMap<Integer, UpdateStamp>();
                for (int slot = 0; slot < granularity.numSlots(); slot++) {
                    updates.put(slot, new UpdateStamp(System.currentTimeMillis() - 10000, UpdateStamp.State.Active,
                            true));
                }
                allUpdates.put(granularity, updates);
            }
            writer.persistShardState(shard, allUpdates);
        }

        // Now simulate rolled up state for all the slots for all granularities.
        for (int shard : shards) {
            Map<Granularity, Map<Integer, UpdateStamp>> allUpdates = new HashMap<Granularity, Map<Integer, UpdateStamp>>();
            for (Granularity granularity : Granularity.rollupGranularities()) {
                Map<Integer, UpdateStamp> updates = new HashMap<Integer, UpdateStamp>();
                for (int slot = 0; slot < granularity.numSlots(); slot++) {
                    updates.put(slot, new UpdateStamp(System.currentTimeMillis(), UpdateStamp.State.Rolled,
                            true));
                }
                allUpdates.put(granularity, updates);
            }
            writer.persistShardState(shard, allUpdates);
        }

        // Now we would have the longest row for each shard because we filled all the slots.
        // Now test whether getShardState returns all the slots
        AstyanaxReader reader = AstyanaxReader.getInstance();
        ScheduleContext ctx = new ScheduleContext(System.currentTimeMillis(), shards);
        ShardStateManager shardStateManager = ctx.getShardStateManager();

        for (Integer shard : shards) {
            Collection<SlotState> slotStates = reader.getShardState(shard);
            for (SlotState slotState : slotStates) {
                shardStateManager.updateSlotOnRead(shard, slotState);
            }

            for (Granularity granularity : Granularity.rollupGranularities()) {
                ShardStateManager.SlotStateManager slotStateManager = shardStateManager.getSlotStateManager(shard, granularity);
                Assert.assertEquals(granularity.numSlots(), slotStateManager.getSlotStamps().size());
            }
        }
    }

    @Test
    public void testUpdateStampCoaelescing() throws Exception {
        final int shard = 24;
        final int slot = 16;
        AstyanaxWriter writer = AstyanaxWriter.getInstance();
        Map<Granularity, Map<Integer, UpdateStamp>> updates = new HashMap<Granularity, Map<Integer, UpdateStamp>>();
        Map<Integer, UpdateStamp> slotUpdates = new HashMap<Integer, UpdateStamp>();
        updates.put(Granularity.MIN_5, slotUpdates);
        
        long time = 1234;
        slotUpdates.put(slot, new UpdateStamp(time++, UpdateStamp.State.Active, true));
        writer.persistShardState(shard, updates);
        
        slotUpdates.put(slot, new UpdateStamp(time++, UpdateStamp.State.Rolled, true));
        writer.persistShardState(shard, updates);
        
        AstyanaxReader reader = AstyanaxReader.getInstance();
        ScheduleContext ctx = new ScheduleContext(System.currentTimeMillis(), Lists.newArrayList(shard));

        Collection<SlotState> slotStates = reader.getShardState(shard);
        for (SlotState slotState : slotStates) {
            ctx.getShardStateManager().updateSlotOnRead(shard, slotState);
        }

        ShardStateManager shardStateManager = ctx.getShardStateManager();
        ShardStateManager.SlotStateManager slotStateManager = shardStateManager.getSlotStateManager(shard, Granularity.MIN_5);

        Assert.assertNotNull(slotStateManager.getSlotStamps());
        Assert.assertEquals(UpdateStamp.State.Active, slotStateManager.getSlotStamps().get(slot).getState());
    }
}


File: blueflood-core/src/integration-test/java/com/rackspacecloud/blueflood/service/PreaggregatedMetricsIntegrationTest.java
/*
 * Copyright 2015 Rackspace
 *
 *    Licensed under the Apache License, Version 2.0 (the "License");
 *    you may not use this file except in compliance with the License.
 *    You may obtain a copy of the License at
 *
 *        http://www.apache.org/licenses/LICENSE-2.0
 *
 *    Unless required by applicable law or agreed to in writing, software
 *    distributed under the License is distributed on an "AS IS" BASIS,
 *    WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 *    See the License for the specific language governing permissions and
 *    limitations under the License.
 */

package com.rackspacecloud.blueflood.service;

import com.google.common.collect.Lists;
import com.netflix.astyanax.model.ColumnFamily;
import com.rackspacecloud.blueflood.io.*;
import com.rackspacecloud.blueflood.rollup.Granularity;
import com.rackspacecloud.blueflood.types.IMetric;
import com.rackspacecloud.blueflood.types.Locator;
import com.rackspacecloud.blueflood.types.Points;
import com.rackspacecloud.blueflood.types.PreaggregatedMetric;
import com.rackspacecloud.blueflood.types.Range;
import com.rackspacecloud.blueflood.types.TimerRollup;
import com.rackspacecloud.blueflood.utils.TimeValue;
import junit.framework.Assert;
import org.junit.Before;
import org.junit.Test;

import java.io.IOException;
import java.util.ArrayList;
import java.util.List;
import java.util.Map;
import java.util.concurrent.TimeUnit;
import java.util.concurrent.atomic.AtomicLong;

// todo: need an easy way to run this. It will require some plumbing changes to the project.
public class PreaggregatedMetricsIntegrationTest extends IntegrationTestBase {
    
    private TimerRollup simple;
    private static final TimeValue ttl = new TimeValue(24, TimeUnit.HOURS);
    private AstyanaxWriter writer = AstyanaxWriter.getInstance();
    private AstyanaxReader reader = AstyanaxReader.getInstance();
    private static final AtomicLong timestamp = new AtomicLong(10);
    
    @Before
    public void createFixtures() throws Exception {
        simple = new TimerRollup()
            .withSampleCount(1)
            .withSum(100d)
            .withCountPS(101d)
            .withAverage(102L)
            .withVariance(103d)
            .withMinValue(104)
            .withMaxValue(105)
            .withCount(106);
        simple.setPercentile("98th", 107);
        simple.setPercentile("99th", 110);
    }
    
    private static Points<TimerRollup> getTimerDataToRoll(AstyanaxReader reader, Locator locator, Range range, Granularity gran) throws IOException {
        ColumnFamily<Locator, Long> cf = CassandraModel.getColumnFamily(TimerRollup.class, gran);
        return reader.getDataToRoll(TimerRollup.class, locator, range, cf);
    }
    
    @Test
    public void testFullReadWrite() throws Exception {
        long ts = timestamp.incrementAndGet();
        Locator locator = Locator.createLocatorFromPathComponents("12345", "test", "full", "read", "put");
        IMetric metric = new PreaggregatedMetric(ts, locator, ttl, simple);

        writer.insertMetrics(Lists.newArrayList(metric), CassandraModel.CF_METRICS_PREAGGREGATED_FULL);
        
        Points<TimerRollup> points = PreaggregatedMetricsIntegrationTest.getTimerDataToRoll(reader, locator, new Range(ts, ts+1), Granularity.FULL);

        Assert.assertEquals(1, points.getPoints().size());
        Assert.assertEquals(metric.getMetricValue(), points.getPoints().get(ts).getData());
    }
    
    @Test
    public void testHigherGranReadWrite() throws Exception {
        final long ts = timestamp.incrementAndGet();
        final long rollupTs = ts + 100;
        Locator locator = Locator.createLocatorFromPathComponents("12345", "test", "rollup", "read", "put");
        IMetric metric = new PreaggregatedMetric(ts, locator, ttl, simple);
        
        writer.insertMetrics(Lists.newArrayList(metric), CassandraModel.CF_METRICS_PREAGGREGATED_FULL);
        
        // read the raw data.
        Points<TimerRollup> points = PreaggregatedMetricsIntegrationTest.getTimerDataToRoll(reader, locator, new Range(ts, ts+1), Granularity.FULL);
        Assert.assertEquals(1, points.getPoints().size());
        
        // create the rollup
        final TimerRollup rollup = TimerRollup.buildRollupFromTimerRollups(points);
        // should be the same as simple
        Assert.assertEquals(simple, rollup);
        
        // assemble it into points, but give it a new timestamp.
        points = new Points<TimerRollup>() {{
            add(new Point<TimerRollup>(rollupTs, rollup));
        }};
        List<IMetric> toWrite = toIMetricsList(locator, points);
        writer.insertMetrics(toWrite, CassandraModel.CF_METRICS_PREAGGREGATED_5M);
        
        // we should be able to read that now.
        Points<TimerRollup> rollups5m = reader.getDataToRoll(TimerRollup.class, locator, new Range(rollupTs, rollupTs+1), CassandraModel.CF_METRICS_PREAGGREGATED_5M);
        
        Assert.assertEquals(1, rollups5m.getPoints().size());
        
        TimerRollup rollup5m = rollups5m.getPoints().values().iterator().next().getData();
        // rollups should be identical since one is just a coarse rollup of the other.
        Assert.assertEquals(rollup, rollup5m);
    }
    
    @Test
    public void testTtlWorks() throws Exception {
        final long ts = timestamp.incrementAndGet();
        Locator locator = Locator.createLocatorFromPathComponents("12345", "test", "ttl");
        IMetric metric = new PreaggregatedMetric(ts, locator, new TimeValue(2, TimeUnit.SECONDS), simple);
        
        // put it
        writer.insertMetrics(Lists.newArrayList(metric), CassandraModel.CF_METRICS_PREAGGREGATED_FULL);
        
        // read it quickly.
        Points<TimerRollup> points = PreaggregatedMetricsIntegrationTest.getTimerDataToRoll(reader, locator, new Range(ts, ts+1), Granularity.FULL);
        Assert.assertEquals(1, points.getPoints().size());
        
        // let it time out.
        Thread.sleep(2000);
        
        // ensure it is gone.
        points = PreaggregatedMetricsIntegrationTest.getTimerDataToRoll(reader, locator, new Range(ts, ts+1), Granularity.FULL);
        Assert.assertEquals(0, points.getPoints().size());
    }
    
    private static List<IMetric> toIMetricsList(Locator locator, Points<TimerRollup> points) {
        List<IMetric> list = new ArrayList<IMetric>();
        for (Map.Entry<Long, Points.Point<TimerRollup>> entry : points.getPoints().entrySet()) {
            PreaggregatedMetric metric = new PreaggregatedMetric(entry.getKey(), locator, ttl, entry.getValue().getData());
            list.add(metric);
        }
        return list;
    }
    
}


File: blueflood-core/src/integration-test/java/com/rackspacecloud/blueflood/service/RollupRunnableIntegrationTest.java
/*
 * Copyright 2015 Rackspace
 *
 *    Licensed under the Apache License, Version 2.0 (the "License");
 *    you may not use this file except in compliance with the License.
 *    You may obtain a copy of the License at
 *
 *        http://www.apache.org/licenses/LICENSE-2.0
 *
 *    Unless required by applicable law or agreed to in writing, software
 *    distributed under the License is distributed on an "AS IS" BASIS,
 *    WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 *    See the License for the specific language governing permissions and
 *    limitations under the License.
 */

package com.rackspacecloud.blueflood.service;

import com.rackspacecloud.blueflood.cache.MetadataCache;
import com.rackspacecloud.blueflood.concurrent.ThreadPoolBuilder;
import com.rackspacecloud.blueflood.io.*;
import com.rackspacecloud.blueflood.rollup.Granularity;
import com.rackspacecloud.blueflood.types.*;
import com.rackspacecloud.blueflood.types.RollupType;
import com.rackspacecloud.blueflood.utils.TimeValue;
import junit.framework.Assert;
import org.junit.Test;

import java.io.IOException;
import java.util.ArrayList;
import java.util.Collection;
import java.util.concurrent.TimeUnit;

public class RollupRunnableIntegrationTest extends IntegrationTestBase {
    
    // gentle reader: remember, all column families are truncated between tests.
    
    private AstyanaxWriter writer = AstyanaxWriter.getInstance();
    private AstyanaxReader reader = AstyanaxReader.getInstance();
    
    private final Locator counterLocator = Locator.createLocatorFromPathComponents("runnabletest", "counter");
    private final Locator gaugeLocator = Locator.createLocatorFromPathComponents("runnabletest", "gauge");
    private final Locator timerLocator = Locator.createLocatorFromPathComponents("runnabletest", "timer");
    private final Locator setLocator = Locator.createLocatorFromPathComponents("runnabletest", "set");
    private final Locator normalLocator = Locator.createLocatorFromPathComponents("runnabletest", "just_some_data");
    
    private final Range range = new Range(0, 5 * 60 * 1000);
    
    private MetadataCache cache;

    @Override
    public void setUp() throws Exception {
        super.setUp(); // clears the schema.
        
        final TimeValue ttl = new TimeValue(24, TimeUnit.HOURS);
        
        // cache needs to be populated so rollups knows which serializer to use.
        cache = MetadataCache.createLoadingCacheInstance(ttl, 2);
        String cacheKey = MetricMetadata.ROLLUP_TYPE.name().toLowerCase();
        cache.put(counterLocator, cacheKey, RollupType.COUNTER.name());
        cache.put(gaugeLocator, cacheKey, RollupType.GAUGE.name());
        cache.put(timerLocator, cacheKey, RollupType.TIMER.name());
        cache.put(setLocator, cacheKey, RollupType.SET.name());
        // do not put normalLocator in the cache. it will constitute a miss.
        
        // put some full resolution data.
        Collection<IMetric> preaggregatedMetrics = new ArrayList<IMetric>();
        Collection<IMetric> normalMetrics = new ArrayList<IMetric>();
        
        for (int i = 0; i < 5; i++) {
            long time = i * 30000;
            IMetric metric;
            
            CounterRollup counter = new CounterRollup()
                    .withCount(i)
                    .withRate(i * i)
                    .withSampleCount(1);
            metric = new PreaggregatedMetric(time, counterLocator, ttl, counter);
            preaggregatedMetrics.add(metric);

            GaugeRollup gauge = new GaugeRollup()
                    .withLatest(time, i);
            metric = new PreaggregatedMetric(time, gaugeLocator, ttl, gauge);
            preaggregatedMetrics.add(metric);
            
            TimerRollup timer = new TimerRollup()
                    .withCount(5 * i + 1)
                    .withMaxValue(100 - i)
                    .withMinValue(100 - i - i)
                    .withAverage(i / 2)
                    .withCountPS((double)i).withSum(Double.valueOf(2 * i))
                    .withVariance((double) i / 2d);
            metric = new PreaggregatedMetric(time, timerLocator, ttl, timer);
            preaggregatedMetrics.add(metric);
            
            SetRollup rollup = new SetRollup().withObject(i);
            metric = new PreaggregatedMetric(time, setLocator, ttl, rollup);
            preaggregatedMetrics.add(metric);
            
            metric = new Metric(normalLocator, i, time, ttl, "centipawns");
            normalMetrics.add(metric);
        }
        
        writer.insertMetrics(preaggregatedMetrics, CassandraModel.CF_METRICS_PREAGGREGATED_FULL);
        writer.insertMetrics(normalMetrics, CassandraModel.CF_METRICS_FULL);
         
    }
    
    @Test
    public void testNormalMetrics() throws IOException {
        // full res has 5 samples.
        Assert.assertEquals(5, reader.getDataToRoll(SimpleNumber.class,
                                                    normalLocator,
                                                    range, 
                                                    CassandraModel.CF_METRICS_FULL).getPoints().size());
        
        // assert nothing in 5m for this locator.
        Assert.assertEquals(0, reader.getDataToRoll(BasicRollup.class,
                                                    normalLocator,
                                                    range, 
                                                    CassandraModel.CF_METRICS_5M).getPoints().size());
        
        RollupExecutionContext rec = new RollupExecutionContext(Thread.currentThread());
        SingleRollupReadContext rc = new SingleRollupReadContext(normalLocator, range, Granularity.MIN_5);
        RollupBatchWriter batchWriter = new RollupBatchWriter(new ThreadPoolBuilder().build(), rec);
        RollupRunnable rr = new RollupRunnable(rec, rc, batchWriter);
        rr.run();

        while (!rec.doneReading() && !rec.doneWriting()) {
            batchWriter.drainBatch();
            try {
                Thread.sleep(1000l);
            } catch (InterruptedException e) {
            }
        }

        // assert something in 5m for this locator.
        Assert.assertEquals(1, reader.getDataToRoll(BasicRollup.class,
                                                    normalLocator,
                                                    range,
                                                    CassandraModel.CF_METRICS_5M).getPoints().size());
    }
    
    @Test
    public void testCounterRollup() throws IOException {
        testRolledupMetric(counterLocator, CounterRollup.class, CounterRollup.class);
    }
    
    @Test
    public void testGaugeRollup() throws IOException {
        testRolledupMetric(gaugeLocator, GaugeRollup.class, GaugeRollup.class);
    }
    
    @Test
    public void testTimerRollup() throws IOException {
        testRolledupMetric(timerLocator, TimerRollup.class, TimerRollup.class);
    }
    
    @Test
    public void testSetRollup() throws IOException {
        testRolledupMetric(setLocator, SetRollup.class, SetRollup.class);
    }
    
    private void testRolledupMetric(Locator locator, Class fullResClass, Class rollupClass) throws IOException { 
        // full res has 5 samples.
        Assert.assertEquals(5, reader.getDataToRoll(fullResClass,
                                                    locator,
                                                    range, 
                                                    CassandraModel.CF_METRICS_PREAGGREGATED_FULL).getPoints().size());
        
        // assert nothing in 5m for this locator.
        Assert.assertEquals(0, reader.getDataToRoll(rollupClass,
                                                    locator,
                                                    range, 
                                                    CassandraModel.CF_METRICS_PREAGGREGATED_5M).getPoints().size());
        
        RollupExecutionContext rec = new RollupExecutionContext(Thread.currentThread());
        SingleRollupReadContext rc = new SingleRollupReadContext(locator, range, Granularity.MIN_5);
        RollupBatchWriter batchWriter = new RollupBatchWriter(new ThreadPoolBuilder().build(), rec);
        RollupRunnable rr = new RollupRunnable(rec, rc, batchWriter);
        rr.run();
        
        // assert something in 5m for this locator.
        while (!rec.doneReading() && !rec.doneWriting()) {
            batchWriter.drainBatch();
            try {
                Thread.sleep(1000l);
            } catch (InterruptedException e) {
            }
        }
        Assert.assertEquals(1, reader.getDataToRoll(rollupClass,
                                                    locator,
                                                    range,
                                                    CassandraModel.CF_METRICS_PREAGGREGATED_5M).getPoints().size());
    }
}


File: blueflood-core/src/integration-test/java/com/rackspacecloud/blueflood/service/RollupThreadpoolIntegrationTest.java
/*
 * Copyright 2015 Rackspace
 *
 *    Licensed under the Apache License, Version 2.0 (the "License");
 *    you may not use this file except in compliance with the License.
 *    You may obtain a copy of the License at
 *
 *        http://www.apache.org/licenses/LICENSE-2.0
 *
 *    Unless required by applicable law or agreed to in writing, software
 *    distributed under the License is distributed on an "AS IS" BASIS,
 *    WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 *    See the License for the specific language governing permissions and
 *    limitations under the License.
 */

package com.rackspacecloud.blueflood.service;

import com.codahale.metrics.MetricRegistry;
import com.codahale.metrics.Timer;
import com.rackspacecloud.blueflood.io.AstyanaxReader;
import com.rackspacecloud.blueflood.io.AstyanaxWriter;
import com.rackspacecloud.blueflood.io.IntegrationTestBase;
import com.rackspacecloud.blueflood.types.Locator;
import com.rackspacecloud.blueflood.utils.Metrics;
import com.rackspacecloud.blueflood.utils.Util;
import org.junit.Assert;
import org.junit.Test;

// this test used to measure rollups that were refused, but we don't care anymore. Not it makes sure that all rollups
// get executed.
public class RollupThreadpoolIntegrationTest extends IntegrationTestBase {
    private static final Integer threadsInRollupPool = 2;

    static {
        // run this test with a configuration so that threadpool queue size is artificially constrained smaller.
        System.setProperty("MAX_ROLLUP_READ_THREADS", threadsInRollupPool.toString());
        System.setProperty("MAX_ROLLUP_WRITE_THREADS", threadsInRollupPool.toString());
    }

    @Test
    // remember: this tests behavior, not performance.
    public void testManyLocators() throws Exception {
        Assert.assertEquals(Configuration.getInstance().getIntegerProperty(CoreConfig.MAX_ROLLUP_READ_THREADS), threadsInRollupPool.intValue());
        int shardToTest = 0;

        // I want to see what happens when RollupService.rollupExecutors gets too much work. It should never reject
        // work.
        long time = 1234;

        // now we need to put data that will generate an enormous amount of locators.
        AstyanaxWriter writer = AstyanaxWriter.getInstance();

        final int NUM_LOCATORS = 5000;
        int locatorCount = 0;
        while (locatorCount < NUM_LOCATORS) {
            // generate 100 random metrics.
            writer.insertFull(makeRandomIntMetrics(100));
            locatorCount += 100;
        }

        // lets see how many locators this generated. We want it to be a lot.

        int locatorsForTestShard = 0;
        for (Locator locator : AstyanaxReader.getInstance().getLocatorsToRollup(shardToTest)) {
            locatorsForTestShard++;
        }

        // Make sure number of locators for test shard is greater than number of rollup threads.
        // This is required so that rollups would be rejected for some locators.
        Assert.assertTrue(threadsInRollupPool < locatorsForTestShard);

        // great. now lets schedule those puppies.
        ScheduleContext ctx = new ScheduleContext(time, Util.parseShards(String.valueOf(shardToTest)));
        RollupService rollupService = new RollupService(ctx);
        rollupService.setKeepingServerTime(false);

        // indicate arrival (which we forced using Writer).
        ctx.update(time, shardToTest);

        // move time forward
        time += 500000;
        ctx.setCurrentTimeMillis(time);

        // start the rollups.
        Thread rollupThread = new Thread(rollupService, "rollup service test");
        rollupThread.start();

        Class.forName("com.rackspacecloud.blueflood.service.SingleRollupReadContext"); // Static initializer for the metric

        MetricRegistry registry = Metrics.getRegistry();
        Timer rollupsTimer = registry.getTimers().get(MetricRegistry.name(RollupService.class, "Rollup Execution Timer"));
//        Timer rollupsTimer = (Timer)registry.allMetrics().get(new MetricName("com.rackspacecloud.blueflood.service", "RollupService", "Rollup Execution Timer"));

        Assert.assertNotNull(rollupsTimer);

        // wait up to 120s for those rollups to finish.
        long start = System.currentTimeMillis();
        while (true) {
            try { Thread.currentThread().sleep(1000); } catch (Exception ex) { }
            if (rollupsTimer.getCount() >= locatorsForTestShard)
                break;
            Assert.assertTrue(String.format("rollups:%d", rollupsTimer.getCount()), System.currentTimeMillis() - start < 120000);
        }

        // make sure there were some that were delayed. If not, we need to increase NUM_LOCATORS.
        Assert.assertTrue(rollupsTimer.getCount() > 0);
    }
}


File: blueflood-core/src/integration-test/java/com/rackspacecloud/blueflood/service/ScheduleContextIntegrationTest.java
/*
 * Copyright 2015 Rackspace
 *
 *    Licensed under the Apache License, Version 2.0 (the "License");
 *    you may not use this file except in compliance with the License.
 *    You may obtain a copy of the License at
 *
 *        http://www.apache.org/licenses/LICENSE-2.0
 *
 *    Unless required by applicable law or agreed to in writing, software
 *    distributed under the License is distributed on an "AS IS" BASIS,
 *    WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 *    See the License for the specific language governing permissions and
 *    limitations under the License.
 */

package com.rackspacecloud.blueflood.service;

import org.apache.curator.framework.recipes.locks.InterProcessMutex;
import org.junit.Assert;
import org.junit.Before;
import org.junit.Test;
import org.mockito.internal.util.reflection.Whitebox;
import org.slf4j.Logger;
import org.slf4j.LoggerFactory;

import java.util.Collection;
import java.util.HashSet;
import java.util.Map;

public class ScheduleContextIntegrationTest {
    private static final Logger log = LoggerFactory.getLogger("tests");
    private ScheduleContext context;
    private ShardStateManager shardStateManager;
    private Collection<Integer> manageShards = new HashSet<Integer>();

    @Before
    public void setUp() {
        manageShards.add(1);
        manageShards.add(5);
        manageShards.add(7);
        manageShards.add(11);
        context = new ScheduleContext(1234, manageShards, Configuration.getInstance().getStringProperty(CoreConfig.ZOOKEEPER_CLUSTER));
        shardStateManager = context.getShardStateManager();
    }

    @Test
    public void testSetShardAddition() throws Exception {
        Assert.assertArrayEquals(manageShards.toArray(), shardStateManager.getManagedShards().toArray());
        manageShards.add(2);
        context.addShard(2);
        Assert.assertArrayEquals(manageShards.toArray(), shardStateManager.getManagedShards().toArray());
        final ZKBasedShardLockManager lockManager = (ZKBasedShardLockManager) Whitebox.getInternalState(context,
                "lockManager");

        Map<Integer, InterProcessMutex> lockObjects = (Map<Integer, InterProcessMutex>) Whitebox.getInternalState
                (lockManager, "locks");

        Assert.assertTrue(lockObjects.get(2) != null);  // assert that we have a lock object for shard "2"
    }

    @Test
    public void testSetShardDeletion() {
        Assert.assertArrayEquals(manageShards.toArray(), shardStateManager.getManagedShards().toArray());
        manageShards.remove(1);
        context.removeShard(1);
        Assert.assertArrayEquals(manageShards.toArray(), shardStateManager.getManagedShards().toArray());
        final ZKBasedShardLockManager lockManager = (ZKBasedShardLockManager) Whitebox.getInternalState(context,
                "lockManager");

        Map<Integer, InterProcessMutex> lockObjects = (Map<Integer, InterProcessMutex>) Whitebox.getInternalState
                (lockManager, "locks");

        Assert.assertTrue(lockObjects.get(1) == null);  // assert that we don't have a lock object for shard "1"
    }
}

File: blueflood-core/src/integration-test/java/com/rackspacecloud/blueflood/service/ShardStateIntegrationTest.java
/*
 * Copyright 2015 Rackspace
 *
 *    Licensed under the Apache License, Version 2.0 (the "License");
 *    you may not use this file except in compliance with the License.
 *    You may obtain a copy of the License at
 *
 *        http://www.apache.org/licenses/LICENSE-2.0
 *
 *    Unless required by applicable law or agreed to in writing, software
 *    distributed under the License is distributed on an "AS IS" BASIS,
 *    WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 *    See the License for the specific language governing permissions and
 *    limitations under the License.
 */

package com.rackspacecloud.blueflood.service;

import com.rackspacecloud.blueflood.io.AstyanaxShardStateIO;
import com.rackspacecloud.blueflood.io.IntegrationTestBase;
import com.rackspacecloud.blueflood.io.ShardStateIO;
import com.rackspacecloud.blueflood.rollup.Granularity;
import com.rackspacecloud.blueflood.rollup.SlotKey;
import com.rackspacecloud.blueflood.utils.Util;
import com.google.common.collect.Iterables;
import com.google.common.collect.Lists;
import org.junit.After;
import org.junit.Assert;
import org.junit.Ignore;
import org.junit.Test;
import org.junit.runner.RunWith;
import org.junit.runners.Parameterized;

import java.io.IOException;
import java.util.*;
import java.util.concurrent.CountDownLatch;
import java.util.concurrent.TimeUnit;
import java.util.concurrent.atomic.AtomicBoolean;
import java.util.concurrent.atomic.AtomicLong;

@Ignore
@RunWith(Parameterized.class)
public class ShardStateIntegrationTest extends IntegrationTestBase {
    
    private ShardStateIO io;
    
    public ShardStateIntegrationTest(ShardStateIO io) {
        this.io = io;    
    }

    @Test
    public void testSingleShardManager() {
        long time = 1234000L;
        Collection<Integer> shards = Lists.newArrayList(1, 2, 3, 4);
        ScheduleContext ctx = new ScheduleContext(time, shards);
        ShardStateWorker pull = new ShardStatePuller(shards, ctx.getShardStateManager(), this.io);
        ShardStateWorker push = new ShardStatePusher(shards, ctx.getShardStateManager(), this.io);
        
        for (long t = time; t < time + 10000000; t += 1000) {
            ctx.update(t + 0, 1);
            ctx.update(t + 2000, 2);
            ctx.update(t + 4000, 3);
            ctx.update(t + 6000, 4);
        }
        
        time += 10000000 + 7;
        ctx.setCurrentTimeMillis(time);
        push.performOperation();
        pull.performOperation();
        
        // the numbers we're testing against are the number of slots per granularity in 10000 seconds.
        for (Granularity g : Granularity.rollupGranularities()) {
            for (int shard : shards) {
                if (g == Granularity.MIN_5)
                    Assert.assertEquals(34, ctx.getSlotStamps(g, shard).size());
                else if (g == Granularity.MIN_20)
                    Assert.assertEquals(9, ctx.getSlotStamps(g, shard).size());
                else if (g == Granularity.MIN_60)
                    Assert.assertEquals(4, ctx.getSlotStamps(g, shard).size());
                else if (g == Granularity.MIN_240)
                    Assert.assertEquals(1, ctx.getSlotStamps(g, shard).size());
                else if (g == Granularity.MIN_1440)
                    Assert.assertEquals(1, ctx.getSlotStamps(g, shard).size());
            }
        }
    }

    @Test
    public void testRollupFailureForDelayedMetrics() {
        long time = 1234000L;
        Collection<Integer> managedShards = Lists.newArrayList(0);
        ScheduleContext ingestionCtx = new ScheduleContext(time, managedShards);
        ScheduleContext rollupCtx = new ScheduleContext(time, managedShards);
        // Shard workers for rollup ctx
        ShardStateWorker rollupPuller = new ShardStatePuller(managedShards, rollupCtx.getShardStateManager(), this.io);
        ShardStateWorker rollupPusher = new ShardStatePusher(managedShards, rollupCtx.getShardStateManager(), this.io);

        // Shard workers for ingest ctx
        ShardStateWorker ingestPuller = new ShardStatePuller(managedShards, ingestionCtx.getShardStateManager(), this.io);
        ShardStateWorker ingestPusher = new ShardStatePusher(managedShards, ingestionCtx.getShardStateManager(), this.io);

        ingestionCtx.update(time + 30000, 0);
        ingestPusher.performOperation(); // Shard state is persisted on ingestion host

        rollupPuller.performOperation(); // Shard state is read on rollup host
        rollupCtx.setCurrentTimeMillis(time + 600000);
        rollupCtx.scheduleSlotsOlderThan(300000);
        Assert.assertEquals(1, rollupCtx.getScheduledCount());

        // Simulate the hierarchical scheduling of slots
        int count = 0;
        while (rollupCtx.getScheduledCount() > 0) {
            SlotKey slot = rollupCtx.getNextScheduled();
            rollupCtx.clearFromRunning(slot);
            rollupCtx.scheduleSlotsOlderThan(300000);
            count += 1;
        }
        Assert.assertEquals(5, count); // 5 rollup grans should have been scheduled by now
        rollupPusher.performOperation();

        // Delayed metric is received on ingestion host
        ingestPuller.performOperation();
        ingestionCtx.update(time, 0);
        ingestPusher.performOperation();

        rollupPuller.performOperation();
        rollupCtx.scheduleSlotsOlderThan(300000);
        Assert.assertEquals(1, rollupCtx.getScheduledCount());

        // Simulate the hierarchical scheduling of slots
        count = 0;
        while (rollupCtx.getScheduledCount() > 0) {
            SlotKey slot = rollupCtx.getNextScheduled();
            rollupCtx.clearFromRunning(slot);
            rollupCtx.scheduleSlotsOlderThan(300000);
            count += 1;
        }
        Assert.assertEquals(5, count); // 5 rollup grans should have been scheduled by now
    }

    @Test
    public void testSetAllCoarserSlotsDirtyForFinerSlot() {
        // Tests that the correct coarser slots are set dirty for a finer slot which was seen out-of-order.
        // Prior to a bug fix, clearFromRunning would throw NPE because we were looking up coarser slots
        // based on the timestamp on the finer slot's UpdateStamp, not based on the relative courser slot from the finer slot
        long time = 1386823200000L;
        final Collection<Integer> shards = Lists.newArrayList(123);
        ScheduleContext ctxA = new ScheduleContext(time, shards);

        ctxA.update(time, 123);
        ShardStateManager.SlotStateManager slotStateManager20 = ctxA.getShardStateManager().getSlotStateManager(123, Granularity.MIN_20);

        UpdateStamp stamp  = slotStateManager20.getSlotStamps().get(518);
        stamp.setTimestamp(time + 3600000L); // add one hour
        ctxA.clearFromRunning(SlotKey.of(Granularity.MIN_20, 518, 123));
    }

    @Test
    public void testConcurrentShardManagers() {
        long time = 1234000L;
        // notice how they share shard 5.
        final int commonShard = 5;
        final Collection<Integer> shardsA = Lists.newArrayList(1, 2, 3, 4, commonShard);
        final Collection<Integer> shardsB = Lists.newArrayList(11, 22, 33, 44, commonShard);
        Collection<Integer> allShards = new ArrayList<Integer>() {{
            for (int i : Iterables.concat(shardsA, shardsB))
                add(i);
        }};
        
        ScheduleContext ctxA = new ScheduleContext(time, shardsA);
        ScheduleContext ctxB = new ScheduleContext(time, shardsB);

        ShardStateWorker pushA = new ShardStatePusher(allShards, ctxA.getShardStateManager(), this.io);
        ShardStateWorker pullA = new ShardStatePuller(allShards, ctxA.getShardStateManager(), this.io);
        ShardStateWorker pushB = new ShardStatePusher(allShards, ctxB.getShardStateManager(), this.io);
        ShardStateWorker pullB = new ShardStatePuller(allShards, ctxB.getShardStateManager(), this.io);
        
        // send a few updates to all contexts.
        for (ScheduleContext ctx : new ScheduleContext[] { ctxA, ctxB }) {
            for (long t = time; t < time + 10000000; t += 1000) {
                ctx.update(t + 0, 1);
                ctx.update(t + 1000, 11);
                ctx.update(t + 2000, 2);
                ctx.update(t + 3000, 22);
                ctx.update(t + 4000, 3);
                ctx.update(t + 5000, 33);
                ctx.update(t + 6000, 4);
                ctx.update(t + 7000, 44);            
            }
        }
        
        time += 10000000 + 7;
        ctxA.setCurrentTimeMillis(time);
        ctxB.setCurrentTimeMillis(time);
        
        // simulate a poll() cylce for each.
        pushA.performOperation();
        pushB.performOperation();
        pullA.performOperation();
        pullB.performOperation();
        
        // states should be the same.
        for (Granularity g : Granularity.rollupGranularities()) {
            for (int shard : allShards)
                Assert.assertEquals(ctxA.getSlotStamps(g, shard), ctxB.getSlotStamps(g, shard));
        }
        
        time += 300000; // this pushes us forward at least one slot.
        
        // now do this: update ctxA, do 2 push/pull cycles on each state.  they should sill be the same.
        ctxA.update(time,  1);
        ctxA.update(time, 11);
        ctxA.update(time, 2);
        ctxA.update(time, 22);
        ctxA.setCurrentTimeMillis(time);
        ctxB.setCurrentTimeMillis(time);
        
        // states should not be the same in some places.
        Assert.assertFalse(ctxA.getSlotStamps(Granularity.MIN_5, 1).equals(ctxB.getSlotStamps(Granularity.MIN_5, 1)));
        Assert.assertFalse(ctxA.getSlotStamps(Granularity.MIN_5, 11).equals(ctxB.getSlotStamps(Granularity.MIN_5, 11)));
        Assert.assertTrue(ctxA.getSlotStamps(Granularity.MIN_5, 3).equals(ctxB.getSlotStamps(Granularity.MIN_5, 3)));
        Assert.assertTrue(ctxA.getSlotStamps(Granularity.MIN_5, 33).equals(ctxB.getSlotStamps(Granularity.MIN_5, 33)));
        
        // this is where the syncing should happen. Order is important for a valid test.  A contains the updates, so
        // I want to put that one first.  B contains old data and it gets written second.  Part of what I'm verifying
        // is that B doesn't overwrite A with data that is obviously old.
        
        // A pushes updated data
        pushA.performOperation();
        // B tries to push old data (should not overwrite what A just did)
        pushB.performOperation();
        // B pulls new data (should get updates from A).
        pullB.performOperation();
        
        // we didn't do a pull on A because if things are broken, it would have pulled the crap data written by B and
        // given the false impression that all timestamps are the same.
        
        // states should have synced up and be the same again.
        for (Granularity g : Granularity.rollupGranularities()) {
            Assert.assertEquals(ctxA.getSlotStamps(g, commonShard), ctxB.getSlotStamps(g, commonShard));
        }
    }

    @Test
    // this test illustrates how loading shard state clobbered the knowledge that a shard,slot had already been 
    // rolled up.
    public void testUpdateClobbering() {
        long time = 1234L;
        final Collection<Integer> shardsA = Lists.newArrayList(1);
        final Collection<Integer> shardsB = Lists.newArrayList(2);
        Collection<Integer> allShards = new ArrayList<Integer>() {{
            for (int i : Iterables.concat(shardsA, shardsB)) add(i);
        }};
        
        ScheduleContext ctxA = new ScheduleContext(time, shardsA);
        ShardStateWorker pushA = new ShardStatePusher(allShards, ctxA.getShardStateManager(), this.io);
        ShardStateWorker pullA = new ShardStatePuller(allShards, ctxA.getShardStateManager(), this.io);
        
        // update.
        time += 1000;
        ctxA.setCurrentTimeMillis(time);
        ctxA.update(time, 1);
        
        // persist.
        pushA.performOperation();
        
        // time goes on.
        time += 600000;
        ctxA.setCurrentTimeMillis(time);
        
        // should be ready to schedule.
        ctxA.scheduleSlotsOlderThan(300000);
        Assert.assertEquals(1, ctxA.getScheduledCount());
        
        // simulate slots getting run.
        int count = 0;
        while (ctxA.getScheduledCount() > 0) {
            SlotKey slot = ctxA.getNextScheduled();
            ctxA.clearFromRunning(slot);
            ctxA.scheduleSlotsOlderThan(300000);
            count += 1;
        }
        Assert.assertEquals(5, count);
        // verify that scheduling doesn't find anything else.
        ctxA.scheduleSlotsOlderThan(300000);
        Assert.assertEquals(0, ctxA.getScheduledCount());
        
        // reloading under these circumstances (no updates) should not affect the schedule.
        pullA.performOperation();
        ctxA.scheduleSlotsOlderThan(300000);
        Assert.assertEquals(0, ctxA.getScheduledCount());
    }

    @Test
    public void testShardOperationsConcurrency() throws InterruptedException {
        final long tryFor = 15000;
        final AtomicLong time = new AtomicLong(1234L);
        final Collection<Integer> shards = Collections.unmodifiableCollection(Util.parseShards("ALL"));
        final ScheduleContext ctx = new ScheduleContext(time.get(), shards);
        final CountDownLatch latch = new CountDownLatch(2);
        final Throwable[] errBucket = new Throwable[2];
        Thread pushPull = new Thread() { public void run() {
            ShardStateWorker push = new ShardStatePusher(shards, ctx.getShardStateManager(), ShardStateIntegrationTest.this.io);
            ShardStateWorker pull = new ShardStatePuller(shards, ctx.getShardStateManager(), ShardStateIntegrationTest.this.io);
            
            push.setPeriod(1);
            pull.setPeriod(1);
            long startTime = System.currentTimeMillis();
            while (System.currentTimeMillis() - startTime < tryFor) {
                try {
                    push.performOperation();
                    pull.performOperation();
                } catch (Throwable th) {
                    th.printStackTrace();
                    errBucket[0] = th;
                    break;
                }
            }
            latch.countDown();
        }};
        Thread updateIterator = new Thread() { public void run() {
            long start = System.currentTimeMillis();
            outer: while (System.currentTimeMillis() - start < tryFor) {
                for (int shard : shards) {
                    time.set(time.get() + 30000);
                    ctx.setCurrentTimeMillis(time.get());
                    try {
                        ctx.update(time.get(), shard);
                    } catch (Throwable th) {
                        th.printStackTrace();
                        errBucket[1] = th;
                        break outer;
                    }
                }
            }
            latch.countDown();
        }};

        pushPull.start();
        updateIterator.start();
        latch.await(tryFor + 2000, TimeUnit.MILLISECONDS);
        Assert.assertNull(errBucket[0]);
        Assert.assertNull(errBucket[1]);
    }


    @Test
    public void testConvergenceForMultipleIngestors() throws InterruptedException {
        final long tryFor = 1000;
        final AtomicLong time = new AtomicLong(1234L);
        final Collection<Integer> shards = Collections.unmodifiableCollection(Util.parseShards("ALL"));
        final List<ScheduleContext> ctxs = Lists.newArrayList(new ScheduleContext(time.get(), shards), new ScheduleContext(time.get(), shards));
        final List<ShardStateWorker> workers = Lists.newArrayList(new ShardStatePusher(shards, ctxs.get(0).getShardStateManager(), ShardStateIntegrationTest.this.io),
                new ShardStatePuller(shards, ctxs.get(0).getShardStateManager(), ShardStateIntegrationTest.this.io),
                new ShardStatePusher(shards, ctxs.get(1).getShardStateManager(), ShardStateIntegrationTest.this.io),
                new ShardStatePuller(shards, ctxs.get(1).getShardStateManager(), ShardStateIntegrationTest.this.io));
        final CountDownLatch latch = new CountDownLatch(1);
        final AtomicBoolean err = new AtomicBoolean(false);

        Thread updateIterator = new Thread() { public void run() {
            long start = System.currentTimeMillis();
            Random rand = new Random();
            outer: while (System.currentTimeMillis() - start < tryFor) {
                for (int shard : shards) {
                    time.set(time.get() + 30000);
                    ScheduleContext ctx = ctxs.get(rand.nextInt(2));
                    try {
                        ctx.update(time.get(), shard);
                    } catch (Throwable th) {
                        th.printStackTrace();
                        err.set(true);
                        break outer;
                    }
                }
            }
            latch.countDown();
        }};

        updateIterator.start();
        latch.await();

        workers.get(0).performOperation();
        workers.get(3).performOperation();
        workers.get(2).performOperation();
        workers.get(1).performOperation();
        workers.get(0).performOperation();
        workers.get(3).performOperation();
        workers.get(2).performOperation();
        workers.get(1).performOperation();

        Assert.assertFalse(err.get());

        for (Granularity gran : Granularity.rollupGranularities()) {
            for (int shard : shards) {
                Assert.assertEquals(ctxs.get(0).getSlotStamps(gran, shard).size(), ctxs.get(1).getSlotStamps(gran, shard).size());
                for (Map.Entry<Integer, UpdateStamp> entry : ctxs.get(0).getSlotStamps(gran, shard).entrySet()) {
                    Assert.assertEquals(entry.getValue(), ctxs.get(1).getSlotStamps(gran, shard).get(entry.getKey()));
                }
            }
        }
    }

    @Test
    public void testSlotStateConvergence() throws InterruptedException {
        int shard = 0;
        long time = 1234000L;
        long metricTimeUpdate1 = time + 30000;
        long metricsTimeUpdate2 = time + 60000;
        Collection<Integer> shards = Lists.newArrayList(shard);
        List<ShardStateWorker> allWorkers = new ArrayList<ShardStateWorker>(6);

        // Ingestor 1
        ScheduleContext ctxIngestor1 = new ScheduleContext(time, shards);
        ShardStatePuller pullerIngestor1 = new ShardStatePuller(shards, ctxIngestor1.getShardStateManager(), this.io);
        ShardStatePusher pusherIngestor1 = new ShardStatePusher(shards, ctxIngestor1.getShardStateManager(), this.io);
        allWorkers.add(pullerIngestor1);
        allWorkers.add(pusherIngestor1);

        // Ingestor 2
        ScheduleContext ctxIngestor2 = new ScheduleContext(time, shards);
        ShardStatePuller pullerIngestor2 = new ShardStatePuller(shards, ctxIngestor2.getShardStateManager(), this.io);
        ShardStatePusher pusherIngestor2 = new ShardStatePusher(shards, ctxIngestor2.getShardStateManager(), this.io);
        allWorkers.add(pullerIngestor2);
        allWorkers.add(pusherIngestor2);

        // Rollup slave
        ScheduleContext ctxRollup = new ScheduleContext(time, shards);
        ShardStatePuller pullerRollup = new ShardStatePuller(shards, ctxRollup.getShardStateManager(), this.io);
        ShardStatePusher pusherRollup = new ShardStatePusher(shards, ctxRollup.getShardStateManager(), this.io);
        allWorkers.add(pullerRollup);
        allWorkers.add(pusherRollup);

        // Updates for same shard come for same slot on different ingestion contexts
        ctxIngestor1.update(metricTimeUpdate1, shard);
        ctxIngestor2.update(metricsTimeUpdate2, shard);

        makeWorkersSyncState(allWorkers);

        // After the sync, the higher timestamp should have "won" and ACTIVE slots should have converged on both the ingestion contexts
        for (Granularity gran : Granularity.rollupGranularities())
            Assert.assertEquals(ctxIngestor1.getSlotStamps(gran, shard), ctxIngestor2.getSlotStamps(gran, shard));

        ctxRollup.setCurrentTimeMillis(time + 600000L);
        ctxRollup.scheduleSlotsOlderThan(300000L);
        Assert.assertEquals(1, ctxRollup.getScheduledCount());

        // Simulate the hierarchical scheduling of slots
        int count = 0;
        while (ctxRollup.getScheduledCount() > 0) {
            SlotKey slot = ctxRollup.getNextScheduled();
            ctxRollup.clearFromRunning(slot);
            ctxRollup.scheduleSlotsOlderThan(300000L);
            count += 1;
        }
        Assert.assertEquals(5, count); // 5 rollup grans should have been scheduled by now

        makeWorkersSyncState(allWorkers);

        // By this point of time, all contexts should have got the ROLLED state
        for (Granularity gran : Granularity.rollupGranularities()) { // Check to see if shard states are indeed matching
            Assert.assertEquals(ctxIngestor1.getSlotStamps(gran, shard), ctxIngestor2.getSlotStamps(gran, shard));
            Assert.assertEquals(ctxRollup.getSlotStamps(gran, shard), ctxIngestor2.getSlotStamps(gran, shard));
        }

        Map<Integer, UpdateStamp> slotStamps;
        // Test for specific state of ROLLED. Because we have already tested that slot states are same across, it also means ROLLED has been stamped on ingestor1 and ingestor2
        for (Granularity gran : Granularity.rollupGranularities()) {
            int slot = 0;
            if (gran == Granularity.MIN_5) slot = 4;
            if (gran == Granularity.MIN_20) slot = 1;
            slotStamps = ctxRollup.getSlotStamps(gran, shard);
            Assert.assertEquals(slotStamps.get(slot).getState(), UpdateStamp.State.Rolled);
            Assert.assertEquals(slotStamps.get(slot).getTimestamp(), metricsTimeUpdate2);
        }

        // Delayed metric test
        long delayedMetricTimestamp = time + 45000; // Notice that this is lesser than the last time we rolled the slot
        ctxIngestor1.update(delayedMetricTimestamp, shard);

        makeWorkersSyncState(allWorkers);

        // Shard state will be the same throughout and will be marked as ACTIVE
        for (Granularity gran : Granularity.rollupGranularities()) {
            Assert.assertEquals(ctxIngestor1.getSlotStamps(gran, shard), ctxIngestor2.getSlotStamps(gran, shard));
            Assert.assertEquals(ctxRollup.getSlotStamps(gran, shard), ctxIngestor2.getSlotStamps(gran, shard));
        }

        for (Granularity gran : Granularity.rollupGranularities()) {
            int slot = 0;
            if (gran == Granularity.MIN_5) slot = 4;
            if (gran == Granularity.MIN_20) slot = 1;
            slotStamps = ctxRollup.getSlotStamps(gran, shard);
            Assert.assertEquals(slotStamps.get(slot).getState(), UpdateStamp.State.Active);
            Assert.assertEquals(slotStamps.get(slot).getTimestamp(), delayedMetricTimestamp);
        }

        // Scheduling the slot for rollup will and following the same process as we did before will mark the state as ROLLED again, but notice that it will have the timestamp of delayed metric
        ctxRollup.scheduleSlotsOlderThan(300000);
        Assert.assertEquals(1, ctxRollup.getScheduledCount());

        // Simulate the hierarchical scheduling of slots
        count = 0;
        while (ctxRollup.getScheduledCount() > 0) {
            SlotKey slot = ctxRollup.getNextScheduled();
            ctxRollup.clearFromRunning(slot);
            ctxRollup.scheduleSlotsOlderThan(300000);
            count += 1;
        }
        Assert.assertEquals(5, count); // 5 rollup grans should have been scheduled by now

        makeWorkersSyncState(allWorkers);

        for (Granularity gran : Granularity.rollupGranularities()) {
            Assert.assertEquals(ctxIngestor1.getSlotStamps(gran, shard), ctxIngestor2.getSlotStamps(gran, shard));
            Assert.assertEquals(ctxRollup.getSlotStamps(gran, shard), ctxIngestor2.getSlotStamps(gran, shard));
        }

        for (Granularity gran : Granularity.rollupGranularities()) {
            int slot = 0;
            if (gran == Granularity.MIN_5) slot = 4;
            if (gran == Granularity.MIN_20) slot = 1;
            slotStamps = ctxRollup.getSlotStamps(gran, shard);
            Assert.assertEquals(slotStamps.get(slot).getState(), UpdateStamp.State.Rolled);
            Assert.assertEquals(slotStamps.get(slot).getTimestamp(), delayedMetricTimestamp);
        }
    }

    @After
    public void cleanupShardStateIO () {
        if (this.io instanceof InMemoryShardStateIO) {
            ((InMemoryShardStateIO) this.io).cleanUp();
        }
    }

    private void makeWorkersSyncState(List<ShardStateWorker> workers) {
        // All states should be synced after 2 attempts, irrespective of operation ordering which is proved by shuffling of orders
        for (int i=0; i<=2; i++) {
            for (ShardStateWorker worker : workers) {
                worker.performOperation();
            }
        }
    }
    
    @Parameterized.Parameters
    public static Collection<Object[]> getDifferentShardStateIOInstances() {
        List<Object[]> instances = new ArrayList<Object[]>();
        instances.add(new Object[] { new AstyanaxShardStateIO() });
        instances.add(new Object[] { new InMemoryShardStateIO() });
        return instances;
    }
    
    private static class InMemoryShardStateIO implements ShardStateIO {
        
        private Map<Integer, Map<Granularity, Map<Integer, UpdateStamp>>> map = new HashMap<Integer, Map<Granularity, Map<Integer, UpdateStamp>>>();
        
        @Override
        public Collection<SlotState> getShardState(int shard) throws IOException {
            Map<Granularity, Map<Integer, UpdateStamp>> updates = map.get(shard);
            if (updates == null) {
                return new ArrayList<SlotState>();
            } else {
                List<SlotState> states = new ArrayList<SlotState>();
                for (Map.Entry<Granularity, Map<Integer, UpdateStamp>> e0 : updates.entrySet()) {
                    for (Map.Entry<Integer, UpdateStamp> e1 : e0.getValue().entrySet()) {
                        SlotState state = new SlotState(e0.getKey(), e1.getKey(), e1.getValue().getState());
                        state.withTimestamp(e1.getValue().getTimestamp());
                        states.add(state);
                    }
                }
                return states;
            }
        }

        @Override
        public void putShardState(int shard, Map<Granularity, Map<Integer, UpdateStamp>> slotTimes) throws IOException {
            map.put(shard, slotTimes);
        }

        public void cleanUp() {
            map.clear();
        }
    }
}


File: blueflood-core/src/integration-test/java/com/rackspacecloud/blueflood/utils/RollupTestUtils.java
/*
 * Copyright 2015 Rackspace
 *
 *    Licensed under the Apache License, Version 2.0 (the "License");
 *    you may not use this file except in compliance with the License.
 *    You may obtain a copy of the License at
 *
 *        http://www.apache.org/licenses/LICENSE-2.0
 *
 *    Unless required by applicable law or agreed to in writing, software
 *    distributed under the License is distributed on an "AS IS" BASIS,
 *    WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 *    See the License for the specific language governing permissions and
 *    limitations under the License.
 */

package com.rackspacecloud.blueflood.utils;

import com.netflix.astyanax.model.ColumnFamily;
import com.rackspacecloud.blueflood.io.AstyanaxIO;
import com.rackspacecloud.blueflood.io.AstyanaxReader;
import com.rackspacecloud.blueflood.io.AstyanaxWriter;
import com.rackspacecloud.blueflood.io.CassandraModel;
import com.rackspacecloud.blueflood.rollup.Granularity;
import com.rackspacecloud.blueflood.service.SingleRollupWriteContext;
import com.rackspacecloud.blueflood.types.*;
import org.apache.cassandra.thrift.Cassandra;

import java.util.ArrayList;

public class RollupTestUtils {
    public static void generateRollups(Locator locator, long from, long to, Granularity destGranularity) throws Exception {
        if (destGranularity == Granularity.FULL) {
            throw new Exception("Can't roll up to FULL");
        }

        ColumnFamily<Locator, Long> destCF = CassandraModel.getColumnFamily(BasicRollup.class, destGranularity);
        ArrayList<SingleRollupWriteContext> writeContexts = new ArrayList<SingleRollupWriteContext>();
        for (Range range : Range.rangesForInterval(destGranularity, from, to)) {
            Points<SimpleNumber> input = AstyanaxReader.getInstance().getDataToRoll(SimpleNumber.class, locator, range, CassandraModel.CF_METRICS_FULL);
            Rollup basicRollup = BasicRollup.buildRollupFromRawSamples(input);
            writeContexts.add(new SingleRollupWriteContext(basicRollup, locator, destGranularity, destCF, range.getStart()));
        }


        AstyanaxWriter.getInstance().insertRollups(writeContexts);
    }
}


File: blueflood-core/src/main/java/com/rackspacecloud/blueflood/cache/AbstractJmxCache.java
/*
 * Copyright 2015 Rackspace
 *
 *    Licensed under the Apache License, Version 2.0 (the "License");
 *    you may not use this file except in compliance with the License.
 *    You may obtain a copy of the License at
 *
 *        http://www.apache.org/licenses/LICENSE-2.0
 *
 *    Unless required by applicable law or agreed to in writing, software
 *    distributed under the License is distributed on an "AS IS" BASIS,
 *    WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 *    See the License for the specific language governing permissions and
 *    limitations under the License.
 */

package com.rackspacecloud.blueflood.cache;

import com.codahale.metrics.Gauge;
import com.codahale.metrics.JmxAttributeGauge;
import com.codahale.metrics.MetricRegistry;
import com.google.common.cache.CacheStats;
import com.rackspacecloud.blueflood.utils.Metrics;

import javax.management.ObjectName;

public abstract class AbstractJmxCache implements  CacheStatsMBean {

    private Gauge hitCount;
    private Gauge hitRate;
    private Gauge loadCount;
    private Gauge missRate;
    private Gauge requestCount;
    private Gauge totalLoadTime;

    public abstract CacheStats getStats();
    
    public long getHitCount() {
        return getStats().hitCount();
    }

    public double getHitRate() {
        return getStats().hitRate();
    }

    public long getMissCount() {
        return getStats().missCount();
    }

    public double getMissRate() {
        return getStats().missRate();
    }

    public long getLoadCount() {
        return getStats().loadCount();
    }

    public long getRequestCount() {
        return getStats().requestCount();
    }

    public long getTotalLoadTime() {
        return getStats().totalLoadTime();
    }

    public void instantiateYammerMetrics(Class klass, String scope, ObjectName nameObj) {
        String name = MetricRegistry.name(klass);
        if (scope != null) {
            name = MetricRegistry.name(name, scope);
        }
        MetricRegistry reg = Metrics.getRegistry();
        hitCount = reg.register(MetricRegistry.name(name, "Hit Count"),
                new JmxAttributeGauge(nameObj, "HitCount"));
        hitRate = reg.register(MetricRegistry.name(name, "Hit Rate"),
                new JmxAttributeGauge(nameObj, "HitRate"));
        loadCount = reg.register(MetricRegistry.name(name, "Load Count"),
                new JmxAttributeGauge(nameObj, "LoadCount"));
        missRate = reg.register(MetricRegistry.name(name, "Miss Rate"),
                new JmxAttributeGauge(nameObj, "MissRate"));
        requestCount = reg.register(MetricRegistry.name(name, "Request Count"),
                new JmxAttributeGauge(nameObj, "RequestCount"));
        totalLoadTime = reg.register(MetricRegistry.name(name, "Total Load Time"),
                new JmxAttributeGauge(nameObj, "TotalLoadTime"));
    }
}


File: blueflood-core/src/main/java/com/rackspacecloud/blueflood/cache/CacheStatsMBean.java
/*
 * Copyright 2015 Rackspace
 *
 *    Licensed under the Apache License, Version 2.0 (the "License");
 *    you may not use this file except in compliance with the License.
 *    You may obtain a copy of the License at
 *
 *        http://www.apache.org/licenses/LICENSE-2.0
 *
 *    Unless required by applicable law or agreed to in writing, software
 *    distributed under the License is distributed on an "AS IS" BASIS,
 *    WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 *    See the License for the specific language governing permissions and
 *    limitations under the License.
 */

package com.rackspacecloud.blueflood.cache;

public interface CacheStatsMBean {
    public long getHitCount();
    public double getHitRate();
    public long getMissCount();
    public double getMissRate();
    public long getLoadCount();
    public long getRequestCount();
    public long getTotalLoadTime();
}


File: blueflood-core/src/main/java/com/rackspacecloud/blueflood/cache/MetadataCache.java
/*
 * Copyright 2015 Rackspace
 *
 *    Licensed under the Apache License, Version 2.0 (the "License");
 *    you may not use this file except in compliance with the License.
 *    You may obtain a copy of the License at
 *
 *        http://www.apache.org/licenses/LICENSE-2.0
 *
 *    Unless required by applicable law or agreed to in writing, software
 *    distributed under the License is distributed on an "AS IS" BASIS,
 *    WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 *    See the License for the specific language governing permissions and
 *    limitations under the License.
 */

package com.rackspacecloud.blueflood.cache;


import com.codahale.metrics.*;
import com.codahale.metrics.Timer;
import com.google.common.cache.CacheBuilder;
import com.google.common.cache.CacheLoader;
import com.google.common.cache.CacheStats;
import com.google.common.collect.HashBasedTable;
import com.google.common.collect.Table;
import com.rackspacecloud.blueflood.concurrent.ThreadPoolBuilder;
import com.rackspacecloud.blueflood.exceptions.CacheException;
import com.rackspacecloud.blueflood.io.AstyanaxMetadataIO;
import com.rackspacecloud.blueflood.io.MetadataIO;
import com.rackspacecloud.blueflood.service.Configuration;
import com.rackspacecloud.blueflood.service.CoreConfig;
import com.rackspacecloud.blueflood.types.Locator;
import com.rackspacecloud.blueflood.utils.Metrics;
import com.rackspacecloud.blueflood.utils.TimeValue;
import org.slf4j.Logger;
import org.slf4j.LoggerFactory;

import javax.management.InstanceAlreadyExistsException;
import javax.management.MBeanServer;
import javax.management.ObjectName;
import java.io.DataInputStream;
import java.io.DataOutputStream;
import java.io.IOException;
import java.lang.management.ManagementFactory;
import java.util.concurrent.ExecutionException;
import java.util.concurrent.TimeUnit;
import java.util.*;
import java.util.concurrent.*;

public class MetadataCache extends AbstractJmxCache implements MetadataCacheMBean {
    // todo: give each cache a name.

    private final com.google.common.cache.LoadingCache<CacheKey, String> cache;
    private static final String NULL = "null".intern();
    private static final Logger log = LoggerFactory.getLogger(MetadataCache.class);
    private static final TimeValue defaultExpiration = new TimeValue(Configuration.getInstance().getIntegerProperty(
            CoreConfig.META_CACHE_RETENTION_IN_MINUTES), TimeUnit.MINUTES);
    private static final int defaultConcurrency = Configuration.getInstance().getIntegerProperty(
            CoreConfig.META_CACHE_MAX_CONCURRENCY);
    private final Boolean batchedReads;
    private final Boolean batchedWrites;

    // Specific to batched meta reads

    private static final Integer batchedReadsThreshold = Configuration.getInstance().getIntegerProperty(
            CoreConfig.META_CACHE_BATCHED_READS_THRESHOLD);
    private static final Integer batchedReadsTimerConfig = Configuration.getInstance().getIntegerProperty(
            CoreConfig.META_CACHE_BATCHED_READS_TIMER_MS);
    private static final TimeValue batchedReadsInterval = new TimeValue(batchedReadsTimerConfig, TimeUnit.MILLISECONDS);
    private static final Integer batchedReadsPipelineLimit = Configuration.getInstance().getIntegerProperty(
            CoreConfig.META_CACHE_BATCHED_READS_PIPELINE_DEPTH);

    private final java.util.Timer batchedReadsTimer = new java.util.Timer("MetadataBatchedReads");
    private final ThreadPoolExecutor readThreadPoolExecutor;
    private final Set<Locator> outstandingMetaReads;
    private final Queue<Locator> metaReads; // Guarantees FIFO reads
    private static final Timer batchedReadsTimerMetric = Metrics.timer(MetadataCache.class, "Metadata batched reads timer");

    // Specific to batched meta writes

    private static final Integer batchedWritesThreshold = Configuration.getInstance().getIntegerProperty(
            CoreConfig.META_CACHE_BATCHED_WRITES_THRESHOLD);
    private static final Integer batchedWritesTimerConfig = Configuration.getInstance().getIntegerProperty(
            CoreConfig.META_CACHE_BATCHED_WRITES_TIMER_MS);
    private static final TimeValue batchedWritesInterval = new TimeValue(batchedWritesTimerConfig, TimeUnit.MILLISECONDS);
    private static final Integer batchedWritesPipelineLimit = Configuration.getInstance().getIntegerProperty(
            CoreConfig.META_CACHE_BATCHED_WRITES_PIPELINE_DEPTH);

    private final java.util.Timer batchedWritesTimer = new java.util.Timer("MetadataBatchedWrites");
    private final ThreadPoolExecutor writeThreadPoolExecutor;
    private final Set<CacheKey> outstandingMetaWrites;
    private final Queue<CacheKey> metaWrites; // Guarantees FIFO writes
    private static final Timer batchedWritesTimerMetric = Metrics.timer(MetadataCache.class, "Metadata batched writes timer");

    private static final MetadataCache INSTANCE = new MetadataCache(defaultExpiration, defaultConcurrency);
    private MetadataIO io = new AstyanaxMetadataIO();
    private static Timer cacheSaveTimer = Metrics.timer(MetadataCache.class, "Persistence Save");
    private static Timer cacheLoadTimer = Metrics.timer(MetadataCache.class, "Persistence Load");
    private static final Meter updatedMetricMeter = Metrics.meter(MetadataCache.class, "Received updated metric");
    private static final Histogram totalMetadataSize = Metrics.histogram(MetadataCache.class, "Metadata row size");
    private static final Timer cacheGetTimer = Metrics.timer(MetadataCache.class, "Metadata get timer");
    private static final Timer cachePutTimer = Metrics.timer(MetadataCache.class, "Metadata put timer");
    private final Gauge cacheSizeGauge = new Gauge<Long>() {
        @Override
        public Long getValue() {
            return cache.size();
        }
    };

    private MetadataCache(TimeValue expiration, int concurrency) {
        try {
            final MBeanServer mbs = ManagementFactory.getPlatformMBeanServer();
            final String name = String.format(MetadataCache.class.getPackage().getName() + ":type=%s,name=Stats", MetadataCache.class.getSimpleName());
            final ObjectName nameObj = new ObjectName(name);
            mbs.registerMBean(this, nameObj);
            instantiateYammerMetrics(MetadataCache.class, "metadata", nameObj);
        } catch (InstanceAlreadyExistsException doNotCare) {
            log.debug(doNotCare.getMessage());
        } catch (Exception ex) {
            log.error("Unable to register mbean for " + getClass().getName(), ex);
        }

        CacheLoader<CacheKey, String> loader = new CacheLoader<CacheKey, String>() {
            @Override
            public String load(CacheKey key) throws Exception {
                return MetadataCache.this.databaseLoad(key.locator, key.keyString);
            }
        };
        cache = CacheBuilder.newBuilder()
                .expireAfterWrite(expiration.getValue(), expiration.getUnit())
                .concurrencyLevel(concurrency)
                .recordStats()
                .build(loader);
        try {
            Metrics.getRegistry().register(MetricRegistry.name(MetadataCache.class, "Cache Size"), this.cacheSizeGauge);
        } catch (Exception e) {
            // pass
        }
        this.outstandingMetaReads = new ConcurrentSkipListSet<Locator>();
        this.metaReads = new ConcurrentLinkedQueue<Locator>();
        this.readThreadPoolExecutor = new ThreadPoolBuilder().withCorePoolSize(batchedReadsPipelineLimit)
                .withMaxPoolSize(batchedReadsPipelineLimit)
                .withBoundedQueue(Configuration.getInstance()
                        .getIntegerProperty(CoreConfig.META_CACHE_BATCHED_READS_QUEUE_SIZE))
                .withName("MetaBatchedReadsThreadPool").build();

        this.batchedReads = Configuration.getInstance().getBooleanProperty(
                CoreConfig.META_CACHE_BATCHED_READS);
        this.batchedWrites = Configuration.getInstance().getBooleanProperty(
                CoreConfig.META_CACHE_BATCHED_WRITES);
        if (batchedReads) {
            this.batchedReadsTimer.schedule(new TimerTask() {
                @Override
                public void run() {
                    fetchMeta(true);
                }
            }, 0, this.batchedReadsInterval.toMillis());
        }
        this.outstandingMetaWrites = new ConcurrentSkipListSet<CacheKey>();
        this.writeThreadPoolExecutor = new ThreadPoolBuilder().withCorePoolSize(batchedWritesPipelineLimit)
                .withMaxPoolSize(batchedWritesPipelineLimit)
                .withBoundedQueue(Configuration.getInstance()
                        .getIntegerProperty(CoreConfig.META_CACHE_BATCHED_WRITES_QUEUE_SIZE))
                .withName("MetaBatchedWritesThreadPool").build();
        this.metaWrites = new ConcurrentLinkedQueue<CacheKey>();

        if (batchedWrites) {
            this.batchedWritesTimer.schedule(new TimerTask() {
                @Override
                public void run() {
                    flushMeta(true);
                }
            }, 0, this.batchedWritesInterval.toMillis());
        }
    }
    
    public void setIO(MetadataIO io) {
        this.io = io;
        cache.invalidateAll();
    }

    public static MetadataCache getInstance() {
        return INSTANCE;
    }

    public static MetadataCache createLoadingCacheInstance() {
        return new MetadataCache(defaultExpiration, defaultConcurrency);
    }

    public static MetadataCache createLoadingCacheInstance(TimeValue expiration, int concurrency) {
        return new MetadataCache(expiration, concurrency);
    }
    
    public void save(DataOutputStream out) throws IOException {
        
        Timer.Context ctx = cacheSaveTimer.time();
        try {
        // convert to a table. this avoids us writing out the locator over and over.
            Map<CacheKey, String> map = new HashMap<CacheKey, String>(cache.asMap());
            Table<Locator, String, String> table = HashBasedTable.create();
            for (Map.Entry<CacheKey, String> entry : map.entrySet()) {
                table.put(entry.getKey().locator, entry.getKey().keyString, entry.getValue());
            }
            
            Set<Locator> rowKeys = table.rowKeySet();
            out.writeInt(rowKeys.size());
            
            for (Locator locator : rowKeys) {
                out.writeUTF(locator.toString());
                
                // how many key/value pairs are there?
                Map<String, String> pairs = table.row(locator);
                out.writeInt(pairs.size());
                for (Map.Entry<String, String> entry : pairs.entrySet()) {
                    out.writeUTF(entry.getKey());
                    out.writeUTF(entry.getValue());
                }
            }
        } finally {
            ctx.stop();
        }
    }
    
    public void load(DataInputStream in) throws IOException {
        Timer.Context ctx = cacheLoadTimer.time();
        try {
            int numLocators = in.readInt();
            for (int locIndex = 0; locIndex < numLocators; locIndex++) {
                Locator locator = Locator.createLocatorFromDbKey(in.readUTF());
                int numPairs = in.readInt();
                for (int pairIndex = 0; pairIndex < numPairs; pairIndex++) {
                    cache.put(new CacheKey(locator, in.readUTF()), in.readUTF());
                }
            }
        } finally {
            ctx.stop();
        }
    }

    public boolean containsKey(Locator locator, String key) {
        return cache.getIfPresent(new CacheKey(locator, key)) != null;
    }

    public String get(Locator locator, String key) throws CacheException {
        if (!batchedReads) {
            return getImmediately(locator, key);
        }

        String val = cache.getIfPresent(new CacheKey(locator, key));

        if (val == null) {
            databaseLazyLoad(locator); // loads all meta for the locator (optimized to prevent duplicate reads)
        }

        return val;
    }

    public String getImmediately(Locator locator, String key) throws CacheException {
        Timer.Context cacheGetTimerContext = cacheGetTimer.time();
        try {
            CacheKey cacheKey = new CacheKey(locator, key);
            String result = cache.get(cacheKey);
            if (result.equals(NULL)) {
                return null;
            } else {
                return result;
            }
        } catch (ExecutionException ex) {
            throw new CacheException(ex);
        } finally {
            cacheGetTimerContext.stop();
        }
    }

    public <T> T get(Locator locator, String key, Class<T> type) throws CacheException {
        try {
            String val = get(locator, key);
            if (val == null) {
                return null;
            }
            return (T) val;
        } catch (ClassCastException ex) {
            throw new CacheException(ex);
        }
    }

    // todo: synchronization?
    // returns true if updated.
    public boolean put(Locator locator, String key, String value) throws CacheException {
        if (value == null) return false;

        Timer.Context cachePutTimerContext = MetadataCache.cachePutTimer.time();
        boolean dbWrite = false;
        try {
            CacheKey cacheKey = new CacheKey(locator, key);
            String oldValue = cache.getIfPresent(cacheKey);
            // don't care if oldValue == EMPTY.
            // always put new value in the cache. it keeps reads from happening.
            cache.put(cacheKey, value);
            if (oldValue == null || !oldValue.equals(value)) {
                dbWrite = true;
            }

            if (dbWrite) {
                updatedMetricMeter.mark();
                if (!batchedWrites) {
                    databasePut(locator, key, value);
                } else {
                    databaseLazyWrite(locator, key);
                }
            }

            return dbWrite;
        } finally {
            cachePutTimerContext.stop();
        }
    }

    public void invalidate(Locator locator, String key) {
        cache.invalidate(new CacheKey(locator, key));
    }

    private void databasePut(Locator locator, String key, String value) throws CacheException {
        try {
            io.put(locator, key, value);
        } catch (IOException ex) {
            throw new CacheException(ex);
        }
    }

    // implements the CacheLoader interface.
    private String databaseLoad(Locator locator, String key) throws CacheException {
        try {
            CacheKey cacheKey = new CacheKey(locator, key);
            Map<String, String> metadata = io.getAllValues(locator);
            if (metadata == null || metadata.isEmpty()) {
                cache.put(cacheKey, NULL);
                return NULL;
            }

            int metadataRowSize = 0;
            // prepopulate all other metadata other than the key we called the method with
            for (Map.Entry<String, String> meta : metadata.entrySet()) {
                metadataRowSize += meta.getKey().getBytes().length + locator.toString().getBytes().length;
                if (meta.getValue() != null)
                    metadataRowSize += meta.getValue().getBytes().length;
                if (meta.getKey().equals(key)) continue;
                CacheKey metaKey = new CacheKey(locator, meta.getKey());
                cache.put(metaKey, meta.getValue());
            }
            totalMetadataSize.update(metadataRowSize);

            String value = metadata.get(key);

            if (value == null) {
                cache.put(cacheKey, NULL);
                value = NULL;
            }

            return value;
        } catch (IOException ex) {
            throw new CacheException(ex);
        }
    }

    private void databaseLazyLoad(Locator locator) {
        boolean isPresent = outstandingMetaReads.contains(locator);

        if (!isPresent) {
            metaReads.add(locator);
            outstandingMetaReads.add(locator);
        }

        // Kickoff fetch meta if necessary
        if (metaReads.size() > batchedReadsThreshold) {
            fetchMeta(false);
        }
    }

    private void databaseLazyWrite(Locator locator, String metaKey) {
        CacheKey compoundKey = new CacheKey(locator, metaKey);
        if (outstandingMetaWrites.contains(compoundKey)) {
            return; // already queued up to write.
        }

        outstandingMetaWrites.add(compoundKey);
        metaWrites.add(compoundKey);

        if (metaWrites.size() > batchedWritesThreshold) {
            flushMeta(false);
        }

        return;
    }

    private void fetchMeta(boolean forced) { // Only one thread should ever call into this.
        synchronized (metaReads) {
            if (!forced && metaReads.size() < batchedReadsThreshold) {
                return;
            }

            while (!metaReads.isEmpty()) {
                Set<Locator> batch = new HashSet<Locator>();

                for (int i = 0; !metaReads.isEmpty() && i < batchedReadsThreshold; i++) {
                    batch.add(metaReads.poll()); // poll() is a destructive read (removes the head from the queue).
                }

                readThreadPoolExecutor.submit(new BatchedMetaReadsRunnable(batch));
            }
        }
    }

    private void flushMeta(boolean forced) { // Only one thread should ever call into this.
        synchronized (metaWrites) {
            if (!forced && metaWrites.size() < batchedWritesThreshold) {
                return;
            }

            while (!metaWrites.isEmpty()) {
                Table<Locator, String, String> metaBatch = HashBasedTable.create();

                for (int i = 0; !metaWrites.isEmpty() && i < batchedWritesThreshold; i++) {
                    CacheKey compoundKey = metaWrites.poll(); // destructive read.
                    Locator locator = compoundKey.locator();
                    String metaKey = compoundKey.keyString();
                    String metaVal = cache.getIfPresent(compoundKey);
                    if (metaVal != null) {
                        metaBatch.put(locator, metaKey, metaVal);
                    }
                }

                writeThreadPoolExecutor.submit(new BatchedMetaWritesRunnable(metaBatch));
            }
        }
    }

    private final class CacheKey implements Comparable<CacheKey> {
        private final Locator locator;
        private final String keyString;
        private final int hashCode;

        CacheKey(Locator locator, String keyString) {
            this.locator = locator;
            this.keyString = keyString;
            hashCode = (locator.toString() + "," + keyString).hashCode();
        }

        @Override
        public int hashCode() {
            return hashCode;
        }

        public Locator locator() {
            return locator;
        }

        public String keyString() {
            return keyString;
        }

        @Override
        public boolean equals(Object obj) {
            if (!(obj instanceof CacheKey)) return false;
            CacheKey other = (CacheKey)obj;
            // kind of a cop-out.
            return (locator().equals(other.locator) && keyString().equals(other.keyString()));
        }

        @Override
        public String toString() {
            return locator.toString() + "," + keyString;
        }

        @Override
        public int compareTo(CacheKey o) {
            return this.toString().compareTo(o.toString());
        }
    }

    @Override
    public CacheStats getStats() {
        return cache.stats();
    }

    private class BatchedMetaReadsRunnable implements Runnable {
        private final Set<Locator> locators;

        public BatchedMetaReadsRunnable(Set<Locator> locators) {
            this.locators = locators;
        }

        @Override
        public void run() {
            Timer.Context ctx = batchedReadsTimerMetric.time();
            try {
                Table<Locator, String, String> metaTable = io.getAllValues(locators);
                int metadataRowSize = 0;

                for (Locator locator : metaTable.rowKeySet()) {
                    Map<String, String> metaMapForLocator = metaTable.row(locator);

                    for (Map.Entry<String, String> meta : metaMapForLocator.entrySet()) {
                        CacheKey metaKey = new CacheKey(locator, meta.getKey());
                        String existing = cache.getIfPresent(metaKey);

                        if (existing == null) {
                            cache.put(metaKey, meta.getValue());
                        }

                        boolean differs = existing != null && !existing.equals(meta.getValue());
                        if (differs) {
                            log.warn("Meta " + meta.getKey() + " changed from " + existing + " to " + meta.getValue()
                                    + " for locator " + locator); // delayed audit log.
                            // In this case, do not update the cache. DB has stale data.
                            continue;
                        }

                        metadataRowSize += meta.getKey().getBytes().length + locator.toString().getBytes().length;
                        metadataRowSize += meta.getValue().getBytes().length;
                    }

                    // Got the meta for locator. Remove this from the place holder.
                    outstandingMetaReads.remove(locator);
                }

                totalMetadataSize.update(metadataRowSize);
                // Kickoff fetch meta if necessary
                if (metaReads.size() > batchedReadsThreshold) {
                    fetchMeta(false);
                }
            } catch (Exception ex) {
                // Queue up the locators again (at the end)!
                for (Locator locator : locators) {
                    metaReads.add(locator);
                }
                log.error("Exception reading metadata from db (batched reads)", ex);
            } finally {
                ctx.stop();
            }
        }
    }

    private class BatchedMetaWritesRunnable implements Runnable {
        private final Table<Locator, String, String> metaToWrite;

        public BatchedMetaWritesRunnable(Table<Locator, String, String> metaToWrite) {
            this.metaToWrite = metaToWrite;
        }

        @Override
        public void run() {
            Timer.Context ctx = batchedWritesTimerMetric.time();
            try {
                io.putAll(metaToWrite);
            } catch (Exception ex) {
                log.error("Exception writing metadata to db (batched writes)", ex);
                // Queue up writes at the end.
                for (Locator locator : metaToWrite.rowKeySet()) {
                    Map<String, String> metaMapForLocator = metaToWrite.row(locator);

                    for (Map.Entry<String, String> meta : metaMapForLocator.entrySet()) {
                        CacheKey compoundKey = new CacheKey(locator, meta.getKey());
                        metaWrites.add(compoundKey);
                        // This is fine. We always read the latest value from the real cache. So we'll pull the latest
                        // value to write.
                    }
                }
            } finally {
                ctx.stop();
            }
        }
    }
}


File: blueflood-core/src/main/java/com/rackspacecloud/blueflood/cache/MetadataCacheMBean.java
/*
 * Copyright 2015 Rackspace
 *
 *    Licensed under the Apache License, Version 2.0 (the "License");
 *    you may not use this file except in compliance with the License.
 *    You may obtain a copy of the License at
 *
 *        http://www.apache.org/licenses/LICENSE-2.0
 *
 *    Unless required by applicable law or agreed to in writing, software
 *    distributed under the License is distributed on an "AS IS" BASIS,
 *    WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 *    See the License for the specific language governing permissions and
 *    limitations under the License.
 */

package com.rackspacecloud.blueflood.cache;

public interface MetadataCacheMBean extends CacheStatsMBean {
}


File: blueflood-core/src/main/java/com/rackspacecloud/blueflood/concurrent/ThreadPoolBuilder.java
/*
 * Copyright 2015 Rackspace
 *
 *    Licensed under the Apache License, Version 2.0 (the "License");
 *    you may not use this file except in compliance with the License.
 *    You may obtain a copy of the License at
 *
 *        http://www.apache.org/licenses/LICENSE-2.0
 *
 *    Unless required by applicable law or agreed to in writing, software
 *    distributed under the License is distributed on an "AS IS" BASIS,
 *    WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 *    See the License for the specific language governing permissions and
 *    limitations under the License.
 */

package com.rackspacecloud.blueflood.concurrent;

import com.google.common.util.concurrent.ThreadFactoryBuilder;
import com.rackspacecloud.blueflood.utils.TimeValue;
import org.slf4j.Logger;
import org.slf4j.LoggerFactory;

import java.util.concurrent.*;
import java.util.concurrent.atomic.AtomicInteger;

public class ThreadPoolBuilder {
    private static final Logger log = LoggerFactory.getLogger(ThreadPoolBuilder.class);
    /** Used to ensure that the thread pools have unique name. */
    private static final ConcurrentHashMap<String, AtomicInteger> nameMap = new ConcurrentHashMap<String, AtomicInteger>();
    private static final String DEFAULT_NAME = "Threadpool";
    private int corePoolSize = 10;
    private int maxPoolSize = 10;
    private int queueSize = 0;
    private TimeValue keepAliveTime = new TimeValue(30, TimeUnit.SECONDS);
    
    private RejectedExecutionHandler rejectedHandler = new ThreadPoolExecutor.CallerRunsPolicy();
    private Thread.UncaughtExceptionHandler exceptionHandler = new Thread.UncaughtExceptionHandler() {
        public void uncaughtException(Thread t, Throwable e) {
            log.error(e.getMessage(), e);
        }
    };

    private String threadNameFormat = null;
    private String poolName = null;

    public ThreadPoolBuilder() {
        withName(DEFAULT_NAME);
    }

    public ThreadPoolBuilder withCorePoolSize(int size) {
        this.corePoolSize = size;
        return this;
    }

    public ThreadPoolBuilder withMaxPoolSize(int size) {
        this.maxPoolSize = size;
        return this;
    }

    public ThreadPoolBuilder withSynchronousQueue() {
        this.queueSize = 0;
        return this;
    }

    public ThreadPoolBuilder withUnboundedQueue() {
        this.queueSize = -1;
        return this;
    }

    public ThreadPoolBuilder withBoundedQueue(int size) {
        this.queueSize = size;
        return this;
    }
    
    public ThreadPoolBuilder withKeepAliveTime(TimeValue time) {
        this.keepAliveTime = time;
        return this;
    }

    public ThreadPoolBuilder withRejectedHandler(RejectedExecutionHandler rejectedHandler) {
        this.rejectedHandler = rejectedHandler;
        return this;
    }

    /**
     * Set the threadpool name. Used to generate metric names and thread names.
     */
    public ThreadPoolBuilder withName(String name) {
        // ensure we've got a spot to put the thread id.
        if (!name.contains("%d")) {
            name = name + "-%d";
        }
        nameMap.putIfAbsent(name, new AtomicInteger(0));
        int id = nameMap.get(name).incrementAndGet();
        this.poolName = String.format(name, id);
        if (id > 1) {
            this.threadNameFormat = name.replace("%d", id + "-%d");
        } else {
            this.threadNameFormat = name;
        }
        return this;
    }

    public ThreadPoolBuilder withExceptionHandler(Thread.UncaughtExceptionHandler exceptionHandler) {
        this.exceptionHandler = exceptionHandler;
        return this;
    }

    public ThreadPoolExecutor build() {
        BlockingQueue<Runnable> workQueue;
        switch (this.queueSize) {
            case 0: workQueue = new SynchronousQueue<Runnable>();
                break;
            case -1: workQueue = new LinkedBlockingQueue<Runnable>();
                break;
            default: workQueue = new ArrayBlockingQueue<Runnable>(queueSize);
                break;
        };

        ThreadPoolExecutor executor = new ThreadPoolExecutor(
                corePoolSize, maxPoolSize,
                keepAliveTime.getValue(), keepAliveTime.getUnit(),
                workQueue,
                new ThreadFactoryBuilder().setNameFormat(threadNameFormat).setPriority(Thread.NORM_PRIORITY).setUncaughtExceptionHandler(exceptionHandler).build(),
                rejectedHandler);
        InstrumentedThreadPoolExecutor.instrument(executor, poolName);
        return executor;
    }
}

File: blueflood-core/src/main/java/com/rackspacecloud/blueflood/eventemitter/RollupEvent.java
/*
* Copyright 2015 Rackspace
*
*    Licensed under the Apache License, Version 2.0 (the "License");
*    you may not use this file except in compliance with the License.
*    You may obtain a copy of the License at
*
*        http://www.apache.org/licenses/LICENSE-2.0
*
*    Unless required by applicable law or agreed to in writing, software
*    distributed under the License is distributed on an "AS IS" BASIS,
*    WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
*    See the License for the specific language governing permissions and
*    limitations under the License.
*/

package com.rackspacecloud.blueflood.eventemitter;

import com.rackspacecloud.blueflood.types.Locator;
import com.rackspacecloud.blueflood.types.Rollup;

public class RollupEvent {
    private final Locator locator;
    private final Rollup rollup;
    private String unit;
    private final String granularityName;
    //Rollup slot in millis
    private final long timestamp;

    public RollupEvent(Locator loc, Rollup rollup, String unit, String gran, long ts) {
        this.locator = loc;
        this.rollup = rollup;
        this.unit = unit;
        this.granularityName = gran;
        this.timestamp = ts;
    }

    public Rollup getRollup() {
        return rollup;
    }

    public Locator getLocator() {
        return locator;
    }

    public String getUnit() {
        return unit;
    }

    public String getGranularityName() {
        return granularityName;
    }

    public long getTimestamp() {
        return timestamp;
    }

    public void setUnit(String unit) {
        this.unit = unit;
    }
}


File: blueflood-core/src/main/java/com/rackspacecloud/blueflood/eventemitter/RollupEventEmitter.java
/*
* Copyright 2015 Rackspace
*
*    Licensed under the Apache License, Version 2.0 (the "License");
*    you may not use this file except in compliance with the License.
*    You may obtain a copy of the License at
*
*        http://www.apache.org/licenses/LICENSE-2.0
*
*    Unless required by applicable law or agreed to in writing, software
*    distributed under the License is distributed on an "AS IS" BASIS,
*    WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
*    See the License for the specific language governing permissions and
*    limitations under the License.
*/

package com.rackspacecloud.blueflood.eventemitter;

import com.google.common.base.Function;
import com.google.common.collect.Lists;
import com.rackspacecloud.blueflood.concurrent.ThreadPoolBuilder;
import com.rackspacecloud.blueflood.io.DiscoveryIO;
import com.rackspacecloud.blueflood.types.BasicRollup;
import com.rackspacecloud.blueflood.utils.QueryDiscoveryModuleLoader;
import com.rackspacecloud.blueflood.utils.Util;
import org.slf4j.Logger;
import org.slf4j.LoggerFactory;

import java.util.Arrays;
import java.util.concurrent.*;

public class RollupEventEmitter extends Emitter<RollupEvent> {
    private static final Logger log = LoggerFactory.getLogger(QueryDiscoveryModuleLoader.class);
    private static final int numberOfWorkers = 5;
    public static final String ROLLUP_EVENT_NAME = "rollup".intern();
    private static ThreadPoolExecutor eventExecutors;
    private static final RollupEventEmitter instance = new RollupEventEmitter();

    private RollupEventEmitter() {
        eventExecutors = new ThreadPoolBuilder()
                .withName("RollupEventEmitter ThreadPool")
                .withCorePoolSize(numberOfWorkers)
                .withMaxPoolSize(numberOfWorkers)
                .withUnboundedQueue()
                .build();
    }

    public static RollupEventEmitter getInstance() { return instance; }

    @Override
    public Future emit(final String event, final RollupEvent... eventPayload) {
        //TODO: This hack will go away after Kafka Serializer is made generic
        Future emitFuture = null;
        if(eventPayload[0].getRollup() instanceof BasicRollup && super.hasListeners(ROLLUP_EVENT_NAME)) {
            emitFuture = eventExecutors.submit(new Callable() {
                @Override
                public Future call() {
                    if (Util.shouldUseESForUnits()) {
                        QueryDiscoveryModuleLoader.loadDiscoveryModule();
                        final DiscoveryIO discoveryIO = QueryDiscoveryModuleLoader.getDiscoveryInstance();
                        // TODO: Sync for now, but we will have to make it async eventually
                        Lists.transform(Arrays.asList(eventPayload), new Function<RollupEvent, RollupEvent>() {
                            @Override
                            public RollupEvent apply(RollupEvent event) {
                                String unit;
                                try {
                                    unit = discoveryIO.search(event.getLocator().getTenantId(), event.getLocator().getMetricName()).get(0).getUnit();
                                } catch (Exception e) {
                                    log.warn("Exception encountered while getting units out of ES : %s", e.getMessage());
                                    unit = Util.UNKNOWN;
                                }
                                event.setUnit(unit);
                                return event;
                            }
                        });
                    }
                    return RollupEventEmitter.super.emit(event, eventPayload);
                }
            });
        }
        return emitFuture;
    }
}


File: blueflood-core/src/main/java/com/rackspacecloud/blueflood/exceptions/CacheException.java
/*
 * Copyright 2015 Rackspace
 *
 *    Licensed under the Apache License, Version 2.0 (the "License");
 *    you may not use this file except in compliance with the License.
 *    You may obtain a copy of the License at
 *
 *        http://www.apache.org/licenses/LICENSE-2.0
 *
 *    Unless required by applicable law or agreed to in writing, software
 *    distributed under the License is distributed on an "AS IS" BASIS,
 *    WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 *    See the License for the specific language governing permissions and
 *    limitations under the License.
 */

package com.rackspacecloud.blueflood.exceptions;

// todo: consider just dropping this for IOException.
public class CacheException extends Exception {
    public CacheException(Throwable cause) {
        super(cause);
    }
    
    public CacheException(String wha) {
        super(wha);
    }
}


File: blueflood-core/src/main/java/com/rackspacecloud/blueflood/exceptions/GranularityException.java
/*
 * Copyright 2015 Rackspace
 *
 *    Licensed under the Apache License, Version 2.0 (the "License");
 *    you may not use this file except in compliance with the License.
 *    You may obtain a copy of the License at
 *
 *        http://www.apache.org/licenses/LICENSE-2.0
 *
 *    Unless required by applicable law or agreed to in writing, software
 *    distributed under the License is distributed on an "AS IS" BASIS,
 *    WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 *    See the License for the specific language governing permissions and
 *    limitations under the License.
 */

package com.rackspacecloud.blueflood.exceptions;

public class GranularityException extends Exception {

    public GranularityException(String message) {
        super(message);
    }
}


File: blueflood-core/src/main/java/com/rackspacecloud/blueflood/exceptions/IncomingMetricException.java
/*
 * Copyright 2015 Rackspace
 *
 *    Licensed under the Apache License, Version 2.0 (the "License");
 *    you may not use this file except in compliance with the License.
 *    You may obtain a copy of the License at
 *
 *        http://www.apache.org/licenses/LICENSE-2.0
 *
 *    Unless required by applicable law or agreed to in writing, software
 *    distributed under the License is distributed on an "AS IS" BASIS,
 *    WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 *    See the License for the specific language governing permissions and
 *    limitations under the License.
 */

package com.rackspacecloud.blueflood.exceptions;

public abstract class IncomingMetricException extends Exception {
    public IncomingMetricException(String message) {
        super(message);
    }
}


File: blueflood-core/src/main/java/com/rackspacecloud/blueflood/exceptions/IncomingTypeException.java
/*
 * Copyright 2015 Rackspace
 *
 *    Licensed under the Apache License, Version 2.0 (the "License");
 *    you may not use this file except in compliance with the License.
 *    You may obtain a copy of the License at
 *
 *        http://www.apache.org/licenses/LICENSE-2.0
 *
 *    Unless required by applicable law or agreed to in writing, software
 *    distributed under the License is distributed on an "AS IS" BASIS,
 *    WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 *    See the License for the specific language governing permissions and
 *    limitations under the License.
 */

package com.rackspacecloud.blueflood.exceptions;

import com.rackspacecloud.blueflood.exceptions.IncomingMetricException;
import com.rackspacecloud.blueflood.types.Locator;

public class IncomingTypeException extends IncomingMetricException {
    private final Locator locator;
    private final String oldType;
    private final String newType;
    
    public IncomingTypeException(Locator locator, String oldType, String newType) {
        super(String.format("Detected type change for %s %s->%s", locator.toString(), oldType, newType));
        this.locator = locator;
        this.oldType = oldType;
        this.newType = newType;
    }
}


File: blueflood-core/src/main/java/com/rackspacecloud/blueflood/exceptions/IncomingUnitException.java
/*
 * Copyright 2015 Rackspace
 *
 *    Licensed under the Apache License, Version 2.0 (the "License");
 *    you may not use this file except in compliance with the License.
 *    You may obtain a copy of the License at
 *
 *        http://www.apache.org/licenses/LICENSE-2.0
 *
 *    Unless required by applicable law or agreed to in writing, software
 *    distributed under the License is distributed on an "AS IS" BASIS,
 *    WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 *    See the License for the specific language governing permissions and
 *    limitations under the License.
 */

package com.rackspacecloud.blueflood.exceptions;

import com.rackspacecloud.blueflood.exceptions.IncomingMetricException;
import com.rackspacecloud.blueflood.types.Locator;

public class IncomingUnitException extends IncomingMetricException {
    private final Locator locator;
    private final String oldUnit;
    private final String newUnit;

    public IncomingUnitException(Locator locator, String oldUnit, String newUnit) {
        super(String.format("Detected unit change for %s %s->%s", locator.toString(), oldUnit, newUnit));
        this.locator = locator;
        this.oldUnit = oldUnit;
        this.newUnit = newUnit;
    }
}


File: blueflood-core/src/main/java/com/rackspacecloud/blueflood/exceptions/InvalidRequestException.java
/*
 * Copyright 2015 Rackspace
 *
 *    Licensed under the Apache License, Version 2.0 (the "License");
 *    you may not use this file except in compliance with the License.
 *    You may obtain a copy of the License at
 *
 *        http://www.apache.org/licenses/LICENSE-2.0
 *
 *    Unless required by applicable law or agreed to in writing, software
 *    distributed under the License is distributed on an "AS IS" BASIS,
 *    WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 *    See the License for the specific language governing permissions and
 *    limitations under the License.
 */

package com.rackspacecloud.blueflood.exceptions;

public class InvalidRequestException extends Exception {

    public InvalidRequestException(String message) {
        super(message);
    }
}


File: blueflood-core/src/main/java/com/rackspacecloud/blueflood/exceptions/SerializationException.java
/*
 * Copyright 2015 Rackspace
 *
 *    Licensed under the Apache License, Version 2.0 (the "License");
 *    you may not use this file except in compliance with the License.
 *    You may obtain a copy of the License at
 *
 *        http://www.apache.org/licenses/LICENSE-2.0
 *
 *    Unless required by applicable law or agreed to in writing, software
 *    distributed under the License is distributed on an "AS IS" BASIS,
 *    WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 *    See the License for the specific language governing permissions and
 *    limitations under the License.
 */

package com.rackspacecloud.blueflood.exceptions;

import java.io.IOException;

public class SerializationException extends IOException {
    public SerializationException(String message) {
        super(message);
    }
}


File: blueflood-core/src/main/java/com/rackspacecloud/blueflood/exceptions/UnexpectedStringSerializationException.java
/*
 * Copyright 2015 Rackspace
 *
 *    Licensed under the Apache License, Version 2.0 (the "License");
 *    you may not use this file except in compliance with the License.
 *    You may obtain a copy of the License at
 *
 *        http://www.apache.org/licenses/LICENSE-2.0
 *
 *    Unless required by applicable law or agreed to in writing, software
 *    distributed under the License is distributed on an "AS IS" BASIS,
 *    WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 *    See the License for the specific language governing permissions and
 *    limitations under the License.
 */

package com.rackspacecloud.blueflood.exceptions;

public class UnexpectedStringSerializationException extends SerializationException {
    public UnexpectedStringSerializationException(String message) {
        super(message);
    }
}


File: blueflood-core/src/main/java/com/rackspacecloud/blueflood/inputs/formats/JSONMetricsContainer.java
/*
 * Copyright 2015 Rackspace
 *
 *    Licensed under the Apache License, Version 2.0 (the "License");
 *    you may not use this file except in compliance with the License.
 *    You may obtain a copy of the License at
 *
 *        http://www.apache.org/licenses/LICENSE-2.0
 *
 *    Unless required by applicable law or agreed to in writing, software
 *    distributed under the License is distributed on an "AS IS" BASIS,
 *    WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 *    See the License for the specific language governing permissions and
 *    limitations under the License.
 */

package com.rackspacecloud.blueflood.inputs.formats;

import com.rackspacecloud.blueflood.types.Locator;
import com.rackspacecloud.blueflood.types.Metric;
import com.rackspacecloud.blueflood.utils.TimeValue;
import org.codehaus.jackson.annotate.JsonIgnore;

import java.util.ArrayList;
import java.util.List;
import java.util.concurrent.TimeUnit;

public class JSONMetricsContainer {
    private final String tenantId;
    private final List<JSONMetric> jsonMetrics;

    public JSONMetricsContainer(String tenantId, List<JSONMetric> metrics) {
        this.tenantId = tenantId;
        this.jsonMetrics = metrics;
    }

    public boolean isValid() {
        // Validate that any ScopedJSONMetric is actually scoped to a tenant.
        for (JSONMetric jsonMetric : this.jsonMetrics) {
            if (!jsonMetric.isValid()) {
                return false;
            }
        }
        return true;
    }

    public List<Metric> toMetrics() {
        if (jsonMetrics == null || jsonMetrics.isEmpty()) {
            return null;
        }

        final List<Metric> metrics = new ArrayList<Metric>();
        for (JSONMetric jsonMetric : jsonMetrics) {
            Locator locator;
            if (jsonMetric instanceof ScopedJSONMetric) {
                ScopedJSONMetric scopedMetric = (ScopedJSONMetric)jsonMetric;
                locator = Locator.createLocatorFromPathComponents(scopedMetric.getTenantId(), jsonMetric.getMetricName());
            } else {
                locator = Locator.createLocatorFromPathComponents(tenantId, jsonMetric.getMetricName());
            }

            if (jsonMetric.getMetricValue() != null) {
                final Metric metric = new Metric(locator, jsonMetric.getMetricValue(), jsonMetric.getCollectionTime(),
                        new TimeValue(jsonMetric.getTtlInSeconds(), TimeUnit.SECONDS), jsonMetric.getUnit());
                metrics.add(metric);
            }
        }

        return metrics;
    }

    // Jackson compatible class. Jackson uses reflection to call these methods and so they have to match JSON keys.
    public static class JSONMetric {
        private String metricName;
        private Object metricValue;
        private long collectionTime;
        private int ttlInSeconds;
        private String unit;

        public String getMetricName() {
            return metricName;
        }

        public void setMetricName(String metricName) {
            this.metricName = metricName;
        }

        public String getUnit() {
            return unit;
        }

        public void setUnit(String unit) {
            this.unit = unit;
        }

        public Object getMetricValue() {
            return metricValue;
        }

        public void setMetricValue(Object metricValue) {
            this.metricValue = metricValue;
        }

        public long getCollectionTime() {
            return collectionTime;
        }

        public void setCollectionTime(long collectionTime) {
            this.collectionTime = collectionTime;
        }

        public int getTtlInSeconds() {
            return this.ttlInSeconds;
        }

        public void setTtlInSeconds(int ttlInSeconds) {
            this.ttlInSeconds = ttlInSeconds;
        }

        @JsonIgnore
        public boolean isValid() {
            return true;
        }
    }

    public static class ScopedJSONMetric extends JSONMetric {
        private String tenantId;

        public String getTenantId() { return tenantId; }

        public void setTenantId(String tenantId) { this.tenantId = tenantId; }

        @JsonIgnore
        public boolean isValid() {
            return (tenantId != null && super.isValid());
        }
    }
}


File: blueflood-core/src/main/java/com/rackspacecloud/blueflood/io/AstyanaxIO.java
/*
 * Copyright 2015 Rackspace
 *
 *    Licensed under the Apache License, Version 2.0 (the "License");
 *    you may not use this file except in compliance with the License.
 *    You may obtain a copy of the License at
 *
 *        http://www.apache.org/licenses/LICENSE-2.0
 *
 *    Unless required by applicable law or agreed to in writing, software
 *    distributed under the License is distributed on an "AS IS" BASIS,
 *    WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 *    See the License for the specific language governing permissions and
 *    limitations under the License.
 */

package com.rackspacecloud.blueflood.io;

import com.netflix.astyanax.AstyanaxContext;
import com.netflix.astyanax.Keyspace;
import com.netflix.astyanax.connectionpool.NodeDiscoveryType;
import com.netflix.astyanax.connectionpool.impl.ConnectionPoolConfigurationImpl;
import com.netflix.astyanax.connectionpool.impl.ConnectionPoolType;
import com.netflix.astyanax.impl.AstyanaxConfigurationImpl;
import com.netflix.astyanax.retry.RetryNTimes;
import com.netflix.astyanax.serializers.AbstractSerializer;
import com.netflix.astyanax.serializers.BooleanSerializer;
import com.netflix.astyanax.serializers.StringSerializer;
import com.netflix.astyanax.thrift.ThriftFamilyFactory;
import com.rackspacecloud.blueflood.io.serializers.NumericSerializer;
import com.rackspacecloud.blueflood.rollup.Granularity;
import com.rackspacecloud.blueflood.service.Configuration;
import com.rackspacecloud.blueflood.service.CoreConfig;
import com.rackspacecloud.blueflood.types.DataType;
import com.rackspacecloud.blueflood.types.RollupType;

import java.util.*;

public class AstyanaxIO {
    private static final AstyanaxContext<Keyspace> context;
    private static final Keyspace keyspace;
    protected static final Configuration config = Configuration.getInstance();

    static {
        context = createPreferredHostContext();
        context.start();
        keyspace = context.getEntity();
    }

    protected AstyanaxIO() {
    }

    private static AstyanaxContext<Keyspace> createCustomHostContext(AstyanaxConfigurationImpl configuration,
            ConnectionPoolConfigurationImpl connectionPoolConfiguration) {
        return new AstyanaxContext.Builder()
                .forCluster(CassandraModel.CLUSTER)
                .forKeyspace(CassandraModel.KEYSPACE)
                .withAstyanaxConfiguration(configuration)
                .withConnectionPoolConfiguration(connectionPoolConfiguration)
                .withConnectionPoolMonitor(new InstrumentedConnectionPoolMonitor())
                .buildKeyspace(ThriftFamilyFactory.getInstance());
    }

    private static AstyanaxContext<Keyspace> createPreferredHostContext() {
        return createCustomHostContext(createPreferredAstyanaxConfiguration(), createPreferredConnectionPoolConfiguration());
    }

    private static AstyanaxConfigurationImpl createPreferredAstyanaxConfiguration() {
        AstyanaxConfigurationImpl astyconfig = new AstyanaxConfigurationImpl()
                .setDiscoveryType(NodeDiscoveryType.NONE)
                .setConnectionPoolType(ConnectionPoolType.ROUND_ROBIN);

        int numRetries = config.getIntegerProperty(CoreConfig.CASSANDRA_MAX_RETRIES);
        if (numRetries > 0) {
            astyconfig.setRetryPolicy(new RetryNTimes(numRetries));
        }

        return astyconfig;
    }

    private static ConnectionPoolConfigurationImpl createPreferredConnectionPoolConfiguration() {
        int port = config.getIntegerProperty(CoreConfig.DEFAULT_CASSANDRA_PORT);
        Set<String> uniqueHosts = new HashSet<String>();
        Collections.addAll(uniqueHosts, config.getStringProperty(CoreConfig.CASSANDRA_HOSTS).split(","));
        int numHosts = uniqueHosts.size();
        int maxConns = config.getIntegerProperty(CoreConfig.MAX_CASSANDRA_CONNECTIONS);
        int timeout = config.getIntegerProperty(CoreConfig.CASSANDRA_REQUEST_TIMEOUT);

        int connsPerHost = maxConns / numHosts + (maxConns % numHosts == 0 ? 0 : 1);
        // This timeout effectively results in waiting a maximum of (timeoutWhenExhausted / numHosts) on each Host
        int timeoutWhenExhausted = config.getIntegerProperty(CoreConfig.MAX_TIMEOUT_WHEN_EXHAUSTED);
        timeoutWhenExhausted = Math.max(timeoutWhenExhausted, 1 * numHosts); // Minimum of 1ms per host

        final ConnectionPoolConfigurationImpl connectionPoolConfiguration = new ConnectionPoolConfigurationImpl("MyConnectionPool")
                .setPort(port)
                .setSocketTimeout(timeout)
                .setInitConnsPerHost(connsPerHost)
                .setMaxConnsPerHost(connsPerHost)
                .setMaxBlockedThreadsPerHost(5)
                .setMaxTimeoutWhenExhausted(timeoutWhenExhausted)
                .setInitConnsPerHost(connsPerHost / 2)
                .setSeeds(config.getStringProperty(CoreConfig.CASSANDRA_HOSTS));
        return connectionPoolConfiguration;
    }

    protected static Keyspace getKeyspace() {
        return keyspace;
    }

    protected AbstractSerializer serializerFor(RollupType rollupType, DataType dataType, Granularity gran) {
        if (rollupType == null) {
            rollupType = RollupType.BF_BASIC;
        }

        if (dataType == null) {
            dataType = DataType.NUMERIC;
        }

        if (dataType.equals(DataType.STRING)) {
            return StringSerializer.get();
        } else if (dataType.equals(DataType.BOOLEAN)) {
            return BooleanSerializer.get();
        } else {
            return NumericSerializer.serializerFor(RollupType.classOf(rollupType, gran));
        }
    }
}


File: blueflood-core/src/main/java/com/rackspacecloud/blueflood/io/AstyanaxReader.java
/*
 * Copyright 2015 Rackspace
 *
 *    Licensed under the Apache License, Version 2.0 (the "License");
 *    you may not use this file except in compliance with the License.
 *    You may obtain a copy of the License at
 *
 *        http://www.apache.org/licenses/LICENSE-2.0
 *
 *    Unless required by applicable law or agreed to in writing, software
 *    distributed under the License is distributed on an "AS IS" BASIS,
 *    WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 *    See the License for the specific language governing permissions and
 *    limitations under the License.
 */

package com.rackspacecloud.blueflood.io;

import com.codahale.metrics.Timer;
import com.google.common.collect.ArrayListMultimap;
import com.google.common.collect.HashBasedTable;
import com.google.common.collect.ListMultimap;
import com.google.common.collect.Table;
import com.netflix.astyanax.Keyspace;
import com.netflix.astyanax.connectionpool.OperationResult;
import com.netflix.astyanax.connectionpool.exceptions.ConnectionException;
import com.netflix.astyanax.connectionpool.exceptions.NotFoundException;
import com.netflix.astyanax.model.*;
import com.netflix.astyanax.query.RowQuery;
import com.netflix.astyanax.serializers.AbstractSerializer;
import com.netflix.astyanax.serializers.BooleanSerializer;
import com.netflix.astyanax.serializers.StringSerializer;
import com.netflix.astyanax.shallows.EmptyColumnList;
import com.netflix.astyanax.util.RangeBuilder;
import com.rackspacecloud.blueflood.cache.MetadataCache;
import com.rackspacecloud.blueflood.exceptions.CacheException;
import com.rackspacecloud.blueflood.io.serializers.NumericSerializer;
import com.rackspacecloud.blueflood.io.serializers.StringMetadataSerializer;
import com.rackspacecloud.blueflood.outputs.formats.MetricData;
import com.rackspacecloud.blueflood.rollup.Granularity;
import com.rackspacecloud.blueflood.service.SlotState;
import com.rackspacecloud.blueflood.types.*;
import com.rackspacecloud.blueflood.utils.Util;
import org.slf4j.Logger;
import org.slf4j.LoggerFactory;

import java.io.IOException;
import java.util.*;

public class AstyanaxReader extends AstyanaxIO {
    private static final Logger log = LoggerFactory.getLogger(AstyanaxReader.class);
    private static final MetadataCache metaCache = MetadataCache.getInstance();
    private static final AstyanaxReader INSTANCE = new AstyanaxReader();
    private static final String rollupTypeCacheKey = MetricMetadata.ROLLUP_TYPE.toString().toLowerCase();
    private static final String dataTypeCacheKey = MetricMetadata.TYPE.toString().toLowerCase();

    private static final Keyspace keyspace = getKeyspace();

    public static AstyanaxReader getInstance() {
        return INSTANCE;
    }

    /**
     * Method that returns all metadata for a given locator as a map.
     *
     * @param locator  locator name
     * @return Map of metadata for that locator
     * @throws RuntimeException(com.netflix.astyanax.connectionpool.exceptions.ConnectionException)
     */
    public Map<String, String> getMetadataValues(Locator locator) {
        Timer.Context ctx = Instrumentation.getReadTimerContext(CassandraModel.CF_METRIC_METADATA);
        try {
            final ColumnList<String> results = keyspace.prepareQuery(CassandraModel.CF_METRIC_METADATA)
                    .getKey(locator)
                    .execute().getResult();
            return new HashMap<String, String>(){{
                for (Column<String> result : results) {
                    put(result.getName(), result.getValue(StringMetadataSerializer.get()));
                }
            }};
        } catch (NotFoundException ex) {
            Instrumentation.markNotFound(CassandraModel.CF_METRIC_METADATA);
            return null;
        } catch (ConnectionException e) {
            log.error("Error reading metadata value", e);
            Instrumentation.markReadError(e);
            throw new RuntimeException(e);
        } finally {
            ctx.stop();
        }
    }

    public Table<Locator, String, String> getMetadataValues(Set<Locator> locators) {
        ColumnFamily CF = CassandraModel.CF_METRIC_METADATA;
        boolean isBatch = locators.size() > 1;
        Table<Locator, String, String> metaTable = HashBasedTable.create();

        Timer.Context ctx = isBatch ? Instrumentation.getBatchReadTimerContext(CF) : Instrumentation.getReadTimerContext(CF);
        try {
            // We don't paginate this call. So we should make sure the number of reads is tolerable.
            // TODO: Think about paginating this call.
            OperationResult<Rows<Locator, String>> query = keyspace
                    .prepareQuery(CF)
                    .getKeySlice(locators)
                    .execute();

            for (Row<Locator, String> row : query.getResult()) {
                ColumnList<String> columns = row.getColumns();
                for (Column<String> column : columns) {
                    String metaValue = column.getValue(StringMetadataSerializer.get());
                    String metaKey = column.getName();
                    metaTable.put(row.getKey(), metaKey, metaValue);
                }
            }
        } catch (ConnectionException e) {
            if (e instanceof NotFoundException) { // TODO: Not really sure what happens when one of the keys is not found.
                Instrumentation.markNotFound(CF);
            } else {
                if (isBatch) { Instrumentation.markBatchReadError(e); }
                else { Instrumentation.markReadError(e); }
            }
            log.warn((isBatch ? "Batch " : "") + " read query failed for column family " + CF.getName(), e);
        } finally {
            ctx.stop();
        }

        return metaTable;
    }

    /**
     * Method that makes the actual cassandra call to get the most recent string value for a locator
     *
     * @param locator  locator name
     * @return String most recent string value for metric.
     * @throws RuntimeException(com.netflix.astyanax.connectionpool.exceptions.ConnectionException)
     */
    public String getLastStringValue(Locator locator) {
        Timer.Context ctx = Instrumentation.getReadTimerContext(CassandraModel.CF_METRICS_STRING);

        try {
            ColumnList<Long> query = keyspace
                    .prepareQuery(CassandraModel.CF_METRICS_STRING)
                    .getKey(locator)
                    .withColumnRange(new RangeBuilder().setReversed(true).setLimit(1).build())
                    .execute()
                    .getResult();

            return query.isEmpty() ? null : query.getColumnByIndex(0).getStringValue();
        } catch (ConnectionException e) {
            if (e instanceof NotFoundException) {
                Instrumentation.markNotFound(CassandraModel.CF_METRICS_STRING);
            } else {
                Instrumentation.markReadError(e);
            }
            log.warn("Could not get previous string metric value for locator " +
                    locator, e);
            throw new RuntimeException(e);
        } finally {
            ctx.stop();
        }
    }

    /**
     * Returns the recently seen locators, i.e. those that should be rolled up, for a given shard.
     * 'Should' means:
     *  1) A locator is capable of rollup (it is not a string/boolean metric).
     *  2) A locator has had new data in the past {@link com.rackspacecloud.blueflood.io.AstyanaxWriter.LOCATOR_TTL} seconds.
     *
     * @param shard Number of the shard you want the recent locators for. 0-127 inclusive.
     * @return Collection of locators
     * @throws RuntimeException(com.netflix.astyanax.connectionpool.exceptions.ConnectionException)
     */
    public Collection<Locator> getLocatorsToRollup(long shard) {
        Timer.Context ctx = Instrumentation.getReadTimerContext(CassandraModel.CF_METRICS_LOCATOR);
        try {
            RowQuery<Long, Locator> query = keyspace
                    .prepareQuery(CassandraModel.CF_METRICS_LOCATOR)
                    .getKey(shard);
            return query.execute().getResult().getColumnNames();
        } catch (NotFoundException e) {
            Instrumentation.markNotFound(CassandraModel.CF_METRICS_LOCATOR);
            return Collections.emptySet();
        } catch (ConnectionException e) {
            Instrumentation.markReadError(e);
            log.error("Error reading locators", e);
            throw new RuntimeException("Error reading locators", e);
        } finally {
            ctx.stop();
        }
    }

    /**
     * Gets all ShardStates for a given shard.
     *
     * @param shard Shard to retrieve all SlotState objects for.
     */
    public Collection<SlotState> getShardState(int shard) {
        Timer.Context ctx = Instrumentation.getReadTimerContext(CassandraModel.CF_METRICS_STATE);
        final Collection<SlotState> slotStates = new LinkedList<SlotState>();
        try {
            ColumnList<SlotState> columns = keyspace.prepareQuery(CassandraModel.CF_METRICS_STATE)
                    .getKey((long)shard)
                    .execute()
                    .getResult();

            for (Column<SlotState> column : columns) {
                slotStates.add(column.getName().withTimestamp(column.getLongValue()));
            }
        } catch (ConnectionException e) {
            Instrumentation.markReadError(e);
            log.error("Error getting shard state for shard " + shard, e);
            throw new RuntimeException(e);
        } finally {
            ctx.stop();
        }
        return slotStates;
    }

    private ColumnList<Long> getColumnsFromDB(final Locator locator, ColumnFamily<Locator, Long> srcCF, Range range) {
        List<Locator> locators = new LinkedList<Locator>(){{ add(locator); }};
        ColumnList<Long> columns = getColumnsFromDB(locators, srcCF, range).get(locator);
        return columns == null ? new EmptyColumnList<Long>() : columns;
    }

    private Map<Locator, ColumnList<Long>> getColumnsFromDB(List<Locator> locators, ColumnFamily<Locator, Long> CF,
                                                            Range range) {
        if (range.getStart() > range.getStop()) {
            throw new RuntimeException(String.format("Invalid rollup range: ", range.toString()));
        }
        boolean isBatch = locators.size() != 1;

        final Map<Locator, ColumnList<Long>> columns = new HashMap<Locator, ColumnList<Long>>();
        final RangeBuilder rangeBuilder = new RangeBuilder().setStart(range.getStart()).setEnd(range.getStop());

        Timer.Context ctx = isBatch ? Instrumentation.getBatchReadTimerContext(CF) : Instrumentation.getReadTimerContext(CF);
        try {
            // We don't paginate this call. So we should make sure the number of reads is tolerable.
            // TODO: Think about paginating this call.
            OperationResult<Rows<Locator, Long>> query = keyspace
                    .prepareQuery(CF)
                    .getKeySlice(locators)
                    .withColumnRange(rangeBuilder.build())
                    .execute();

            for (Row<Locator, Long> row : query.getResult()) {
                columns.put(row.getKey(), row.getColumns());
            }
        } catch (ConnectionException e) {
            if (e instanceof NotFoundException) { // TODO: Not really sure what happens when one of the keys is not found.
                Instrumentation.markNotFound(CF);
            } else {
                if (isBatch) { Instrumentation.markBatchReadError(e); }
                else { Instrumentation.markReadError(e); }
            }
            log.warn((isBatch ? "Batch " : "") + " read query failed for column family " + CF.getName(), e);
        } finally {
            ctx.stop();
        }

        return columns;
    }

    // todo: this could be the basis for every rollup read method.
    // todo: A better interface may be to pass the serializer in instead of the class type.
    public <T extends Rollup> Points<T> getDataToRoll(Class<T> type, Locator locator, Range range, ColumnFamily<Locator, Long> cf) throws IOException {
        AbstractSerializer serializer = NumericSerializer.serializerFor(type);
        // special cases. :( the problem here is that the normal full res serializer returns Number instances instead of
        // SimpleNumber instances.
        // todo: this logic will only become more complicated. It needs to be in its own method and the serializer needs
        // to be known before we ever get to this method (see above comment).
        if (cf == CassandraModel.CF_METRICS_FULL) {
            serializer = NumericSerializer.simpleNumberSerializer;
        } else if ( cf == CassandraModel.CF_METRICS_PREAGGREGATED_FULL) {
            // consider a method for this.  getSerializer(CF, TYPE);
            if (type.equals(TimerRollup.class)) {
                serializer = NumericSerializer.timerRollupInstance;
            } else if (type.equals(SetRollup.class)) {
                serializer = NumericSerializer.setRollupInstance;
            } else if (type.equals(GaugeRollup.class)) {
                serializer = NumericSerializer.gaugeRollupInstance;
            } else if (type.equals(CounterRollup.class)) {
                serializer = NumericSerializer.CounterRollupInstance;
            } else {
                serializer = NumericSerializer.simpleNumberSerializer;
            }
        }
        
        ColumnList<Long> cols = getColumnsFromDB(locator, cf, range);
        Points<T> points = new Points<T>();
        try {
            for (Column<Long> col : cols) {
                points.add(new Points.Point<T>(col.getName(), (T)col.getValue(serializer)));
            }
        } catch (RuntimeException ex) {
            log.error("Problem deserializing data for " + locator + " (" + range + ") from " + cf.getName(), ex);
            throw new IOException(ex);
        }
        return points;
    }

    public static String getUnitString(Locator locator) {
        String unitString = Util.UNKNOWN;
        // Only grab units from cassandra, if we have to
        if (!Util.shouldUseESForUnits()) {
            try {
                unitString = metaCache.get(locator, MetricMetadata.UNIT.name().toLowerCase(), String.class);
            } catch (CacheException ex) {
                log.warn("Cache exception reading unitString from MetadataCache: ", ex);
            }
            if (unitString == null) {
                unitString = Util.UNKNOWN;
            }
        }

        return unitString;
    }

    public static String getType(Locator locator) {
        String type = null;
        try {
            type = metaCache.get(locator, MetricMetadata.TYPE.name().toLowerCase(), String.class);
        } catch (CacheException ex) {
            log.warn("Cache exception reading type from MetadataCache. ", ex);
        }
        if (type == null) {
            type = Util.UNKNOWN;
        }
        return type;
    }

    public MetricData getDatapointsForRange(Locator locator, Range range, Granularity gran) {
        try {
            Object type = metaCache.get(locator, dataTypeCacheKey);
            RollupType rollupType = RollupType.fromString(metaCache.get(locator, rollupTypeCacheKey));

            if (rollupType == null) {
                rollupType = RollupType.BF_BASIC;
            }
            if (type == null) {
                return getNumericOrStringRollupDataForRange(locator, range, gran, rollupType);
            }

            DataType metricType = new DataType((String) type);
            if (!DataType.isKnownMetricType(metricType)) {
                return getNumericOrStringRollupDataForRange(locator, range, gran, rollupType);
            }

            if (metricType.equals(DataType.STRING)) {
                gran = Granularity.FULL;
                return getStringMetricDataForRange(locator, range, gran);
            } else if (metricType.equals(DataType.BOOLEAN)) {
                gran = Granularity.FULL;
                return getBooleanMetricDataForRange(locator, range, gran);
            } else {
                return getNumericMetricDataForRange(locator, range, gran, rollupType, metricType);
            }

        } catch (CacheException e) {
            log.warn("Caught exception trying to find metric type from meta cache for locator " + locator.toString(), e);
            return getNumericOrStringRollupDataForRange(locator, range, gran, RollupType.BF_BASIC);
        }
    }

    // TODO: This should be the only method all output handlers call. We should be able to deprecate
    // other individual metric fetch methods once this gets in.
    public Map<Locator, MetricData> getDatapointsForRange(List<Locator> locators, Range range, Granularity gran) {
        ListMultimap<ColumnFamily, Locator> locatorsByCF =
                 ArrayListMultimap.create();
        Map<Locator, MetricData> results = new HashMap<Locator, MetricData>();

        for (Locator locator : locators) {
            try {
                RollupType rollupType = RollupType.fromString((String)
                            metaCache.get(locator, MetricMetadata.ROLLUP_TYPE.name().toLowerCase()));
                DataType dataType = getDataType(locator, MetricMetadata.TYPE.name().toLowerCase());
                ColumnFamily cf = CassandraModel.getColumnFamily(rollupType, dataType, gran);
                List<Locator> locs = locatorsByCF.get(cf);
                locs.add(locator);
            } catch (Exception e) {
                // pass for now. need metric to figure this stuff out.
            }
        }

         for (ColumnFamily CF : locatorsByCF.keySet()) {
            List<Locator> locs = locatorsByCF.get(CF);
            Map<Locator, ColumnList<Long>> metrics = getColumnsFromDB(locs, CF, range);
            // transform columns to MetricData
            for (Locator loc : metrics.keySet()) {
                MetricData data = transformColumnsToMetricData(loc, metrics.get(loc), gran);
                if (data != null && data.getData() != null) {
                    results.put(loc, data);
                }
            }
        }

        return results;
    }


    public MetricData getHistogramsForRange(Locator locator, Range range, Granularity granularity) throws IOException {
        if (!granularity.isCoarser(Granularity.FULL)) {
            throw new RuntimeException("Histograms are not available for granularity " + granularity.toString());
        }

        ColumnFamily cf = CassandraModel.getColumnFamily(HistogramRollup.class, granularity);
        Points<HistogramRollup> histogramRollupPoints = getDataToRoll(HistogramRollup.class, locator, range, cf);
        return new MetricData(histogramRollupPoints, getUnitString(locator), MetricData.Type.HISTOGRAM);
    }

    // Used for string metrics
    private MetricData getStringMetricDataForRange(Locator locator, Range range, Granularity gran) {
        Points<String> points = new Points<String>();
        ColumnList<Long> results = getColumnsFromDB(locator, CassandraModel.CF_METRICS_STRING, range);

        for (Column<Long> column : results) {
            try {
                points.add(new Points.Point<String>(column.getName(), column.getValue(StringSerializer.get())));
            } catch (RuntimeException ex) {
                log.error("Problem deserializing String data for " + locator + " (" + range + ") from " +
                        CassandraModel.CF_METRICS_STRING.getName(), ex);
            }
        }

        return new MetricData(points, getUnitString(locator), MetricData.Type.STRING);
    }

    private MetricData getBooleanMetricDataForRange(Locator locator, Range range, Granularity gran) {
        Points<Boolean> points = new Points<Boolean>();
        ColumnList<Long> results = getColumnsFromDB(locator, CassandraModel.CF_METRICS_STRING, range);

        for (Column<Long> column : results) {
            try {
                points.add(new Points.Point<Boolean>(column.getName(), column.getValue(BooleanSerializer.get())));
            } catch (RuntimeException ex) {
                log.error("Problem deserializing Boolean data for " + locator + " (" + range + ") from " +
                        CassandraModel.CF_METRICS_STRING.getName(), ex);
            }
        }

        return new MetricData(points, getUnitString(locator), MetricData.Type.BOOLEAN);
    }

    // todo: replace this with methods that pertain to type (which can be used to derive a serializer).
    private MetricData getNumericMetricDataForRange(Locator locator, Range range, Granularity gran, RollupType rollupType, DataType dataType) {
        ColumnFamily<Locator, Long> CF = CassandraModel.getColumnFamily(rollupType, dataType, gran);

        Points points = new Points();
        ColumnList<Long> results = getColumnsFromDB(locator, CF, range);
        
        // todo: this will not work when we cannot derive data type from granularity. we will need to know what kind of
        // data we are asking for and use a specific reader method.
        AbstractSerializer serializer = NumericSerializer.serializerFor(RollupType.classOf(rollupType, gran));

        for (Column<Long> column : results) {
            try {
                points.add(pointFromColumn(column, serializer));
            } catch (RuntimeException ex) {
                log.error("Problem deserializing data for " + locator + " (" + range + ") from " + CF.getName(), ex);
            }
        }

        return new MetricData(points, getUnitString(locator), MetricData.Type.NUMBER);
    }

    // gets called when we DO NOT know what the data type is (numeric, string, etc.)
    private MetricData getNumericOrStringRollupDataForRange(Locator locator, Range range, Granularity gran, RollupType rollupType) {
        Instrumentation.markScanAllColumnFamilies();

        final MetricData metricData = getNumericMetricDataForRange(locator, range, gran, rollupType, DataType.NUMERIC);

        if (metricData.getData().getPoints().size() > 0) {
            return metricData;
        }

        return getStringMetricDataForRange(locator, range, gran);
    }

    private MetricData transformColumnsToMetricData(Locator locator, ColumnList<Long> columns,
                                                                       Granularity gran) {
        try {
            RollupType rollupType = RollupType.fromString(metaCache.get(locator, rollupTypeCacheKey));
            DataType dataType = getDataType(locator, dataTypeCacheKey);
            String unit = getUnitString(locator);
            MetricData.Type outputType = MetricData.Type.from(rollupType, dataType);
            Points points = getPointsFromColumns(columns, rollupType, dataType, gran);
            MetricData data = new MetricData(points, unit, outputType);
            return data;
        } catch (Exception e) {
            return null;
        }
    }

    private DataType getDataType(Locator locator, String dataTypeCacheKey) throws CacheException{
        String meta = metaCache.get(locator, dataTypeCacheKey);
        if (meta != null) {
            return new DataType(meta);
        }
        return DataType.NUMERIC;
    }

    private Points getPointsFromColumns(ColumnList<Long> columnList, RollupType rollupType,
                                        DataType dataType, Granularity gran) {
        Points points = new Points();

        AbstractSerializer serializer = serializerFor(rollupType, dataType, gran);
        for (Column<Long> column : columnList) {
            points.add(pointFromColumn(column, serializer));
        }

        return points;
    }

    private Points.Point pointFromColumn(Column<Long> column, AbstractSerializer serializer) {
        if (serializer instanceof NumericSerializer.RawSerializer)
            return new Points.Point(column.getName(), new SimpleNumber(column.getValue(serializer)));
        else
            // this works for EVERYTHING except SimpleNumber.
        return new Points.Point(column.getName(), column.getValue(serializer));
    }
}


File: blueflood-core/src/main/java/com/rackspacecloud/blueflood/io/AstyanaxRowCounterFunction.java
/*
 * Copyright 2015 Rackspace
 *
 *    Licensed under the Apache License, Version 2.0 (the "License");
 *    you may not use this file except in compliance with the License.
 *    You may obtain a copy of the License at
 *
 *        http://www.apache.org/licenses/LICENSE-2.0
 *
 *    Unless required by applicable law or agreed to in writing, software
 *    distributed under the License is distributed on an "AS IS" BASIS,
 *    WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 *    See the License for the specific language governing permissions and
 *    limitations under the License.
 */

package com.rackspacecloud.blueflood.io;
import com.google.common.base.Function;
import com.netflix.astyanax.model.Row;

import java.util.concurrent.atomic.AtomicLong;

// todo: This belongs in the test code. IntegrationTestBase depends on it though. So we have to wait until
// IntegrationTestBase is moved back into the test section of the repository.
/**
 * Simple function to counter the number of rows
 *
 * @author elandau
 *
 * @param <K>
 * @param <C>
 */
// Copy-pasted from astyanax 1.56.37, it doesn't exist in 1.56.32 which we use.
public class AstyanaxRowCounterFunction<K,C> implements Function<Row<K,C>, Boolean> {

    private final AtomicLong counter = new AtomicLong(0);

    @Override
    public Boolean apply(Row<K,C> input) {
        counter.incrementAndGet();
        return true;
    }

    public long getCount() {
        return counter.get();
    }

    public void reset() {
        counter.set(0);
    }
}
